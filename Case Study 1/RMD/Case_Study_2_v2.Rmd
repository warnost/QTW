---
title: "Case Study - Real Time Location Systems"
date: "`r Sys.Date()`"
author: "Allison Roderick, Jenna Ford, William Arnost"
output:
  rmdformats::readthedown:
    number_sections: true
    code_folding: hide
    highlight: kate
    toc_depth: 3
---


```{r setup, echo=FALSE, cache=FALSE, include=FALSE}
library(knitr)
library(rmdformats)
library(formatR)

library(tidyverse)
library(magrittr)
library(caret)
library(pls)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

# Code

Use the `code` button to the right to expand the code for cleaning up the dataset.

```{r datapull1}
########## Data Cleanup ##########

processLine = function(x){
  tokens = strsplit(x, "[;=,]")[[1]]
  
  if (length(tokens) == 10) 
    return(NULL)
 
  # keep the last 4 columns related to measurements
  tmp = matrix(tokens[ - (1:10) ], ncol= 4, byrow = TRUE)
  # don't include columns 1, 3, 4, 9 because these are variable names
  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6, byrow = TRUE), tmp)
}


roundOrientation = function(angles) {
  refs = seq(0, by = 45, length  = 9)
  q = sapply(angles, function(o) which.min(abs(o - refs)))
  c(refs[1:8], 0)[q]
}

readData = function(filename = '../Data/offline.final.trace.txt', 
           subMacs = c("00:0f:a3:39:e1:c0", "00:0f:a3:39:dd:cd", "00:14:bf:b1:97:8a",
                       "00:14:bf:3b:c7:c6", "00:14:bf:b1:97:90", "00:14:bf:b1:97:8d",
                       "00:14:bf:b1:97:81"))  {
    txt = readLines(filename)
    
    #remove comments
    lines = txt[ substr(txt, 1, 1) != "#" ]
    
    #apply function to read and parse data
    tmp = lapply(lines, processLine)
    offline = as.data.frame(do.call("rbind", tmp), 
                            stringsAsFactors= FALSE) 
    
    names(offline) = c("time", "scanMac", 
                       "posX", "posY", "posZ", "orientation", 
                       "mac", "signal", "channel", "type")
    
     # keep only signals from access points
    offline = offline[ offline$type == "3", ]
    
    # drop scanMac, posZ, channel, and type - no info in them
    dropVars = c("scanMac", "posZ", "channel", "type")
    offline = offline[ , !( names(offline) %in% dropVars ) ]
    
    # drop more unwanted access points
    offline = offline[ offline$mac %in% subMacs, ]
    
    # convert numeric values
    numVars = c("time", "posX", "posY", "orientation", "signal")
    offline[ numVars ] = lapply(offline[ numVars ], as.numeric)

    # convert time to POSIX
    offline$rawTime = offline$time
    offline$time = offline$time/1000
    class(offline$time) = c("POSIXt", "POSIXct")
    
    # round orientations to nearest 45
    offline$angle = roundOrientation(offline$orientation)
      
    return(offline)
  }

offline = readData(filename = '../Data/offline.final.trace.txt')
subMacs = names(sort(table(offline$mac), decreasing = TRUE))
online = readData(filename = '../Data/online.final.trace.txt')

# investigating frequency of measurements by mac address
vals = data.frame(table(mac=offline['mac']))
#vals[order(-vals$Freq),] #used table 2 instead

# format signal stength as an integer
offline$signal %<>% as.integer
online$signal %<>% as.integer

# remove channel and scanMac as they have no bearing on the analysis
# transpose long to wide so each of the 7 macs has a column
offline_pivot<-offline %>% pivot_wider(names_from = mac,values_from = signal, values_fn = list(signal=mean))
online_pivot<- online %>% pivot_wider(names_from = mac,values_from = signal, values_fn = list(signal=mean))

# impute NA 
#offline_pivot[is.na(offline_pivot)] <- -100
#online_pivot[is.na(online_pivot)] <- -100

# drop records with missing values
non_miss <- complete.cases(offline_pivot)
offline_pivot <- offline_pivot[non_miss,]

non_miss <- complete.cases(online_pivot)
online_pivot <- online_pivot[non_miss,]

# create categorical variable representing the x-y position 
offline_pivot$posXY = paste(offline_pivot$posX, offline_pivot$posY, sep = "-")
online_pivot$posXY = paste(online_pivot$posX, online_pivot$posY, sep = "-")
online_pivot$posXY_round = paste(round(online_pivot$posX,digits=0), round(online_pivot$posY,digits=0), sep = "-")

# create 2 datasets for the 2 different models, offline_pivot has posXY and offline_pivot_x_y has both posX and posY
offline_pivot_x_y = offline_pivot
# remove variables that are not needed for modeling
offline_pivot = select(offline_pivot,-c(time, posX, posY, orientation, rawTime))
offline_pivot_x_y = select(offline_pivot_x_y,-c(time, orientation, rawTime, posXY))

# create 2 datasets for the 2 different models, offline_pivot has posXY and offline_pivot_x_y has both posX and posY
online_pivot_x_y = online_pivot
# remove variables that are not needed for modeling
online_pivot = select(online_pivot,-c(time, posX, posY, orientation, rawTime, posXY))
online_pivot = online_pivot %>% rename(posXY = posXY_round)
online_pivot_x_y = select(online_pivot_x_y,-c(time, orientation, rawTime, posXY_round))
```
 
 Use the `code` button to the right to expand the code for modeling.
 
```{r}
########## Model Code ##########

# all 7 subMacs
set.seed(123)
trControl <- trainControl(method  = "cv", number  = 5)
fit <- train(posXY ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = seq(3,11,2)),
             trControl  = trControl,
             data       = offline_pivot,
             preProcess = c("center","scale")
             )
predict = predict(fit, newdata=online_pivot, type="raw")
accuracy <- as.data.frame(cbind(predict=as.factor(predict),actual=as.factor(online_pivot$posXY)))
accuracy$correct <- accuracy[,1] == accuracy[,2]
acc = sum(accuracy$correct)/length(accuracy$correct)

# 6 subMacs, including 00:0f:a3:39:dd:cd
offline_pivot_6 = select(offline_pivot,-c(`00:0f:a3:39:e1:c0`))
online_pivot_6 = select(online_pivot,-c(`00:0f:a3:39:e1:c0`))
set.seed(123)
trControl <- trainControl(method  = "cv", number  = 5)
fit <- train(posXY ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = seq(3,11,2)),
             trControl  = trControl,
             data       = offline_pivot_6,
             preProcess = c("center","scale")
)
predict = predict(fit, newdata=online_pivot_6, type="raw")
accuracy <- as.data.frame(cbind(predict=as.factor(predict),actual=as.factor(online_pivot_6$posXY)))
accuracy$correct <- accuracy[,1] == accuracy[,2]
acc = sum(accuracy$correct)/length(accuracy$correct)

# 6 subMacs, including 00:0f:a3:39:e1:c0
offline_pivot_6 = select(offline_pivot,-c(`00:0f:a3:39:dd:cd`))
online_pivot_6 = select(online_pivot,-c(`00:0f:a3:39:dd:cd`))
set.seed(123)
trControl <- trainControl(method  = "cv", number  = 5)
fit <- train(posXY ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = seq(3,11,2)),
             trControl  = trControl,
             data       = offline_pivot_6,
             preProcess = c("center","scale")
)
predict = predict(fit, newdata=online_pivot_6, type="raw")
accuracy <- as.data.frame(cbind(predict=as.factor(predict),actual=as.factor(online_pivot_6$posXY)))
accuracy$correct <- accuracy[,1] == accuracy[,2]
acc = sum(accuracy$correct)/length(accuracy$correct)


# multi-target regression

# all 7 subMacs
X <- cbind(offline_pivot_x_y$`00:14:bf:b1:97:8a`,offline_pivot_x_y$`00:14:bf:b1:97:90`,offline_pivot_x_y$`00:0f:a3:39:e1:c0`,offline_pivot_x_y$`00:14:bf:b1:97:8d`,
           offline_pivot_x_y$`00:14:bf:b1:97:81`,offline_pivot_x_y$`00:14:bf:3b:c7:c6`,offline_pivot_x_y$`00:0f:a3:39:dd:cd`,offline_pivot_x_y$angle)
fit <- plsr(cbind(posX,posY) ~ X, ncomp=8, data=offline_pivot_x_y, scale=TRUE, validation="CV", segments=5)
mean_distance_error <- mean(sqrt(fit$residuals[1]^2+fit$residuals[2]^2))

newX <- cbind(online_pivot_x_y$`00:14:bf:b1:97:8a`,online_pivot_x_y$`00:14:bf:b1:97:90`,online_pivot_x_y$`00:0f:a3:39:e1:c0`,online_pivot_x_y$`00:14:bf:b1:97:8d`,
              online_pivot_x_y$`00:14:bf:b1:97:81`,online_pivot_x_y$`00:14:bf:3b:c7:c6`,online_pivot_x_y$`00:0f:a3:39:dd:cd`,online_pivot_x_y$angle)
predict <- predict(fit, ncomp=8, newdata=newX)
predict_df <- as.data.frame(predict)
names(predict_df) = c("posX","posY")
mean_distance_error <- mean(sqrt((online_pivot_x_y$posX - predict_df$posX)^2+(online_pivot_x_y$posY - predict_df$posY)^2))

# 6 subMacs, including 00:0f:a3:39:dd:cd
X <- cbind(offline_pivot_x_y$`00:14:bf:b1:97:8a`,offline_pivot_x_y$`00:14:bf:b1:97:90`,offline_pivot_x_y$`00:14:bf:b1:97:8d`,
           offline_pivot_x_y$`00:14:bf:b1:97:81`,offline_pivot_x_y$`00:14:bf:3b:c7:c6`,offline_pivot_x_y$`00:0f:a3:39:dd:cd`,offline_pivot_x_y$angle)
fit <- plsr(cbind(posX,posY) ~ X, ncomp=7, data=offline_pivot_x_y, scale=TRUE, validation="CV", segments=5)
mean_distance_error <- mean(sqrt(fit$residuals[1]^2+fit$residuals[2]^2))

newX <- cbind(online_pivot_x_y$`00:14:bf:b1:97:8a`,online_pivot_x_y$`00:14:bf:b1:97:90`,online_pivot_x_y$`00:14:bf:b1:97:8d`,
              online_pivot_x_y$`00:14:bf:b1:97:81`,online_pivot_x_y$`00:14:bf:3b:c7:c6`,online_pivot_x_y$`00:0f:a3:39:dd:cd`,online_pivot_x_y$angle)
predict <- predict(fit, ncomp=7, newdata=newX)
predict_df <- as.data.frame(predict)
names(predict_df) = c("posX","posY")
mean_distance_error <- mean(sqrt((online_pivot_x_y$posX - predict_df$posX)^2+(online_pivot_x_y$posY - predict_df$posY)^2))

# 6 subMacs, including 00:0f:a3:39:e1:c0
X <- cbind(offline_pivot_x_y$`00:14:bf:b1:97:8a`,offline_pivot_x_y$`00:14:bf:b1:97:90`,offline_pivot_x_y$`00:0f:a3:39:e1:c0`,offline_pivot_x_y$`00:14:bf:b1:97:8d`,
           offline_pivot_x_y$`00:14:bf:b1:97:81`,offline_pivot_x_y$`00:14:bf:3b:c7:c6`,offline_pivot_x_y$angle)
fit <- plsr(cbind(posX,posY) ~ X, ncomp=7, data=offline_pivot_x_y, scale=TRUE, validation="CV", segments=5)
mean_distance_error <- mean(sqrt(fit$residuals[1]^2+fit$residuals[2]^2))

newX <- cbind(online_pivot_x_y$`00:14:bf:b1:97:8a`,online_pivot_x_y$`00:14:bf:b1:97:90`,online_pivot_x_y$`00:0f:a3:39:e1:c0`,online_pivot_x_y$`00:14:bf:b1:97:8d`,
              online_pivot_x_y$`00:14:bf:b1:97:81`,online_pivot_x_y$`00:14:bf:3b:c7:c6`,online_pivot_x_y$angle)
predict <- predict(fit, ncomp=7, newdata=newX)
predict_df <- as.data.frame(predict)
names(predict_df) = c("posX","posY")
mean_distance_error <- mean(sqrt((online_pivot_x_y$posX - predict_df$posX)^2+(online_pivot_x_y$posY - predict_df$posY)^2))
```

# Introduction

This case study explores the data captured by real time location systems (RLTS). The data provided indicates the signal strength, as measured in decibels (dB) by a hand-held device, from various fixed access points. Both the scanning devices and the fixed devices are identified in the data by their media access control (MAC) addresses. k-NN classification is used to classify a location. This is done by combining X and Y coordinates into a single variable for classification. Due to drawbacks that are discussed later, a multi-target regression model is also run.

Section 3 gives some background on the dataset. Section 4 goes into detail about the dataset, data cleanup and the models used. Next, in Section 5 the results for the models are reviewed. Section 6 highlights some drawbacks of using k-NN classification for RLTS and Section 7 concludes this case study.

# Background

RTLS are ubiquitous with modern technology. Your phone knows where you are and can give directions to other locations based off your current location. You can locate someone else's phone, your car, your keys even. Global Positioning Systems (GPS) are a primary location mechanism, but primarily work outdoors. Using wireless signal strength between a hand-held device and a fixed device is one way to identify location inside a building, where GPS does not work.

# Methods

## Dataset

The dataset used in this case study contains 914,951 signal strength readings from one floor of a building at the University of Mannheim. There are 6 fixed access points where the signal strength is measured from hand-held devices. 166 different spots were selected for the hand-held devices to record signal strength. At each of these 166 spots measurements were taken at different angles. There were 9 possible angles, each spaced 45 degrees apart.

The data is organized as a text file with each line representing a measurement event. An example line and each variable recorded are shown below.

```{r txt}
# this is the first non-comment line in the text file
txt = readLines('../Data/offline.final.trace.txt')
txt[4]
```

`Table 1` presents details about the variables that are available in the dataset.

Table 1: Dataset Variables

| Variable        | Description | 
| ------- |-------------| 
| time | Time the measurement was taken in milliseconds from January 1, 1970. | 
| id | Scanning device's MAC Address id. All measurements are taken by the same scanning device: `00:02:2D:21:0F:33`. |
| pos | 3 position measurements: posX, posY, and posZ. posZ is always zero. |
| degree | Orientation of the scanning device in degrees. |
| Recorded Measurement - MAC Address | First value in the field indicating the MAC address access point. |
| Recorded Measurement - Signal | Second value in the field indicating the signal strength measured in dB. |
| Recorded Measurement - Channel | Third value in the field indicating the channel frequency. |
| Recorded Measurement - Access Point Type | Fourth value in the field indicating the access point type. 1 = adhoc device. 3 = fixed access point. |

## Dataset Cleanup

Data cleanup is necessary to be able to use this text file. What follows in this section is a discussion of the data clean-up steps taken. Please note that the majority of this code was taken from the Data Science in R textbook.

A quick review of the textfile provided shows that there are lines that begin with `#`. These lines are comments and should not be included in the final dataset. They are removed before further processing the data.

Next, a function is applied to parse the data from a sting into columns. The last 4 columns are the `Recorded Measurements` and are pulled out first. These columns do not have variable names included in the textfile. Included within the first 10 columns is a variable name and its value. Columns 2, 4, 6:8 and 10 are data values and are kept. The remaining columns are discarded. The resulting dataset is converted to a dataframe and variable names are added.

There are some records in the dataset that are from adhoc access points. Due to information provided in the textbook, these records have been removed because they are not of interest.

As noted in `Table 1` there are several variables that have the same value throughout the dataset: `id`, `posZ` and `channel frequency`. Also, since adhoc access points were filtered out of the dataset, `access point type` also has the same value throughout the dataset. These variables are dropped.

The textbook noted that there are only 6 actual access points, however more are found in the dataset. Only the top 7 addresses by frequency will be considered in this analysis. `Table 2` displays the MAC address access point and frequency for the top 7 access points. The dataset is filtered to only include these 7 MAC addresses.

Table 2: MAC Address Access Point Frequency

| MAC | Frequency | 
| - |------| 
| 00:0f:a3:39:e1:c0 | 145,862 | 
| 00:0f:a3:39:dd:cd | 145,619 |
| 00:14:bf:b1:97:8a | 132,962 |
| 00:14:bf:3b:c7:c6 | 126,529 |
| 00:14:bf:b1:97:90 | 122,315 |
| 00:14:bf:b1:97:8d | 121,325 |
| 00:14:bf:b1:97:81 | 120,339 |

Data types also need to be corrected. `time`, `posX`, `posY`, `orientation`, and `signal` are converted to numeric. `time` is further converted to datetime. `degree` is also adjusted by rounding to the nearest 45 degree increment.

Each measurement event can be uniquely identified by the time, position, and orientation of the scanning device. However, our initial processing of the text file created a "long" dataframe that had multiple rows for each unique event. Each row represents a measurement for one of the 7 fixed access devices. The dataframe is transposed from "long" to "wide" to make each row a unique event. The resulting dataframe has 7 new variables, each representing a fixed access device's measurement.

A review of the resulting dataframes show that there are missing values for some measurements. The models described in the next section require the data to not have missing values. The option chosen here to handle missing values is drop records where any of the explanatory variables are missing. Another possible option would have been to impute missing values.

The k-NN classification model will also require a singular categorical target variable. `posX` and `posY` are concatenated together into `posXY`, where the X and Y values are separated by a hyphen. At this point, a copy of the dataframe is made. One copy (offline_pivot) will be used for k-NN classification and the other copy (offline_pivot_x_y) will be used for multi-target regression. The reason for creating 2 datasets is that the same set of variables is not needed for each model. `posXY` is needed for k-NN classification, but `posX` and `posY` are needed for multi-target regression. Other variables that do not provide any extra value for modeling are dropped: `time`, `rawTime` and `orientation` (using the rounded `angle` instead).

The steps outlined above are used both on the offline textfile (training) and the online textfile (test). There is an extra step taken for the online dataset. For k-NN classification, the same target variables need to be in the training and test datasets. The online dataset has coordinates with decimal places and the offline dataset were integers. Therefore, `posX` and `posY` were rounded to the nearest integer. These rounded positions will be used for k-NN classification. The exact positions will be used for multi-target regression.

## Modeling  

The goal of this case study is to use the offline data to predict the x-y location of the online data. Two methods are applied towards this end: k-NN classification and multi-target regression. 

### k-NN Classification 

k-NN classification is used to predict the categorical variable `posXY`, which contains the x and y coordinates separated by a hyphen. k-NN classification works as follows: for each measurement event in the dataset, the closest k neighbors are identified by finding the k smallest Euclidean distances between the datapoint and all other datapoints. The explanatory variables `angle` and the 7 signal strengths are used for calculating the Euclidean distance. The predicted class (x-y coordinates separated by a hyphen) is classified by plurality votes from the selected k nearest neighbors.

### Multi-Target Regression  

A drawback for using a classification modeling technique for this dataset is that combinations of X and Y that are found in the test dataset, but not the training dataset, do not have the chance of being classified correctly. A classification model can only classify observations based on the classes available in the training dataset. The training dataset provided had all X and Y values rounded to the nearest integer. The test dataset had many unrounded values. This issue and the fact that there are 2 target variables (X and Y), lead us to research multi-target regression models.  

The pls package in R provides a multi-target Partial Least Squares Regression model.  Partial Least Squares decomposes a matrix of independent variables X and a matrix of target variables Y. While the number of optimal components could have been evaluated, for the problem here the model is forced to include all components (or variables). The ability to use a matrix Y is what is focused on.

More drawbacks to k-NN classification are discussed in Section 5.

### K-Fold Cross Validation  

Cross validation allows us to test our model on data it hasn't seen, to see how well the model performs when making predictions. Using cross validation can help identify if the model is overfitting the training data. When splitting data into training and test datasets there is a concern that important patterns found in the data may be left out of the training dataset. If these patterns are not present in the training dataset, the model won't be able to predict them in the test dataset. K-fold cross validation takes this into account by dividing the data into k folds. K-1 folds are used to train the model and the remaining fold is used for testing. This is repeated for k-1 models and every fold is used for testing once. This reduces bias and variance since we are essentially using the entire dataset for training and testing. We have chosen 5-folds for this project, a typical value chosen. This validation method will be applied to both k-NN classification and multi-target regression.

# Results

## k-NN Classification  

Accuracy is used as the evaluation metric for this classification problem. 

The textbook included mac address 00:0f:a3:39:e1:c0 and excluded 00:0f:a3:39:dd:cd. The reasoning found in the text indicates that these 2 have similar heat maps, indicating they are located close to one another. The first one (00:0f:a3:39:e1:c0) is chosen and 00:0f:a3:39:dd:cd is discarded. Our task was to determine if discarding 00:0f:a3:39:e1:c0 was the correct choice to make.

`Table 3` shows results from running k-NN with 5-fold cross validation for different numbers of nearest neighbors. Only odd values of K were run to ensure there are no issues with a tie. Also a value of one for k was not runm is to minimize the possibility of overfitting.  

Table 3: k-NN Classification Accuracies

| MAC Address | k=3 | k=5 | k=7| k=9 | k=11 | Selected K | Test Dataset Accuracy |
| - | - | - | - | - | - | - |
| Keep 00:0f:a3:39:e1:c0 | 71.99% | 71.81% | 71.02% | 70.03% | 69.08% | k=3 | 0.30% |
| Keep 00:0f:a3:39:dd:cd | 71.39% | 71.67% | 71.05% | 70.10% | 69.38% | k=5 | 0.69% |
| Keep all 7 | 75.58% | 75.57% | 74.69% | 73.78% | 72.80% | k=3 | 0.43% |

Keeping 00:0f:a3:39:e1:c0 turns out to be the better choice, when attempting to decide between 00:0f:a3:39:e1:c0 and 00:0f:a3:39:dd:cd. With k=3 an accuracy of 71.99% is achieved. 6 MAC addresses were chosen because of information provided about the dataset. However, using all MAC addresses and 3 neighbors achieves a higher accuracy of 75.58%. It would be advisable to discuss this finding with the data provider. If there are truly only 6 MAC addresses it would not be appropriate to use all 7. The models with the selected k values were used to predict the online (or test) dataset. Accuracies were extremely low. This is at least partially due to the decimal issue that was encountered with the online dataset where the X and Y coordinates had decimals (the offline dataset did not have decimals). 

## Multi-Target Regression

Accuracy as an evaluation metric isn't available for multi-target regression. A distance calculation is used instead. The distance calculation used for the multi-target regression model attempts to recreate a Euclidean distance. The formula is:

$$\frac{\sum_{i=1}^N\sqrt{Residuals_X^2 + Residuals_Y^2}}{N}$$

`Table 4` shows results from running multi-target regression with 5-fold cross validation. 

Table 4: Multi-Target Regression Mean Distance Error

| MAC Address | Training | Test |
| - | - | - | 
| Keep 00:0f:a3:39:e1:c0 | 1.68 | 3.42 |
| Keep 00:0f:a3:39:dd:cd | 1.86 | 3.22 |
| Keep all 7 | 2.61 | 3.20 |

The multi-target regression model with the lowest error was the model using 6 MAC addresses where 00:0f:a3:39:e1:c0 was included. The different evaluation metrics used for k-NN classification and multi-target regression make it impossible to evaluate a winning model between these 2 types of models. This same distance metric could be calculated for k-NN by separating out the predicted X and Y coordinates. This would allow for direct comparison.

```{r plots}
## This is a function to plot the actual vs predicted pairs, joining them with a line to easily see errors
## 100 sample points are used so as clearly see the errors.
## actual should be a two column data frame with columns "posX" and "posY"
## predicted should be a two column data frame with columns "posX" and "posY"
## sample is the number of pairs to display in the graph
## seed is used when sampling the data
## the function with return a ggplot object

plot_distances <- function(actual_orig, predicted_orig, sample = 100, seed = 314) {

  actual <- actual_orig
  predicted <- predicted_orig
  
  actual$name <- "actual"
  actual$obs <- seq(1,dim(actual)[1],1)
  predicted$name <- "predicted"
  predicted$obs <- seq(1,dim(predicted)[1],1)

  plot_data <- rbind(actual,predicted)
  set.seed(seed)
  sample_index <- sample(seq(1,length(actual$name),1),sample)
  plot_data_sample <- plot_data %>% filter(obs %in% sample_index)
  
  p <- ggplot(plot_data_sample,aes(x=posX,y=posY)) + geom_point(aes(color=name)) + geom_line(aes(group=obs))
  return(p)
}

p <- plot_distances(online_pivot_x_y[,c("posX","posY")],predict_df[,c("posX","posY")])

caption <- "Figure 1: This plot shows the differences between actual and predicted 
values for the multi-target regression model using 00:0f:a3:39:e1:c0. The model mostly predicts in the middle region,  
and the larger errors are associated with observations with high or low Y values."
caption <- paste0(strwrap(caption, 80), sep="", collapse="\n")

p + labs(title="Figure 1: Error Plot for Multi-Target Regression using 00:0f:a3:39:e1:c0", 
         caption= caption,
         colow = "Group") +
         xlab("X Position") +
         ylab("Y Position") +
  theme(plot.caption = element_text(hjust = 0, face= "italic"),
 #       plot.title.position = "plot",
        legend.title = element_blank()) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

# Drawbacks and Alternatives  

KNN has several drawbacks for predicting real time location. The model is not easily transferable without the training data, its speed decreases with more observations, and it could have difficulty with outliers.  

KNN predictions are made by comparing a point to its closest neighbors then determining its location by either voting or an average of its neighbors’ locations. This means you must have other data points to make a prediction. If the training set is large, it would need to be copied to every location where the model would need to be run. If it is running on a single server somewhere that might not be an issue, but if it is running on user’s cell phones that might make the transfer time consuming and the storage cost to the user might be prohibitive. 
Large training set sizes could also be an issue when it comes time to compute the prediction. The more observations in the training set, the more need to be searched through to find the nearest neighbors, increasing prediction time. The cost of this would be dependent on the use case. If it is merely observational, perhaps a few seconds difference might not matter. But it a decision needs to be made quickly based on location, then it could be a significant problem. For instance, if a robotic currier needed to decide where to turn based on its location, or trying to intercept an item moving through a storage facility.  

Finally, there could be issues with outliers or irregular spaces. A new data point far outside the space would be placed by the average of its three closest neighbors, which could be far away from its actual location. I think that would manifest itself as a “ghost”, where the system would say something was present when the signal was coming from outside the space. Depending on the sensors used, there might be some maximum distance the sensors can transmit which might mitigate this issue. Another issue might be when the nearest neighbors might place an object outside the space.  

A regression or random forest approach might solve the first two issues. These models are more portable in that they do not require the training data to make predictions and faster because they don’t need to search the training set for nearest neighbors. To address the outlier issue, we could limit our predictions based on the boundaries of the space. Any predictions outside the space are move to the nearest in-space location. We could potentially deal with outliers in preprocessing, perhaps looking for signal strengths that don’t make sense for the space.

# Conclusion
