{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn import datasets\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import shutil\n",
    "# # C:\\Users\\allro\\JupyterNotebook\\QTW\\Data\n",
    "# with gzip.open('C:\\\\Users\\\\allro\\\\JupyterNotebook\\\\QTW\\\\Data\\\\HIGGS.csv.gz', 'rb') as f_in:\n",
    "#    with open('C:\\\\Users\\\\allro\\\\JupyterNotebook\\\\QTW\\\\Data\\\\HIGGS.csv', 'wb') as f_out:\n",
    "#        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://archive.ics.uci.edu/ml/datasets/HIGGS#\n",
    "df = pd.read_csv(\"./Data/HIGGS.csv\", header=None)\n",
    "# df = pd.read_csv(\"../../HIGGS.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns =['target', 'lepton_ph', 'lepton_eta', 'lepton_phi','missing_energy_magnitude','missing_energy_phi',\n",
    "             'jet_1_pt','jet_1_eta','jet_1_phi','jet_1_btag','jet_2_pt','jet_2_eta','jet_2_phi','jet_2_btag',\n",
    "             'jet_3_pt','jet_3_eta','jet_3_phi','jet_3_btag','jet_4_pt','jet_4_eta','jet_4_phi','jet_4_btag',\n",
    "             'm_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000000 entries, 0 to 10999999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   target                    float64\n",
      " 1   lepton_ph                 float64\n",
      " 2   lepton_eta                float64\n",
      " 3   lepton_phi                float64\n",
      " 4   missing_energy_magnitude  float64\n",
      " 5   missing_energy_phi        float64\n",
      " 6   jet_1_pt                  float64\n",
      " 7   jet_1_eta                 float64\n",
      " 8   jet_1_phi                 float64\n",
      " 9   jet_1_btag                float64\n",
      " 10  jet_2_pt                  float64\n",
      " 11  jet_2_eta                 float64\n",
      " 12  jet_2_phi                 float64\n",
      " 13  jet_2_btag                float64\n",
      " 14  jet_3_pt                  float64\n",
      " 15  jet_3_eta                 float64\n",
      " 16  jet_3_phi                 float64\n",
      " 17  jet_3_btag                float64\n",
      " 18  jet_4_pt                  float64\n",
      " 19  jet_4_eta                 float64\n",
      " 20  jet_4_phi                 float64\n",
      " 21  jet_4_btag                float64\n",
      " 22  m_jj                      float64\n",
      " 23  m_jjj                     float64\n",
      " 24  m_lv                      float64\n",
      " 25  m_jlv                     float64\n",
      " 26  m_bb                      float64\n",
      " 27  m_wbb                     float64\n",
      " 28  m_wwbb                    float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 2.4 GB\n"
     ]
    }
   ],
   "source": [
    "# Print out the data types\n",
    "df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  lepton_ph  lepton_eta  lepton_phi  missing_energy_magnitude  \\\n",
       "0     1.0   0.869293   -0.635082    0.225690                  0.327470   \n",
       "1     1.0   0.907542    0.329147    0.359412                  1.497970   \n",
       "2     1.0   0.798835    1.470639   -1.635975                  0.453773   \n",
       "3     0.0   1.344385   -0.876626    0.935913                  1.992050   \n",
       "4     1.0   1.105009    0.321356    1.522401                  0.882808   \n",
       "\n",
       "   missing_energy_phi  jet_1_pt  jet_1_eta  jet_1_phi  jet_1_btag  ...  \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064    0.000000  ...   \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230    2.173076  ...   \n",
       "2            0.425629  1.104875   1.282322   1.381664    0.000000  ...   \n",
       "3            0.882454  1.786066  -1.646778  -0.942383    0.000000  ...   \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871    0.000000  ...   \n",
       "\n",
       "   jet_4_eta  jet_4_phi  jet_4_btag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
       "0  -0.010455  -0.045767    3.101961  1.353760  0.979563  0.978076  0.920005   \n",
       "1  -1.138930  -0.000819    0.000000  0.302220  0.833048  0.985700  0.978098   \n",
       "2   1.128848   0.900461    0.000000  0.909753  1.108330  0.985692  0.951331   \n",
       "3  -0.678379  -1.360356    0.000000  0.946652  1.028704  0.998656  0.728281   \n",
       "4  -0.373566   0.113041    0.000000  0.755856  1.361057  0.986610  0.838085   \n",
       "\n",
       "       m_bb     m_wbb    m_wwbb  \n",
       "0  0.721657  0.988751  0.876678  \n",
       "1  0.779732  0.992356  0.798343  \n",
       "2  0.803252  0.865924  0.780118  \n",
       "3  0.869200  1.026736  0.957904  \n",
       "4  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsample the data\n",
    "train = df.sample(n=2600000, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>jet_2_pt</th>\n",
       "      <th>jet_2_eta</th>\n",
       "      <th>jet_2_phi</th>\n",
       "      <th>jet_2_btag</th>\n",
       "      <th>jet_3_pt</th>\n",
       "      <th>jet_3_eta</th>\n",
       "      <th>jet_3_phi</th>\n",
       "      <th>jet_3_btag</th>\n",
       "      <th>jet_4_pt</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.299203e-01</td>\n",
       "      <td>9.914658e-01</td>\n",
       "      <td>-8.297618e-06</td>\n",
       "      <td>-1.327225e-05</td>\n",
       "      <td>9.985364e-01</td>\n",
       "      <td>2.613459e-05</td>\n",
       "      <td>9.909152e-01</td>\n",
       "      <td>-2.027520e-05</td>\n",
       "      <td>7.716199e-06</td>\n",
       "      <td>9.999687e-01</td>\n",
       "      <td>9.927294e-01</td>\n",
       "      <td>-1.026444e-05</td>\n",
       "      <td>-2.076887e-05</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>9.922591e-01</td>\n",
       "      <td>1.459561e-05</td>\n",
       "      <td>3.678632e-06</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>9.861087e-01</td>\n",
       "      <td>-5.756954e-06</td>\n",
       "      <td>1.744903e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.034290e+00</td>\n",
       "      <td>1.024805e+00</td>\n",
       "      <td>1.050554e+00</td>\n",
       "      <td>1.009742e+00</td>\n",
       "      <td>9.729596e-01</td>\n",
       "      <td>1.033036e+00</td>\n",
       "      <td>9.598120e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.991040e-01</td>\n",
       "      <td>5.653777e-01</td>\n",
       "      <td>1.008827e+00</td>\n",
       "      <td>1.006346e+00</td>\n",
       "      <td>6.000185e-01</td>\n",
       "      <td>1.006326e+00</td>\n",
       "      <td>4.749747e-01</td>\n",
       "      <td>1.009303e+00</td>\n",
       "      <td>1.005901e+00</td>\n",
       "      <td>1.027808e+00</td>\n",
       "      <td>4.999939e-01</td>\n",
       "      <td>1.009331e+00</td>\n",
       "      <td>1.006154e+00</td>\n",
       "      <td>1.049398e+00</td>\n",
       "      <td>4.876623e-01</td>\n",
       "      <td>1.008747e+00</td>\n",
       "      <td>1.006305e+00</td>\n",
       "      <td>1.193676e+00</td>\n",
       "      <td>5.057777e-01</td>\n",
       "      <td>1.007694e+00</td>\n",
       "      <td>1.006366e+00</td>\n",
       "      <td>1.400209e+00</td>\n",
       "      <td>6.746354e-01</td>\n",
       "      <td>3.808074e-01</td>\n",
       "      <td>1.645763e-01</td>\n",
       "      <td>3.974453e-01</td>\n",
       "      <td>5.254063e-01</td>\n",
       "      <td>3.652556e-01</td>\n",
       "      <td>3.133378e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.746966e-01</td>\n",
       "      <td>-2.434976e+00</td>\n",
       "      <td>-1.742508e+00</td>\n",
       "      <td>2.370088e-04</td>\n",
       "      <td>-1.743944e+00</td>\n",
       "      <td>1.375024e-01</td>\n",
       "      <td>-2.969725e+00</td>\n",
       "      <td>-1.741237e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.889811e-01</td>\n",
       "      <td>-2.913090e+00</td>\n",
       "      <td>-1.742372e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.636076e-01</td>\n",
       "      <td>-2.729663e+00</td>\n",
       "      <td>-1.742069e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.653542e-01</td>\n",
       "      <td>-2.497265e+00</td>\n",
       "      <td>-1.742691e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.507046e-02</td>\n",
       "      <td>1.986757e-01</td>\n",
       "      <td>8.304866e-02</td>\n",
       "      <td>1.320062e-01</td>\n",
       "      <td>4.786215e-02</td>\n",
       "      <td>2.951122e-01</td>\n",
       "      <td>3.307214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.907533e-01</td>\n",
       "      <td>-7.383225e-01</td>\n",
       "      <td>-8.719308e-01</td>\n",
       "      <td>5.768156e-01</td>\n",
       "      <td>-8.712081e-01</td>\n",
       "      <td>6.789927e-01</td>\n",
       "      <td>-6.872450e-01</td>\n",
       "      <td>-8.680962e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.564608e-01</td>\n",
       "      <td>-6.944718e-01</td>\n",
       "      <td>-8.701791e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.508527e-01</td>\n",
       "      <td>-6.998083e-01</td>\n",
       "      <td>-8.711343e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.177673e-01</td>\n",
       "      <td>-7.141902e-01</td>\n",
       "      <td>-8.714789e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.906095e-01</td>\n",
       "      <td>8.462266e-01</td>\n",
       "      <td>9.857525e-01</td>\n",
       "      <td>7.675732e-01</td>\n",
       "      <td>6.738168e-01</td>\n",
       "      <td>8.193964e-01</td>\n",
       "      <td>7.703901e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.533714e-01</td>\n",
       "      <td>-5.415563e-05</td>\n",
       "      <td>-2.410638e-04</td>\n",
       "      <td>8.916277e-01</td>\n",
       "      <td>2.125454e-04</td>\n",
       "      <td>8.948193e-01</td>\n",
       "      <td>-2.543566e-05</td>\n",
       "      <td>5.813991e-05</td>\n",
       "      <td>1.086538e+00</td>\n",
       "      <td>8.901377e-01</td>\n",
       "      <td>6.027267e-05</td>\n",
       "      <td>3.514990e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.972494e-01</td>\n",
       "      <td>1.728937e-04</td>\n",
       "      <td>-7.519117e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.682333e-01</td>\n",
       "      <td>3.721330e-04</td>\n",
       "      <td>-2.642369e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.949304e-01</td>\n",
       "      <td>9.506853e-01</td>\n",
       "      <td>9.897798e-01</td>\n",
       "      <td>9.165110e-01</td>\n",
       "      <td>8.733798e-01</td>\n",
       "      <td>9.473447e-01</td>\n",
       "      <td>8.719701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.236226e+00</td>\n",
       "      <td>7.382142e-01</td>\n",
       "      <td>8.709940e-01</td>\n",
       "      <td>1.293056e+00</td>\n",
       "      <td>8.714708e-01</td>\n",
       "      <td>1.170740e+00</td>\n",
       "      <td>6.871941e-01</td>\n",
       "      <td>8.683126e-01</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>1.201875e+00</td>\n",
       "      <td>6.945924e-01</td>\n",
       "      <td>8.698727e-01</td>\n",
       "      <td>2.214872e+00</td>\n",
       "      <td>1.221798e+00</td>\n",
       "      <td>7.001541e-01</td>\n",
       "      <td>8.713947e-01</td>\n",
       "      <td>2.548224e+00</td>\n",
       "      <td>1.220930e+00</td>\n",
       "      <td>7.141017e-01</td>\n",
       "      <td>8.716055e-01</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>1.024730e+00</td>\n",
       "      <td>1.083493e+00</td>\n",
       "      <td>1.020528e+00</td>\n",
       "      <td>1.142226e+00</td>\n",
       "      <td>1.138439e+00</td>\n",
       "      <td>1.140458e+00</td>\n",
       "      <td>1.059248e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.209891e+01</td>\n",
       "      <td>2.434868e+00</td>\n",
       "      <td>1.743236e+00</td>\n",
       "      <td>1.539682e+01</td>\n",
       "      <td>1.743257e+00</td>\n",
       "      <td>9.940391e+00</td>\n",
       "      <td>2.969674e+00</td>\n",
       "      <td>1.741454e+00</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>1.164708e+01</td>\n",
       "      <td>2.913210e+00</td>\n",
       "      <td>1.743175e+00</td>\n",
       "      <td>2.214872e+00</td>\n",
       "      <td>1.470899e+01</td>\n",
       "      <td>2.730009e+00</td>\n",
       "      <td>1.742884e+00</td>\n",
       "      <td>2.548224e+00</td>\n",
       "      <td>1.288257e+01</td>\n",
       "      <td>2.498009e+00</td>\n",
       "      <td>1.743372e+00</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>4.019237e+01</td>\n",
       "      <td>2.037278e+01</td>\n",
       "      <td>7.992739e+00</td>\n",
       "      <td>1.426244e+01</td>\n",
       "      <td>1.776285e+01</td>\n",
       "      <td>1.149652e+01</td>\n",
       "      <td>8.374498e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target     lepton_ph    lepton_eta    lepton_phi  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   5.299203e-01  9.914658e-01 -8.297618e-06 -1.327225e-05   \n",
       "std    4.991040e-01  5.653777e-01  1.008827e+00  1.006346e+00   \n",
       "min    0.000000e+00  2.746966e-01 -2.434976e+00 -1.742508e+00   \n",
       "25%    0.000000e+00  5.907533e-01 -7.383225e-01 -8.719308e-01   \n",
       "50%    1.000000e+00  8.533714e-01 -5.415563e-05 -2.410638e-04   \n",
       "75%    1.000000e+00  1.236226e+00  7.382142e-01  8.709940e-01   \n",
       "max    1.000000e+00  1.209891e+01  2.434868e+00  1.743236e+00   \n",
       "\n",
       "       missing_energy_magnitude  missing_energy_phi      jet_1_pt  \\\n",
       "count              1.100000e+07        1.100000e+07  1.100000e+07   \n",
       "mean               9.985364e-01        2.613459e-05  9.909152e-01   \n",
       "std                6.000185e-01        1.006326e+00  4.749747e-01   \n",
       "min                2.370088e-04       -1.743944e+00  1.375024e-01   \n",
       "25%                5.768156e-01       -8.712081e-01  6.789927e-01   \n",
       "50%                8.916277e-01        2.125454e-04  8.948193e-01   \n",
       "75%                1.293056e+00        8.714708e-01  1.170740e+00   \n",
       "max                1.539682e+01        1.743257e+00  9.940391e+00   \n",
       "\n",
       "          jet_1_eta     jet_1_phi    jet_1_btag      jet_2_pt     jet_2_eta  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean  -2.027520e-05  7.716199e-06  9.999687e-01  9.927294e-01 -1.026444e-05   \n",
       "std    1.009303e+00  1.005901e+00  1.027808e+00  4.999939e-01  1.009331e+00   \n",
       "min   -2.969725e+00 -1.741237e+00  0.000000e+00  1.889811e-01 -2.913090e+00   \n",
       "25%   -6.872450e-01 -8.680962e-01  0.000000e+00  6.564608e-01 -6.944718e-01   \n",
       "50%   -2.543566e-05  5.813991e-05  1.086538e+00  8.901377e-01  6.027267e-05   \n",
       "75%    6.871941e-01  8.683126e-01  2.173076e+00  1.201875e+00  6.945924e-01   \n",
       "max    2.969674e+00  1.741454e+00  2.173076e+00  1.164708e+01  2.913210e+00   \n",
       "\n",
       "          jet_2_phi    jet_2_btag      jet_3_pt     jet_3_eta     jet_3_phi  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean  -2.076887e-05  1.000008e+00  9.922591e-01  1.459561e-05  3.678632e-06   \n",
       "std    1.006154e+00  1.049398e+00  4.876623e-01  1.008747e+00  1.006305e+00   \n",
       "min   -1.742372e+00  0.000000e+00  2.636076e-01 -2.729663e+00 -1.742069e+00   \n",
       "25%   -8.701791e-01  0.000000e+00  6.508527e-01 -6.998083e-01 -8.711343e-01   \n",
       "50%    3.514990e-04  0.000000e+00  8.972494e-01  1.728937e-04 -7.519117e-04   \n",
       "75%    8.698727e-01  2.214872e+00  1.221798e+00  7.001541e-01  8.713947e-01   \n",
       "max    1.743175e+00  2.214872e+00  1.470899e+01  2.730009e+00  1.742884e+00   \n",
       "\n",
       "         jet_3_btag      jet_4_pt     jet_4_eta     jet_4_phi    jet_4_btag  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   1.000011e+00  9.861087e-01 -5.756954e-06  1.744903e-05  1.000000e+00   \n",
       "std    1.193676e+00  5.057777e-01  1.007694e+00  1.006366e+00  1.400209e+00   \n",
       "min    0.000000e+00  3.653542e-01 -2.497265e+00 -1.742691e+00  0.000000e+00   \n",
       "25%    0.000000e+00  6.177673e-01 -7.141902e-01 -8.714789e-01  0.000000e+00   \n",
       "50%    0.000000e+00  8.682333e-01  3.721330e-04 -2.642369e-04  0.000000e+00   \n",
       "75%    2.548224e+00  1.220930e+00  7.141017e-01  8.716055e-01  3.101961e+00   \n",
       "max    2.548224e+00  1.288257e+01  2.498009e+00  1.743372e+00  3.101961e+00   \n",
       "\n",
       "               m_jj         m_jjj          m_lv         m_jlv          m_bb  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   1.034290e+00  1.024805e+00  1.050554e+00  1.009742e+00  9.729596e-01   \n",
       "std    6.746354e-01  3.808074e-01  1.645763e-01  3.974453e-01  5.254063e-01   \n",
       "min    7.507046e-02  1.986757e-01  8.304866e-02  1.320062e-01  4.786215e-02   \n",
       "25%    7.906095e-01  8.462266e-01  9.857525e-01  7.675732e-01  6.738168e-01   \n",
       "50%    8.949304e-01  9.506853e-01  9.897798e-01  9.165110e-01  8.733798e-01   \n",
       "75%    1.024730e+00  1.083493e+00  1.020528e+00  1.142226e+00  1.138439e+00   \n",
       "max    4.019237e+01  2.037278e+01  7.992739e+00  1.426244e+01  1.776285e+01   \n",
       "\n",
       "              m_wbb        m_wwbb  \n",
       "count  1.100000e+07  1.100000e+07  \n",
       "mean   1.033036e+00  9.598120e-01  \n",
       "std    3.652556e-01  3.133378e-01  \n",
       "min    2.951122e-01  3.307214e-01  \n",
       "25%    8.193964e-01  7.703901e-01  \n",
       "50%    9.473447e-01  8.719701e-01  \n",
       "75%    1.140458e+00  1.059248e+00  \n",
       "max    1.149652e+01  8.374498e+00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figure out which columns have values strictly greater than 0, for scaler purposes\n",
    "pd.set_option(\"display.max_rows\", 500, \"display.max_columns\", None)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600000, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "pre_X = train.loc[:, df.columns != 'target']\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_train = scaler.fit_transform(pre_X)\n",
    "# X = pd.DataFrame(data=scaled_train, columns=pre_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_2_pt</th>\n",
       "      <th>jet_4_pt</th>\n",
       "      <th>jet_3_pt</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.695209e-01</td>\n",
       "      <td>-6.625666e-01</td>\n",
       "      <td>-7.968404e-01</td>\n",
       "      <td>-6.073939e-01</td>\n",
       "      <td>-2.264619e-01</td>\n",
       "      <td>-4.952153e-01</td>\n",
       "      <td>-4.221755e-01</td>\n",
       "      <td>-1.084725e+00</td>\n",
       "      <td>-4.670169e+00</td>\n",
       "      <td>-9.966000e-01</td>\n",
       "      <td>-7.556114e-01</td>\n",
       "      <td>-9.412959e-01</td>\n",
       "      <td>-9.336352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.906835e-01</td>\n",
       "      <td>2.969626e-01</td>\n",
       "      <td>3.428450e-01</td>\n",
       "      <td>3.272016e-01</td>\n",
       "      <td>2.719195e-01</td>\n",
       "      <td>2.992355e-01</td>\n",
       "      <td>6.380529e-01</td>\n",
       "      <td>5.307856e-01</td>\n",
       "      <td>6.057191e-01</td>\n",
       "      <td>3.903798e-01</td>\n",
       "      <td>4.299310e-01</td>\n",
       "      <td>4.150297e-01</td>\n",
       "      <td>3.953860e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.556306e-01</td>\n",
       "      <td>8.220505e-01</td>\n",
       "      <td>7.978708e-01</td>\n",
       "      <td>7.947510e-01</td>\n",
       "      <td>7.664560e-01</td>\n",
       "      <td>8.050897e-01</td>\n",
       "      <td>7.926677e-01</td>\n",
       "      <td>8.047199e-01</td>\n",
       "      <td>6.301876e-01</td>\n",
       "      <td>7.658091e-01</td>\n",
       "      <td>8.108293e-01</td>\n",
       "      <td>7.650499e-01</td>\n",
       "      <td>7.195430e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.432801e+00</td>\n",
       "      <td>1.489800e+00</td>\n",
       "      <td>1.378221e+00</td>\n",
       "      <td>1.418066e+00</td>\n",
       "      <td>1.464286e+00</td>\n",
       "      <td>1.471996e+00</td>\n",
       "      <td>9.855056e-01</td>\n",
       "      <td>1.154184e+00</td>\n",
       "      <td>8.183915e-01</td>\n",
       "      <td>1.333369e+00</td>\n",
       "      <td>1.315954e+00</td>\n",
       "      <td>1.293396e+00</td>\n",
       "      <td>1.316636e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.991209e+01</td>\n",
       "      <td>2.073755e+01</td>\n",
       "      <td>1.696594e+01</td>\n",
       "      <td>1.894311e+01</td>\n",
       "      <td>2.448835e+01</td>\n",
       "      <td>2.914014e+01</td>\n",
       "      <td>4.321080e+01</td>\n",
       "      <td>3.756345e+01</td>\n",
       "      <td>3.609834e+01</td>\n",
       "      <td>2.720432e+01</td>\n",
       "      <td>2.530246e+01</td>\n",
       "      <td>2.221914e+01</td>\n",
       "      <td>1.902509e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lepton_ph  missing_energy_magnitude      jet_1_pt      jet_2_pt  \\\n",
       "count  2.600000e+06              2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean   1.000000e+00              1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "std    1.000000e+00              1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.695209e-01             -6.625666e-01 -7.968404e-01 -6.073939e-01   \n",
       "25%    2.906835e-01              2.969626e-01  3.428450e-01  3.272016e-01   \n",
       "50%    7.556306e-01              8.220505e-01  7.978708e-01  7.947510e-01   \n",
       "75%    1.432801e+00              1.489800e+00  1.378221e+00  1.418066e+00   \n",
       "max    1.991209e+01              2.073755e+01  1.696594e+01  1.894311e+01   \n",
       "\n",
       "           jet_4_pt      jet_3_pt          m_jj         m_jjj          m_lv  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.264619e-01 -4.952153e-01 -4.221755e-01 -1.084725e+00 -4.670169e+00   \n",
       "25%    2.719195e-01  2.992355e-01  6.380529e-01  5.307856e-01  6.057191e-01   \n",
       "50%    7.664560e-01  8.050897e-01  7.926677e-01  8.047199e-01  6.301876e-01   \n",
       "75%    1.464286e+00  1.471996e+00  9.855056e-01  1.154184e+00  8.183915e-01   \n",
       "max    2.448835e+01  2.914014e+01  4.321080e+01  3.756345e+01  3.609834e+01   \n",
       "\n",
       "              m_jlv          m_bb         m_wbb        m_wwbb  \n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  \n",
       "mean   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -9.966000e-01 -7.556114e-01 -9.412959e-01 -9.336352e-01  \n",
       "25%    3.903798e-01  4.299310e-01  4.150297e-01  3.953860e-01  \n",
       "50%    7.658091e-01  8.108293e-01  7.650499e-01  7.195430e-01  \n",
       "75%    1.333369e+00  1.315954e+00  1.293396e+00  1.316636e+00  \n",
       "max    2.720432e+01  2.530246e+01  2.221914e+01  1.902509e+01  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not complete, need columns where mean=1 and stdev=1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#NOT strictly greater than 0 columns:\n",
    "not_greater_than_0 = ['lepton_eta','lepton_phi','missing_energy_phi','jet_1_eta','jet_1_phi','jet_1_btag',\n",
    "                      'jet_2_eta','jet_2_phi','jet_2_btag','jet_3_eta','jet_3_phi','jet_3_btag','jet_4_eta',\n",
    "                      'jet_4_phi','jet_4_btag']\n",
    "\n",
    "#strictly greater than 0 columns:\n",
    "greater_than_0 = ['lepton_ph','missing_energy_magnitude','jet_1_pt','jet_2_pt','jet_4_pt','jet_3_pt','m_jj','m_jjj','m_lv',\n",
    "                  'm_jlv','m_bb','m_wbb','m_wwbb']\n",
    "\n",
    "\n",
    "#these columns scale where mean=0 and stdev=1\n",
    "to_scale1 = pre_X[not_greater_than_0]\n",
    "scaler = StandardScaler()\n",
    "scaled_train1 = scaler.fit_transform(to_scale1)\n",
    "scaled_train_df1 = pd.DataFrame(scaled_train1, columns=not_greater_than_0)\n",
    "\n",
    "#these columns scale where mean=1 and stdev=1\n",
    "to_scale2 = pre_X[greater_than_0]\n",
    "scaler = StandardScaler()\n",
    "scaled_train2 = scaler.fit_transform(to_scale2)\n",
    "scaled_train_df2 = pd.DataFrame(scaled_train2 + 1, columns=greater_than_0)\n",
    "scaled_train_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600000, 13)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled_train2 + 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_X[greater_than_0].to_numpy().shape\n",
    "\n",
    "# np_greater_than_0 = pre_X[greater_than_0].to_numpy()\n",
    "\n",
    "def manual_scaling(x, desired_mean=0, desired_std=1):\n",
    "    new_x = np.empty(x.shape)\n",
    "    for i in range(x.shape[1]):\n",
    "        mean = np.mean(x[:, i])\n",
    "        std = np.std(x[:, i])\n",
    "        new_x[:, i] = desired_mean + (x[:, i] - mean) * (desired_std / std)\n",
    "    return new_x\n",
    "\n",
    "np_greater_than_0 = manual_scaling(pre_X[greater_than_0].to_numpy(), desired_mean=1, desired_std=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.175,  0.16 , -0.132, ...,  1.105,  1.272,  0.858],\n",
       "       [ 0.51 ,  4.281,  1.223, ...,  0.709,  1.38 ,  1.777],\n",
       "       [-0.131,  0.97 ,  0.063, ...,  0.414,  0.217,  0.345],\n",
       "       ...,\n",
       "       [ 0.141,  0.259,  1.578, ...,  0.017,  1.233,  0.923],\n",
       "       [ 1.813,  0.645,  1.675, ...,  1.379,  1.363,  1.836],\n",
       "       [ 0.164,  0.846,  1.208, ...,  1.776,  0.987,  0.697]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((np_greater_than_0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.175,  0.16 , -0.132, ...,  1.105,  1.272,  0.858],\n",
       "       [ 0.51 ,  4.281,  1.223, ...,  0.709,  1.38 ,  1.777],\n",
       "       [-0.131,  0.97 ,  0.063, ...,  0.414,  0.217,  0.345],\n",
       "       ...,\n",
       "       [ 0.141,  0.259,  1.578, ...,  0.017,  1.233,  0.923],\n",
       "       [ 1.813,  0.645,  1.675, ...,  1.379,  1.363,  1.836],\n",
       "       [ 0.164,  0.846,  1.208, ...,  1.776,  0.987,  0.697]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((scaled_train2 + 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "are_they_the_same = np.round((np_greater_than_0), 3) == np.round((scaled_train2 + 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2600000, 2600000, 2600000, 2600000, 2600000, 2600000, 2600000,\n",
       "       2600000, 2600000, 2600000, 2600000, 2600000, 2600000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(are_they_the_same == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>jet_2_eta</th>\n",
       "      <th>jet_2_phi</th>\n",
       "      <th>jet_2_btag</th>\n",
       "      <th>jet_3_eta</th>\n",
       "      <th>jet_3_phi</th>\n",
       "      <th>jet_3_btag</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_2_pt</th>\n",
       "      <th>jet_4_pt</th>\n",
       "      <th>jet_3_pt</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.322691</td>\n",
       "      <td>0.863880</td>\n",
       "      <td>-0.572453</td>\n",
       "      <td>-2.141693</td>\n",
       "      <td>-0.523203</td>\n",
       "      <td>-0.972454</td>\n",
       "      <td>1.723081</td>\n",
       "      <td>-1.709792</td>\n",
       "      <td>-0.952660</td>\n",
       "      <td>0.025451</td>\n",
       "      <td>1.289919</td>\n",
       "      <td>1.296983</td>\n",
       "      <td>-0.002654</td>\n",
       "      <td>-0.786827</td>\n",
       "      <td>-0.714619</td>\n",
       "      <td>1.174569</td>\n",
       "      <td>0.160122</td>\n",
       "      <td>-0.132040</td>\n",
       "      <td>0.571042</td>\n",
       "      <td>0.458873</td>\n",
       "      <td>0.872105</td>\n",
       "      <td>0.537537</td>\n",
       "      <td>1.043547</td>\n",
       "      <td>0.613459</td>\n",
       "      <td>0.855754</td>\n",
       "      <td>1.105013</td>\n",
       "      <td>1.271511</td>\n",
       "      <td>0.857620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.416089</td>\n",
       "      <td>0.695152</td>\n",
       "      <td>0.802544</td>\n",
       "      <td>-0.470049</td>\n",
       "      <td>-0.668134</td>\n",
       "      <td>-0.972454</td>\n",
       "      <td>-0.789944</td>\n",
       "      <td>-1.505140</td>\n",
       "      <td>1.158021</td>\n",
       "      <td>0.802190</td>\n",
       "      <td>-0.192560</td>\n",
       "      <td>-0.837770</td>\n",
       "      <td>0.480915</td>\n",
       "      <td>1.476132</td>\n",
       "      <td>-0.714619</td>\n",
       "      <td>0.509711</td>\n",
       "      <td>4.281044</td>\n",
       "      <td>1.223397</td>\n",
       "      <td>2.620156</td>\n",
       "      <td>1.344617</td>\n",
       "      <td>2.941280</td>\n",
       "      <td>0.587525</td>\n",
       "      <td>0.553713</td>\n",
       "      <td>0.652878</td>\n",
       "      <td>2.778725</td>\n",
       "      <td>0.708706</td>\n",
       "      <td>1.379553</td>\n",
       "      <td>1.777043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.014625</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>-1.239583</td>\n",
       "      <td>1.129981</td>\n",
       "      <td>-1.392778</td>\n",
       "      <td>-0.972454</td>\n",
       "      <td>0.016302</td>\n",
       "      <td>1.064422</td>\n",
       "      <td>-0.952660</td>\n",
       "      <td>-0.055741</td>\n",
       "      <td>-0.050936</td>\n",
       "      <td>1.296983</td>\n",
       "      <td>2.108518</td>\n",
       "      <td>-0.857386</td>\n",
       "      <td>-0.714619</td>\n",
       "      <td>-0.131495</td>\n",
       "      <td>0.969540</td>\n",
       "      <td>0.063081</td>\n",
       "      <td>1.850889</td>\n",
       "      <td>1.313378</td>\n",
       "      <td>2.026490</td>\n",
       "      <td>0.902127</td>\n",
       "      <td>1.344002</td>\n",
       "      <td>0.611636</td>\n",
       "      <td>0.129997</td>\n",
       "      <td>0.414243</td>\n",
       "      <td>0.217026</td>\n",
       "      <td>0.345026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.836948</td>\n",
       "      <td>-1.475806</td>\n",
       "      <td>0.854693</td>\n",
       "      <td>2.403334</td>\n",
       "      <td>-1.289730</td>\n",
       "      <td>-0.972454</td>\n",
       "      <td>0.352078</td>\n",
       "      <td>0.411301</td>\n",
       "      <td>1.158021</td>\n",
       "      <td>-0.669193</td>\n",
       "      <td>0.629738</td>\n",
       "      <td>-0.837770</td>\n",
       "      <td>0.763617</td>\n",
       "      <td>-0.477577</td>\n",
       "      <td>1.500372</td>\n",
       "      <td>0.974982</td>\n",
       "      <td>-0.110502</td>\n",
       "      <td>0.356920</td>\n",
       "      <td>0.772858</td>\n",
       "      <td>2.591291</td>\n",
       "      <td>1.104855</td>\n",
       "      <td>0.865492</td>\n",
       "      <td>1.335313</td>\n",
       "      <td>0.656397</td>\n",
       "      <td>1.385766</td>\n",
       "      <td>0.819796</td>\n",
       "      <td>1.213709</td>\n",
       "      <td>0.937928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.177572</td>\n",
       "      <td>0.531387</td>\n",
       "      <td>-1.002016</td>\n",
       "      <td>0.825868</td>\n",
       "      <td>0.737725</td>\n",
       "      <td>-0.972454</td>\n",
       "      <td>1.490251</td>\n",
       "      <td>-0.738936</td>\n",
       "      <td>-0.952660</td>\n",
       "      <td>-0.136933</td>\n",
       "      <td>1.334005</td>\n",
       "      <td>1.296983</td>\n",
       "      <td>1.046319</td>\n",
       "      <td>-0.080681</td>\n",
       "      <td>0.392877</td>\n",
       "      <td>-0.051790</td>\n",
       "      <td>2.577822</td>\n",
       "      <td>0.874030</td>\n",
       "      <td>0.138219</td>\n",
       "      <td>1.611349</td>\n",
       "      <td>0.954612</td>\n",
       "      <td>0.795040</td>\n",
       "      <td>1.126510</td>\n",
       "      <td>1.901067</td>\n",
       "      <td>2.499051</td>\n",
       "      <td>1.154495</td>\n",
       "      <td>1.196558</td>\n",
       "      <td>1.717747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lepton_eta  lepton_phi  missing_energy_phi  jet_1_eta  jet_1_phi  \\\n",
       "0   -0.322691    0.863880           -0.572453  -2.141693  -0.523203   \n",
       "1    0.416089    0.695152            0.802544  -0.470049  -0.668134   \n",
       "2   -0.014625    0.186212           -1.239583   1.129981  -1.392778   \n",
       "3   -1.836948   -1.475806            0.854693   2.403334  -1.289730   \n",
       "4    2.177572    0.531387           -1.002016   0.825868   0.737725   \n",
       "\n",
       "   jet_1_btag  jet_2_eta  jet_2_phi  jet_2_btag  jet_3_eta  jet_3_phi  \\\n",
       "0   -0.972454   1.723081  -1.709792   -0.952660   0.025451   1.289919   \n",
       "1   -0.972454  -0.789944  -1.505140    1.158021   0.802190  -0.192560   \n",
       "2   -0.972454   0.016302   1.064422   -0.952660  -0.055741  -0.050936   \n",
       "3   -0.972454   0.352078   0.411301    1.158021  -0.669193   0.629738   \n",
       "4   -0.972454   1.490251  -0.738936   -0.952660  -0.136933   1.334005   \n",
       "\n",
       "   jet_3_btag  jet_4_eta  jet_4_phi  jet_4_btag  lepton_ph  \\\n",
       "0    1.296983  -0.002654  -0.786827   -0.714619   1.174569   \n",
       "1   -0.837770   0.480915   1.476132   -0.714619   0.509711   \n",
       "2    1.296983   2.108518  -0.857386   -0.714619  -0.131495   \n",
       "3   -0.837770   0.763617  -0.477577    1.500372   0.974982   \n",
       "4    1.296983   1.046319  -0.080681    0.392877  -0.051790   \n",
       "\n",
       "   missing_energy_magnitude  jet_1_pt  jet_2_pt  jet_4_pt  jet_3_pt      m_jj  \\\n",
       "0                  0.160122 -0.132040  0.571042  0.458873  0.872105  0.537537   \n",
       "1                  4.281044  1.223397  2.620156  1.344617  2.941280  0.587525   \n",
       "2                  0.969540  0.063081  1.850889  1.313378  2.026490  0.902127   \n",
       "3                 -0.110502  0.356920  0.772858  2.591291  1.104855  0.865492   \n",
       "4                  2.577822  0.874030  0.138219  1.611349  0.954612  0.795040   \n",
       "\n",
       "      m_jjj      m_lv     m_jlv      m_bb     m_wbb    m_wwbb  \n",
       "0  1.043547  0.613459  0.855754  1.105013  1.271511  0.857620  \n",
       "1  0.553713  0.652878  2.778725  0.708706  1.379553  1.777043  \n",
       "2  1.344002  0.611636  0.129997  0.414243  0.217026  0.345026  \n",
       "3  1.335313  0.656397  1.385766  0.819796  1.213709  0.937928  \n",
       "4  1.126510  1.901067  2.499051  1.154495  1.196558  1.717747  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([scaled_train_df1, scaled_train_df2], axis=1, sort=False)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=500000, random_state=1776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y_train.to_numpy()\n",
    "# type(np.unique(y)[0])\n",
    "\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100000, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>jet_2_eta</th>\n",
       "      <th>jet_2_phi</th>\n",
       "      <th>jet_2_btag</th>\n",
       "      <th>jet_3_eta</th>\n",
       "      <th>jet_3_phi</th>\n",
       "      <th>jet_3_btag</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_2_pt</th>\n",
       "      <th>jet_4_pt</th>\n",
       "      <th>jet_3_pt</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.470954e-18</td>\n",
       "      <td>1.700110e-17</td>\n",
       "      <td>-2.381958e-17</td>\n",
       "      <td>-9.263701e-18</td>\n",
       "      <td>-3.566378e-17</td>\n",
       "      <td>7.213785e-17</td>\n",
       "      <td>-1.918192e-17</td>\n",
       "      <td>-1.036573e-17</td>\n",
       "      <td>3.512711e-17</td>\n",
       "      <td>7.341819e-18</td>\n",
       "      <td>2.970888e-17</td>\n",
       "      <td>-1.521518e-17</td>\n",
       "      <td>-1.473556e-17</td>\n",
       "      <td>2.121790e-17</td>\n",
       "      <td>1.082293e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.414452e+00</td>\n",
       "      <td>-1.731104e+00</td>\n",
       "      <td>-1.731925e+00</td>\n",
       "      <td>-2.942199e+00</td>\n",
       "      <td>-1.730027e+00</td>\n",
       "      <td>-9.724543e-01</td>\n",
       "      <td>-2.885415e+00</td>\n",
       "      <td>-1.732408e+00</td>\n",
       "      <td>-9.526596e-01</td>\n",
       "      <td>-2.705312e+00</td>\n",
       "      <td>-1.730599e+00</td>\n",
       "      <td>-8.377697e-01</td>\n",
       "      <td>-2.479189e+00</td>\n",
       "      <td>-1.731107e+00</td>\n",
       "      <td>-7.146187e-01</td>\n",
       "      <td>-2.695209e-01</td>\n",
       "      <td>-6.625666e-01</td>\n",
       "      <td>-7.968404e-01</td>\n",
       "      <td>-6.073939e-01</td>\n",
       "      <td>-2.264619e-01</td>\n",
       "      <td>-4.952153e-01</td>\n",
       "      <td>-4.221755e-01</td>\n",
       "      <td>-1.084725e+00</td>\n",
       "      <td>-4.670169e+00</td>\n",
       "      <td>-9.966000e-01</td>\n",
       "      <td>-7.556114e-01</td>\n",
       "      <td>-9.412959e-01</td>\n",
       "      <td>-9.336352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.321584e-01</td>\n",
       "      <td>-8.659604e-01</td>\n",
       "      <td>-8.658190e-01</td>\n",
       "      <td>-6.819477e-01</td>\n",
       "      <td>-8.632094e-01</td>\n",
       "      <td>-9.724543e-01</td>\n",
       "      <td>-6.889230e-01</td>\n",
       "      <td>-8.647062e-01</td>\n",
       "      <td>-9.526596e-01</td>\n",
       "      <td>-6.935506e-01</td>\n",
       "      <td>-8.659706e-01</td>\n",
       "      <td>-8.377697e-01</td>\n",
       "      <td>-7.085818e-01</td>\n",
       "      <td>-8.667571e-01</td>\n",
       "      <td>-7.146187e-01</td>\n",
       "      <td>2.906835e-01</td>\n",
       "      <td>2.969626e-01</td>\n",
       "      <td>3.428450e-01</td>\n",
       "      <td>3.272016e-01</td>\n",
       "      <td>2.719195e-01</td>\n",
       "      <td>2.992355e-01</td>\n",
       "      <td>6.380529e-01</td>\n",
       "      <td>5.307856e-01</td>\n",
       "      <td>6.057191e-01</td>\n",
       "      <td>3.903798e-01</td>\n",
       "      <td>4.299310e-01</td>\n",
       "      <td>4.150297e-01</td>\n",
       "      <td>3.953860e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.386904e-04</td>\n",
       "      <td>-1.365973e-03</td>\n",
       "      <td>2.090639e-04</td>\n",
       "      <td>-1.125500e-03</td>\n",
       "      <td>-7.977719e-04</td>\n",
       "      <td>8.484855e-02</td>\n",
       "      <td>9.082319e-04</td>\n",
       "      <td>8.939700e-04</td>\n",
       "      <td>-9.526596e-01</td>\n",
       "      <td>1.093501e-03</td>\n",
       "      <td>3.138265e-04</td>\n",
       "      <td>-8.377697e-01</td>\n",
       "      <td>6.528141e-04</td>\n",
       "      <td>-1.998949e-04</td>\n",
       "      <td>-7.146187e-01</td>\n",
       "      <td>7.556306e-01</td>\n",
       "      <td>8.220505e-01</td>\n",
       "      <td>7.978708e-01</td>\n",
       "      <td>7.947510e-01</td>\n",
       "      <td>7.664560e-01</td>\n",
       "      <td>8.050897e-01</td>\n",
       "      <td>7.926677e-01</td>\n",
       "      <td>8.047199e-01</td>\n",
       "      <td>6.301876e-01</td>\n",
       "      <td>7.658091e-01</td>\n",
       "      <td>8.108293e-01</td>\n",
       "      <td>7.650499e-01</td>\n",
       "      <td>7.195430e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.318811e-01</td>\n",
       "      <td>8.655338e-01</td>\n",
       "      <td>8.662048e-01</td>\n",
       "      <td>6.806777e-01</td>\n",
       "      <td>8.628153e-01</td>\n",
       "      <td>1.142151e+00</td>\n",
       "      <td>6.888153e-01</td>\n",
       "      <td>8.641829e-01</td>\n",
       "      <td>1.158021e+00</td>\n",
       "      <td>6.939334e-01</td>\n",
       "      <td>8.661466e-01</td>\n",
       "      <td>1.296983e+00</td>\n",
       "      <td>7.082342e-01</td>\n",
       "      <td>8.659056e-01</td>\n",
       "      <td>1.500372e+00</td>\n",
       "      <td>1.432801e+00</td>\n",
       "      <td>1.489800e+00</td>\n",
       "      <td>1.378221e+00</td>\n",
       "      <td>1.418066e+00</td>\n",
       "      <td>1.464286e+00</td>\n",
       "      <td>1.471996e+00</td>\n",
       "      <td>9.855056e-01</td>\n",
       "      <td>1.154184e+00</td>\n",
       "      <td>8.183915e-01</td>\n",
       "      <td>1.333369e+00</td>\n",
       "      <td>1.315954e+00</td>\n",
       "      <td>1.293396e+00</td>\n",
       "      <td>1.316636e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.414175e+00</td>\n",
       "      <td>1.732883e+00</td>\n",
       "      <td>1.732090e+00</td>\n",
       "      <td>2.941910e+00</td>\n",
       "      <td>1.731837e+00</td>\n",
       "      <td>1.142151e+00</td>\n",
       "      <td>2.885307e+00</td>\n",
       "      <td>1.732988e+00</td>\n",
       "      <td>1.158021e+00</td>\n",
       "      <td>2.705695e+00</td>\n",
       "      <td>1.731326e+00</td>\n",
       "      <td>1.296983e+00</td>\n",
       "      <td>2.478841e+00</td>\n",
       "      <td>1.731909e+00</td>\n",
       "      <td>1.500372e+00</td>\n",
       "      <td>1.991209e+01</td>\n",
       "      <td>2.073755e+01</td>\n",
       "      <td>1.696594e+01</td>\n",
       "      <td>1.894311e+01</td>\n",
       "      <td>2.448835e+01</td>\n",
       "      <td>2.914014e+01</td>\n",
       "      <td>4.321080e+01</td>\n",
       "      <td>3.756345e+01</td>\n",
       "      <td>3.609834e+01</td>\n",
       "      <td>2.720432e+01</td>\n",
       "      <td>2.530246e+01</td>\n",
       "      <td>2.221914e+01</td>\n",
       "      <td>1.902509e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lepton_eta    lepton_phi  missing_energy_phi     jet_1_eta  \\\n",
       "count  2.600000e+06  2.600000e+06        2.600000e+06  2.600000e+06   \n",
       "mean  -4.470954e-18  1.700110e-17       -2.381958e-17 -9.263701e-18   \n",
       "std    1.000000e+00  1.000000e+00        1.000000e+00  1.000000e+00   \n",
       "min   -2.414452e+00 -1.731104e+00       -1.731925e+00 -2.942199e+00   \n",
       "25%   -7.321584e-01 -8.659604e-01       -8.658190e-01 -6.819477e-01   \n",
       "50%   -1.386904e-04 -1.365973e-03        2.090639e-04 -1.125500e-03   \n",
       "75%    7.318811e-01  8.655338e-01        8.662048e-01  6.806777e-01   \n",
       "max    2.414175e+00  1.732883e+00        1.732090e+00  2.941910e+00   \n",
       "\n",
       "          jet_1_phi    jet_1_btag     jet_2_eta     jet_2_phi    jet_2_btag  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean  -3.566378e-17  7.213785e-17 -1.918192e-17 -1.036573e-17  3.512711e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.730027e+00 -9.724543e-01 -2.885415e+00 -1.732408e+00 -9.526596e-01   \n",
       "25%   -8.632094e-01 -9.724543e-01 -6.889230e-01 -8.647062e-01 -9.526596e-01   \n",
       "50%   -7.977719e-04  8.484855e-02  9.082319e-04  8.939700e-04 -9.526596e-01   \n",
       "75%    8.628153e-01  1.142151e+00  6.888153e-01  8.641829e-01  1.158021e+00   \n",
       "max    1.731837e+00  1.142151e+00  2.885307e+00  1.732988e+00  1.158021e+00   \n",
       "\n",
       "          jet_3_eta     jet_3_phi    jet_3_btag     jet_4_eta     jet_4_phi  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean   7.341819e-18  2.970888e-17 -1.521518e-17 -1.473556e-17  2.121790e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.705312e+00 -1.730599e+00 -8.377697e-01 -2.479189e+00 -1.731107e+00   \n",
       "25%   -6.935506e-01 -8.659706e-01 -8.377697e-01 -7.085818e-01 -8.667571e-01   \n",
       "50%    1.093501e-03  3.138265e-04 -8.377697e-01  6.528141e-04 -1.998949e-04   \n",
       "75%    6.939334e-01  8.661466e-01  1.296983e+00  7.082342e-01  8.659056e-01   \n",
       "max    2.705695e+00  1.731326e+00  1.296983e+00  2.478841e+00  1.731909e+00   \n",
       "\n",
       "         jet_4_btag     lepton_ph  missing_energy_magnitude      jet_1_pt  \\\n",
       "count  2.600000e+06  2.600000e+06              2.600000e+06  2.600000e+06   \n",
       "mean   1.082293e-16  1.000000e+00              1.000000e+00  1.000000e+00   \n",
       "std    1.000000e+00  1.000000e+00              1.000000e+00  1.000000e+00   \n",
       "min   -7.146187e-01 -2.695209e-01             -6.625666e-01 -7.968404e-01   \n",
       "25%   -7.146187e-01  2.906835e-01              2.969626e-01  3.428450e-01   \n",
       "50%   -7.146187e-01  7.556306e-01              8.220505e-01  7.978708e-01   \n",
       "75%    1.500372e+00  1.432801e+00              1.489800e+00  1.378221e+00   \n",
       "max    1.500372e+00  1.991209e+01              2.073755e+01  1.696594e+01   \n",
       "\n",
       "           jet_2_pt      jet_4_pt      jet_3_pt          m_jj         m_jjj  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -6.073939e-01 -2.264619e-01 -4.952153e-01 -4.221755e-01 -1.084725e+00   \n",
       "25%    3.272016e-01  2.719195e-01  2.992355e-01  6.380529e-01  5.307856e-01   \n",
       "50%    7.947510e-01  7.664560e-01  8.050897e-01  7.926677e-01  8.047199e-01   \n",
       "75%    1.418066e+00  1.464286e+00  1.471996e+00  9.855056e-01  1.154184e+00   \n",
       "max    1.894311e+01  2.448835e+01  2.914014e+01  4.321080e+01  3.756345e+01   \n",
       "\n",
       "               m_lv         m_jlv          m_bb         m_wbb        m_wwbb  \n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  \n",
       "mean   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "min   -4.670169e+00 -9.966000e-01 -7.556114e-01 -9.412959e-01 -9.336352e-01  \n",
       "25%    6.057191e-01  3.903798e-01  4.299310e-01  4.150297e-01  3.953860e-01  \n",
       "50%    6.301876e-01  7.658091e-01  8.108293e-01  7.650499e-01  7.195430e-01  \n",
       "75%    8.183915e-01  1.333369e+00  1.315954e+00  1.293396e+00  1.316636e+00  \n",
       "max    3.609834e+01  2.720432e+01  2.530246e+01  2.221914e+01  1.902509e+01  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# input\n",
    "model.add(tf.keras.Input(shape=(28,)))\n",
    "# hidden\n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.1)))  \n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.05)))\n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.05)))\n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.05)))\n",
    "model.add(layers.Dense(1,\n",
    "                       activation='sigmoid',\n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.001)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=1e-5)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "21000/21000 [==============================] - 62s 3ms/step - loss: 0.5690 - auc: 0.7712 - val_loss: 0.5400 - val_auc: 0.8027\n",
      "Epoch 2/250\n",
      "21000/21000 [==============================] - 32624s 2s/step - loss: 0.5274 - auc: 0.8106 - val_loss: 0.5220 - val_auc: 0.8157\n",
      "Epoch 3/250\n",
      "21000/21000 [==============================] - 43s 2ms/step - loss: 0.5142 - auc: 0.8215 - val_loss: 0.5125 - val_auc: 0.8251\n",
      "Epoch 4/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.5059 - auc: 0.8280 - val_loss: 0.5031 - val_auc: 0.8307\n",
      "Epoch 5/250\n",
      "21000/21000 [==============================] - 57s 3ms/step - loss: 0.5002 - auc: 0.8324 - val_loss: 0.4973 - val_auc: 0.8349\n",
      "Epoch 6/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4958 - auc: 0.8358 - val_loss: 0.4955 - val_auc: 0.8360\n",
      "Epoch 7/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4924 - auc: 0.8383 - val_loss: 0.4926 - val_auc: 0.8387\n",
      "Epoch 8/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4896 - auc: 0.8405 - val_loss: 0.4941 - val_auc: 0.8383\n",
      "Epoch 9/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4873 - auc: 0.8423 - val_loss: 0.4903 - val_auc: 0.8402\n",
      "Epoch 10/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4851 - auc: 0.8438 - val_loss: 0.4880 - val_auc: 0.8415\n",
      "Epoch 11/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4832 - auc: 0.8452 - val_loss: 0.4867 - val_auc: 0.8426\n",
      "Epoch 12/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4815 - auc: 0.8464 - val_loss: 0.4878 - val_auc: 0.8417\n",
      "Epoch 13/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4799 - auc: 0.8476 - val_loss: 0.4880 - val_auc: 0.8435\n",
      "Epoch 14/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4783 - auc: 0.8487 - val_loss: 0.4856 - val_auc: 0.8437\n",
      "Epoch 15/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4769 - auc: 0.8497 - val_loss: 0.4863 - val_auc: 0.8434\n",
      "Epoch 16/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4756 - auc: 0.8507 - val_loss: 0.4861 - val_auc: 0.8438\n",
      "Epoch 17/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4742 - auc: 0.8517 - val_loss: 0.4835 - val_auc: 0.8452\n",
      "Epoch 18/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4729 - auc: 0.8526 - val_loss: 0.4861 - val_auc: 0.8454\n",
      "Epoch 19/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4716 - auc: 0.8535 - val_loss: 0.4828 - val_auc: 0.8456\n",
      "Epoch 20/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4705 - auc: 0.8543 - val_loss: 0.4826 - val_auc: 0.8459\n",
      "Epoch 21/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4694 - auc: 0.8551 - val_loss: 0.4843 - val_auc: 0.8453\n",
      "Epoch 22/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4683 - auc: 0.8558 - val_loss: 0.4844 - val_auc: 0.8450\n",
      "Epoch 23/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4671 - auc: 0.8567 - val_loss: 0.4811 - val_auc: 0.8470\n",
      "Epoch 24/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4661 - auc: 0.8573 - val_loss: 0.4846 - val_auc: 0.8454\n",
      "Epoch 25/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4650 - auc: 0.8581 - val_loss: 0.4832 - val_auc: 0.8460\n",
      "Epoch 26/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4640 - auc: 0.8588 - val_loss: 0.4813 - val_auc: 0.8474\n",
      "Epoch 27/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4630 - auc: 0.8595 - val_loss: 0.4831 - val_auc: 0.8460\n",
      "Epoch 28/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4619 - auc: 0.8602 - val_loss: 0.4824 - val_auc: 0.8466\n",
      "Epoch 29/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4608 - auc: 0.8610 - val_loss: 0.4830 - val_auc: 0.8459\n",
      "Epoch 30/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4599 - auc: 0.8616 - val_loss: 0.4828 - val_auc: 0.8467\n",
      "Epoch 31/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4588 - auc: 0.8623 - val_loss: 0.4825 - val_auc: 0.8464\n",
      "Epoch 32/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4579 - auc: 0.8629 - val_loss: 0.4855 - val_auc: 0.8455\n",
      "Epoch 33/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4570 - auc: 0.8635 - val_loss: 0.4844 - val_auc: 0.8457\n",
      "Epoch 34/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4560 - auc: 0.8642 - val_loss: 0.4831 - val_auc: 0.8464\n",
      "Epoch 35/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4550 - auc: 0.8649 - val_loss: 0.4841 - val_auc: 0.8458\n",
      "Epoch 36/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4539 - auc: 0.8656 - val_loss: 0.4874 - val_auc: 0.8440\n",
      "Epoch 37/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4531 - auc: 0.8661 - val_loss: 0.4846 - val_auc: 0.8459\n",
      "Epoch 38/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4520 - auc: 0.8669 - val_loss: 0.4869 - val_auc: 0.8448\n",
      "Epoch 39/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4510 - auc: 0.8675 - val_loss: 0.4850 - val_auc: 0.8454\n",
      "Epoch 40/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4500 - auc: 0.8681 - val_loss: 0.4880 - val_auc: 0.8436\n",
      "Epoch 41/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4490 - auc: 0.8689 - val_loss: 0.4867 - val_auc: 0.8445\n",
      "Epoch 42/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4480 - auc: 0.8695 - val_loss: 0.4897 - val_auc: 0.8431\n",
      "Epoch 43/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4470 - auc: 0.8701 - val_loss: 0.4894 - val_auc: 0.8441\n",
      "Epoch 44/250\n",
      "21000/21000 [==============================] - 48s 2ms/step - loss: 0.4459 - auc: 0.8708 - val_loss: 0.4894 - val_auc: 0.8433\n",
      "Epoch 45/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4449 - auc: 0.8715 - val_loss: 0.4892 - val_auc: 0.8428\n",
      "Epoch 46/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4439 - auc: 0.8721 - val_loss: 0.4900 - val_auc: 0.8425\n",
      "Epoch 47/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4429 - auc: 0.8727 - val_loss: 0.4909 - val_auc: 0.8424\n",
      "Epoch 48/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4419 - auc: 0.8734 - val_loss: 0.4915 - val_auc: 0.8427\n",
      "Epoch 49/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4409 - auc: 0.8740 - val_loss: 0.4929 - val_auc: 0.8413\n",
      "Epoch 50/250\n",
      "21000/21000 [==============================] - 73s 3ms/step - loss: 0.4397 - auc: 0.8748 - val_loss: 0.4938 - val_auc: 0.8406\n",
      "Epoch 51/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4388 - auc: 0.8754 - val_loss: 0.4948 - val_auc: 0.8401\n",
      "Epoch 52/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4376 - auc: 0.8761 - val_loss: 0.4967 - val_auc: 0.8407\n",
      "Epoch 53/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4368 - auc: 0.8766 - val_loss: 0.4964 - val_auc: 0.8403\n",
      "Epoch 54/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4356 - auc: 0.8773 - val_loss: 0.5004 - val_auc: 0.8379\n",
      "Epoch 55/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4346 - auc: 0.8780 - val_loss: 0.5001 - val_auc: 0.8397\n",
      "Epoch 56/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4336 - auc: 0.8786 - val_loss: 0.4989 - val_auc: 0.8390\n",
      "Epoch 57/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4326 - auc: 0.8792 - val_loss: 0.4983 - val_auc: 0.8384\n",
      "Epoch 58/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4315 - auc: 0.8799 - val_loss: 0.5008 - val_auc: 0.8384\n",
      "Epoch 59/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4306 - auc: 0.8805 - val_loss: 0.5008 - val_auc: 0.8384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4295 - auc: 0.8812 - val_loss: 0.5029 - val_auc: 0.8377\n",
      "Epoch 61/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4285 - auc: 0.8817 - val_loss: 0.5040 - val_auc: 0.8367\n",
      "Epoch 62/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4274 - auc: 0.8824 - val_loss: 0.5059 - val_auc: 0.8362\n",
      "Epoch 63/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4264 - auc: 0.8830 - val_loss: 0.5078 - val_auc: 0.8348\n",
      "Epoch 64/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4254 - auc: 0.8836 - val_loss: 0.5062 - val_auc: 0.8362\n",
      "Epoch 65/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4243 - auc: 0.8843 - val_loss: 0.5096 - val_auc: 0.8353\n",
      "Epoch 66/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4234 - auc: 0.8848 - val_loss: 0.5091 - val_auc: 0.8352\n",
      "Epoch 67/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4223 - auc: 0.8855 - val_loss: 0.5117 - val_auc: 0.8341\n",
      "Epoch 68/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4213 - auc: 0.8860 - val_loss: 0.5137 - val_auc: 0.8339\n",
      "Epoch 69/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4203 - auc: 0.8867 - val_loss: 0.5132 - val_auc: 0.8333\n",
      "Epoch 70/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4193 - auc: 0.8872 - val_loss: 0.5127 - val_auc: 0.8329\n",
      "Epoch 71/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4184 - auc: 0.8878 - val_loss: 0.5136 - val_auc: 0.8324\n",
      "Epoch 72/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4173 - auc: 0.8884 - val_loss: 0.5176 - val_auc: 0.8312\n",
      "Epoch 73/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4163 - auc: 0.8890 - val_loss: 0.5165 - val_auc: 0.8310\n",
      "Epoch 74/250\n",
      "21000/21000 [==============================] - 48s 2ms/step - loss: 0.4155 - auc: 0.8894 - val_loss: 0.5216 - val_auc: 0.8301\n",
      "Epoch 75/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4145 - auc: 0.8900 - val_loss: 0.5210 - val_auc: 0.8300\n",
      "Epoch 76/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4136 - auc: 0.8906 - val_loss: 0.5215 - val_auc: 0.8291\n",
      "Epoch 77/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4127 - auc: 0.8911 - val_loss: 0.5234 - val_auc: 0.8303\n",
      "Epoch 78/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4117 - auc: 0.8917 - val_loss: 0.5251 - val_auc: 0.8283\n",
      "Epoch 79/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4109 - auc: 0.8921 - val_loss: 0.5270 - val_auc: 0.8302\n",
      "Epoch 80/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4100 - auc: 0.8927 - val_loss: 0.5260 - val_auc: 0.8273\n",
      "Epoch 81/250\n",
      "21000/21000 [==============================] - 48s 2ms/step - loss: 0.4090 - auc: 0.8932 - val_loss: 0.5259 - val_auc: 0.8277\n",
      "Epoch 82/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4082 - auc: 0.8937 - val_loss: 0.5269 - val_auc: 0.8258\n",
      "Epoch 83/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4073 - auc: 0.8942 - val_loss: 0.5314 - val_auc: 0.8285\n",
      "Epoch 84/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4064 - auc: 0.8947 - val_loss: 0.5302 - val_auc: 0.8270\n",
      "Epoch 85/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4056 - auc: 0.8951 - val_loss: 0.5326 - val_auc: 0.8270\n",
      "Epoch 86/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4047 - auc: 0.8956 - val_loss: 0.5311 - val_auc: 0.8263\n",
      "Epoch 87/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4038 - auc: 0.8961 - val_loss: 0.5347 - val_auc: 0.8263\n",
      "Epoch 88/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4031 - auc: 0.8965 - val_loss: 0.5365 - val_auc: 0.8263\n",
      "Epoch 89/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4023 - auc: 0.8969 - val_loss: 0.5363 - val_auc: 0.8259\n",
      "Epoch 90/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.4016 - auc: 0.8974 - val_loss: 0.5375 - val_auc: 0.8249\n",
      "Epoch 91/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4008 - auc: 0.8978 - val_loss: 0.5385 - val_auc: 0.8247\n",
      "Epoch 92/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.4000 - auc: 0.8983 - val_loss: 0.5419 - val_auc: 0.8225\n",
      "Epoch 93/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3993 - auc: 0.8986 - val_loss: 0.5408 - val_auc: 0.8237\n",
      "Epoch 94/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3986 - auc: 0.8990 - val_loss: 0.5406 - val_auc: 0.8233\n",
      "Epoch 95/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3977 - auc: 0.8995 - val_loss: 0.5428 - val_auc: 0.8212\n",
      "Epoch 96/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3972 - auc: 0.8998 - val_loss: 0.5426 - val_auc: 0.8220\n",
      "Epoch 97/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3964 - auc: 0.9002 - val_loss: 0.5459 - val_auc: 0.8218\n",
      "Epoch 98/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3958 - auc: 0.9005 - val_loss: 0.5481 - val_auc: 0.8225\n",
      "Epoch 99/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3951 - auc: 0.9009 - val_loss: 0.5462 - val_auc: 0.8222\n",
      "Epoch 100/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3944 - auc: 0.9013 - val_loss: 0.5493 - val_auc: 0.8214\n",
      "Epoch 101/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3937 - auc: 0.9017 - val_loss: 0.5476 - val_auc: 0.8210\n",
      "Epoch 102/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3929 - auc: 0.9021 - val_loss: 0.5490 - val_auc: 0.8197\n",
      "Epoch 103/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3924 - auc: 0.9024 - val_loss: 0.5506 - val_auc: 0.8193\n",
      "Epoch 104/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3918 - auc: 0.9026 - val_loss: 0.5526 - val_auc: 0.8190\n",
      "Epoch 105/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3912 - auc: 0.9030 - val_loss: 0.5524 - val_auc: 0.8193\n",
      "Epoch 106/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3905 - auc: 0.9034 - val_loss: 0.5548 - val_auc: 0.8210\n",
      "Epoch 107/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3900 - auc: 0.9036 - val_loss: 0.5559 - val_auc: 0.8182\n",
      "Epoch 108/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3894 - auc: 0.9039 - val_loss: 0.5575 - val_auc: 0.8187\n",
      "Epoch 109/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3888 - auc: 0.9043 - val_loss: 0.5589 - val_auc: 0.8165\n",
      "Epoch 110/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3883 - auc: 0.9046 - val_loss: 0.5590 - val_auc: 0.8190\n",
      "Epoch 111/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3878 - auc: 0.9048 - val_loss: 0.5584 - val_auc: 0.8193\n",
      "Epoch 112/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3869 - auc: 0.9052 - val_loss: 0.5607 - val_auc: 0.8149\n",
      "Epoch 113/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3865 - auc: 0.9055 - val_loss: 0.5618 - val_auc: 0.8171\n",
      "Epoch 114/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3861 - auc: 0.9057 - val_loss: 0.5629 - val_auc: 0.8176\n",
      "Epoch 115/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3855 - auc: 0.9060 - val_loss: 0.5620 - val_auc: 0.8164\n",
      "Epoch 116/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3850 - auc: 0.9062 - val_loss: 0.5629 - val_auc: 0.8166\n",
      "Epoch 117/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3845 - auc: 0.9065 - val_loss: 0.5666 - val_auc: 0.8160\n",
      "Epoch 118/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3839 - auc: 0.9068 - val_loss: 0.5646 - val_auc: 0.8170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3836 - auc: 0.9070 - val_loss: 0.5666 - val_auc: 0.8152\n",
      "Epoch 120/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3832 - auc: 0.9072 - val_loss: 0.5690 - val_auc: 0.8141\n",
      "Epoch 121/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3825 - auc: 0.9076 - val_loss: 0.5699 - val_auc: 0.8160\n",
      "Epoch 122/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3822 - auc: 0.9077 - val_loss: 0.5694 - val_auc: 0.8157\n",
      "Epoch 123/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3817 - auc: 0.9079 - val_loss: 0.5707 - val_auc: 0.8143\n",
      "Epoch 124/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3812 - auc: 0.9082 - val_loss: 0.5706 - val_auc: 0.8146\n",
      "Epoch 125/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3809 - auc: 0.9084 - val_loss: 0.5711 - val_auc: 0.8150\n",
      "Epoch 126/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3805 - auc: 0.9086 - val_loss: 0.5732 - val_auc: 0.8155\n",
      "Epoch 127/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3801 - auc: 0.9088 - val_loss: 0.5728 - val_auc: 0.8136\n",
      "Epoch 128/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3795 - auc: 0.9091 - val_loss: 0.5737 - val_auc: 0.8130\n",
      "Epoch 129/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3794 - auc: 0.9092 - val_loss: 0.5735 - val_auc: 0.8145\n",
      "Epoch 130/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3787 - auc: 0.9095 - val_loss: 0.5745 - val_auc: 0.8142\n",
      "Epoch 131/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3784 - auc: 0.9097 - val_loss: 0.5762 - val_auc: 0.8120\n",
      "Epoch 132/250\n",
      "21000/21000 [==============================] - 48s 2ms/step - loss: 0.3781 - auc: 0.9098 - val_loss: 0.5745 - val_auc: 0.8131\n",
      "Epoch 133/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3776 - auc: 0.9101 - val_loss: 0.5758 - val_auc: 0.8131\n",
      "Epoch 134/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3774 - auc: 0.9101 - val_loss: 0.5803 - val_auc: 0.8129\n",
      "Epoch 135/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3769 - auc: 0.9104 - val_loss: 0.5780 - val_auc: 0.8143\n",
      "Epoch 136/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3768 - auc: 0.9105 - val_loss: 0.5803 - val_auc: 0.8129\n",
      "Epoch 137/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3762 - auc: 0.9108 - val_loss: 0.5792 - val_auc: 0.8111\n",
      "Epoch 138/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3759 - auc: 0.9109 - val_loss: 0.5803 - val_auc: 0.8109\n",
      "Epoch 139/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3757 - auc: 0.9110 - val_loss: 0.5795 - val_auc: 0.8129\n",
      "Epoch 140/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3753 - auc: 0.9112 - val_loss: 0.5830 - val_auc: 0.8106\n",
      "Epoch 141/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3750 - auc: 0.9114 - val_loss: 0.5841 - val_auc: 0.8125\n",
      "Epoch 142/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3746 - auc: 0.9116 - val_loss: 0.5818 - val_auc: 0.8123\n",
      "Epoch 143/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3742 - auc: 0.9118 - val_loss: 0.5852 - val_auc: 0.8122\n",
      "Epoch 144/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3739 - auc: 0.9119 - val_loss: 0.5845 - val_auc: 0.8109\n",
      "Epoch 145/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3738 - auc: 0.9119 - val_loss: 0.5832 - val_auc: 0.8104\n",
      "Epoch 146/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3736 - auc: 0.9121 - val_loss: 0.5820 - val_auc: 0.8093\n",
      "Epoch 147/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3731 - auc: 0.9123 - val_loss: 0.5898 - val_auc: 0.8104\n",
      "Epoch 148/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3728 - auc: 0.9124 - val_loss: 0.5890 - val_auc: 0.8105\n",
      "Epoch 149/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3724 - auc: 0.9126 - val_loss: 0.5880 - val_auc: 0.8094\n",
      "Epoch 150/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3723 - auc: 0.9127 - val_loss: 0.5860 - val_auc: 0.8106\n",
      "Epoch 151/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3720 - auc: 0.9129 - val_loss: 0.5877 - val_auc: 0.8102\n",
      "Epoch 152/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3717 - auc: 0.9130 - val_loss: 0.5903 - val_auc: 0.8103\n",
      "Epoch 153/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3716 - auc: 0.9131 - val_loss: 0.5885 - val_auc: 0.8099\n",
      "Epoch 154/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3712 - auc: 0.9132 - val_loss: 0.5894 - val_auc: 0.8102\n",
      "Epoch 155/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3709 - auc: 0.9134 - val_loss: 0.5921 - val_auc: 0.8099\n",
      "Epoch 156/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3708 - auc: 0.9135 - val_loss: 0.5901 - val_auc: 0.8082\n",
      "Epoch 157/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3705 - auc: 0.9136 - val_loss: 0.5904 - val_auc: 0.8096\n",
      "Epoch 158/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3703 - auc: 0.9137 - val_loss: 0.5909 - val_auc: 0.8083\n",
      "Epoch 159/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3699 - auc: 0.9139 - val_loss: 0.5926 - val_auc: 0.8082\n",
      "Epoch 160/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3697 - auc: 0.9140 - val_loss: 0.5910 - val_auc: 0.8084\n",
      "Epoch 161/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3696 - auc: 0.9140 - val_loss: 0.5923 - val_auc: 0.8095\n",
      "Epoch 162/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3691 - auc: 0.9143 - val_loss: 0.5946 - val_auc: 0.8094\n",
      "Epoch 163/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3691 - auc: 0.9143 - val_loss: 0.5911 - val_auc: 0.8072\n",
      "Epoch 164/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3689 - auc: 0.9144 - val_loss: 0.5921 - val_auc: 0.8090\n",
      "Epoch 165/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3686 - auc: 0.9145 - val_loss: 0.5916 - val_auc: 0.8094\n",
      "Epoch 166/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3685 - auc: 0.9146 - val_loss: 0.5949 - val_auc: 0.8092\n",
      "Epoch 167/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3681 - auc: 0.9147 - val_loss: 0.5944 - val_auc: 0.8079\n",
      "Epoch 168/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3680 - auc: 0.9148 - val_loss: 0.5938 - val_auc: 0.8066\n",
      "Epoch 169/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3679 - auc: 0.9148 - val_loss: 0.5980 - val_auc: 0.8075\n",
      "Epoch 170/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3675 - auc: 0.9151 - val_loss: 0.5969 - val_auc: 0.8076\n",
      "Epoch 171/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3673 - auc: 0.9152 - val_loss: 0.5970 - val_auc: 0.8065\n",
      "Epoch 172/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3674 - auc: 0.9151 - val_loss: 0.5965 - val_auc: 0.8075\n",
      "Epoch 173/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3670 - auc: 0.9153 - val_loss: 0.5958 - val_auc: 0.8070\n",
      "Epoch 174/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3669 - auc: 0.9153 - val_loss: 0.5991 - val_auc: 0.8068\n",
      "Epoch 175/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3665 - auc: 0.9156 - val_loss: 0.5990 - val_auc: 0.8054\n",
      "Epoch 176/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3664 - auc: 0.9156 - val_loss: 0.5972 - val_auc: 0.8068\n",
      "Epoch 177/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3663 - auc: 0.9156 - val_loss: 0.6020 - val_auc: 0.8068\n",
      "Epoch 178/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3662 - auc: 0.9157 - val_loss: 0.6006 - val_auc: 0.8062\n",
      "Epoch 179/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3660 - auc: 0.9158 - val_loss: 0.5993 - val_auc: 0.8053\n",
      "Epoch 180/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3658 - auc: 0.9159 - val_loss: 0.6038 - val_auc: 0.8080\n",
      "Epoch 181/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3657 - auc: 0.9160 - val_loss: 0.6008 - val_auc: 0.8070\n",
      "Epoch 182/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3653 - auc: 0.9161 - val_loss: 0.6002 - val_auc: 0.8063\n",
      "Epoch 183/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3651 - auc: 0.9162 - val_loss: 0.6040 - val_auc: 0.8072\n",
      "Epoch 184/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3649 - auc: 0.9163 - val_loss: 0.6025 - val_auc: 0.8061\n",
      "Epoch 185/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3650 - auc: 0.9163 - val_loss: 0.6025 - val_auc: 0.8059\n",
      "Epoch 186/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3648 - auc: 0.9164 - val_loss: 0.6026 - val_auc: 0.8064\n",
      "Epoch 187/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3647 - auc: 0.9164 - val_loss: 0.6023 - val_auc: 0.8051\n",
      "Epoch 188/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3644 - auc: 0.9165 - val_loss: 0.6058 - val_auc: 0.8076\n",
      "Epoch 189/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3643 - auc: 0.9166 - val_loss: 0.6058 - val_auc: 0.8049\n",
      "Epoch 190/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3641 - auc: 0.9167 - val_loss: 0.6056 - val_auc: 0.8048\n",
      "Epoch 191/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3640 - auc: 0.9168 - val_loss: 0.6039 - val_auc: 0.8053\n",
      "Epoch 192/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3639 - auc: 0.9168 - val_loss: 0.6064 - val_auc: 0.8046\n",
      "Epoch 193/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3636 - auc: 0.9169 - val_loss: 0.6039 - val_auc: 0.8048\n",
      "Epoch 194/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3634 - auc: 0.9170 - val_loss: 0.6063 - val_auc: 0.8056\n",
      "Epoch 195/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3633 - auc: 0.9171 - val_loss: 0.6057 - val_auc: 0.8055\n",
      "Epoch 196/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3632 - auc: 0.9171 - val_loss: 0.6046 - val_auc: 0.8045\n",
      "Epoch 197/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3631 - auc: 0.9172 - val_loss: 0.6060 - val_auc: 0.8051\n",
      "Epoch 198/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3630 - auc: 0.9172 - val_loss: 0.6060 - val_auc: 0.8055\n",
      "Epoch 199/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3628 - auc: 0.9173 - val_loss: 0.6085 - val_auc: 0.8047\n",
      "Epoch 200/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3626 - auc: 0.9174 - val_loss: 0.6062 - val_auc: 0.8046\n",
      "Epoch 201/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3625 - auc: 0.9175 - val_loss: 0.6074 - val_auc: 0.8063\n",
      "Epoch 202/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3624 - auc: 0.9175 - val_loss: 0.6085 - val_auc: 0.8042\n",
      "Epoch 203/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3622 - auc: 0.9176 - val_loss: 0.6091 - val_auc: 0.8050\n",
      "Epoch 204/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3622 - auc: 0.9176 - val_loss: 0.6103 - val_auc: 0.8036\n",
      "Epoch 205/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3620 - auc: 0.9177 - val_loss: 0.6110 - val_auc: 0.8046\n",
      "Epoch 206/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3619 - auc: 0.9177 - val_loss: 0.6081 - val_auc: 0.8053\n",
      "Epoch 207/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3618 - auc: 0.9178 - val_loss: 0.6110 - val_auc: 0.8042\n",
      "Epoch 208/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3617 - auc: 0.9179 - val_loss: 0.6110 - val_auc: 0.8043\n",
      "Epoch 209/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3614 - auc: 0.9180 - val_loss: 0.6093 - val_auc: 0.8041\n",
      "Epoch 210/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3614 - auc: 0.9180 - val_loss: 0.6112 - val_auc: 0.8042\n",
      "Epoch 211/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3611 - auc: 0.9181 - val_loss: 0.6117 - val_auc: 0.8036\n",
      "Epoch 212/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3612 - auc: 0.9181 - val_loss: 0.6119 - val_auc: 0.8038\n",
      "Epoch 213/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3609 - auc: 0.9182 - val_loss: 0.6123 - val_auc: 0.8037\n",
      "Epoch 214/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3609 - auc: 0.9183 - val_loss: 0.6092 - val_auc: 0.8045\n",
      "Epoch 215/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3605 - auc: 0.9184 - val_loss: 0.6124 - val_auc: 0.8032\n",
      "Epoch 216/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3610 - auc: 0.9182 - val_loss: 0.6130 - val_auc: 0.8050\n",
      "Epoch 217/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3606 - auc: 0.9184 - val_loss: 0.6102 - val_auc: 0.8029\n",
      "Epoch 218/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3604 - auc: 0.9185 - val_loss: 0.6129 - val_auc: 0.8043\n",
      "Epoch 219/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3603 - auc: 0.9185 - val_loss: 0.6136 - val_auc: 0.8022\n",
      "Epoch 220/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3601 - auc: 0.9186 - val_loss: 0.6133 - val_auc: 0.8037\n",
      "Epoch 221/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3601 - auc: 0.9186 - val_loss: 0.6111 - val_auc: 0.8045\n",
      "Epoch 222/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3601 - auc: 0.9186 - val_loss: 0.6099 - val_auc: 0.8035\n",
      "Epoch 223/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3598 - auc: 0.9187 - val_loss: 0.6108 - val_auc: 0.8035\n",
      "Epoch 224/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3595 - auc: 0.9189 - val_loss: 0.6154 - val_auc: 0.8036\n",
      "Epoch 225/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3597 - auc: 0.9188 - val_loss: 0.6161 - val_auc: 0.8022\n",
      "Epoch 226/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3595 - auc: 0.9189 - val_loss: 0.6147 - val_auc: 0.8035\n",
      "Epoch 227/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3596 - auc: 0.9189 - val_loss: 0.6142 - val_auc: 0.8026\n",
      "Epoch 228/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3595 - auc: 0.9189 - val_loss: 0.6142 - val_auc: 0.8031\n",
      "Epoch 229/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3593 - auc: 0.9190 - val_loss: 0.6135 - val_auc: 0.8016\n",
      "Epoch 230/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3592 - auc: 0.9191 - val_loss: 0.6151 - val_auc: 0.8025\n",
      "Epoch 231/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3590 - auc: 0.9192 - val_loss: 0.6170 - val_auc: 0.8037\n",
      "Epoch 232/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3590 - auc: 0.9191 - val_loss: 0.6145 - val_auc: 0.8028\n",
      "Epoch 233/250\n",
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3589 - auc: 0.9192 - val_loss: 0.6157 - val_auc: 0.8028\n",
      "Epoch 234/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3589 - auc: 0.9192 - val_loss: 0.6173 - val_auc: 0.8031\n",
      "Epoch 235/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 47s 2ms/step - loss: 0.3588 - auc: 0.9193 - val_loss: 0.6181 - val_auc: 0.8037\n",
      "Epoch 236/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3587 - auc: 0.9193 - val_loss: 0.6164 - val_auc: 0.8035\n",
      "Epoch 237/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3586 - auc: 0.9193 - val_loss: 0.6173 - val_auc: 0.8025\n",
      "Epoch 238/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3586 - auc: 0.9194 - val_loss: 0.6162 - val_auc: 0.8033\n",
      "Epoch 239/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3582 - auc: 0.9195 - val_loss: 0.6126 - val_auc: 0.8025\n",
      "Epoch 240/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3581 - auc: 0.9195 - val_loss: 0.6186 - val_auc: 0.8014\n",
      "Epoch 241/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3583 - auc: 0.9195 - val_loss: 0.6148 - val_auc: 0.8019\n",
      "Epoch 242/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3579 - auc: 0.9197 - val_loss: 0.6162 - val_auc: 0.8015\n",
      "Epoch 243/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3577 - auc: 0.9198 - val_loss: 0.6191 - val_auc: 0.8019\n",
      "Epoch 244/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3581 - auc: 0.9196 - val_loss: 0.6169 - val_auc: 0.8022\n",
      "Epoch 245/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3575 - auc: 0.9199 - val_loss: 0.6191 - val_auc: 0.8023\n",
      "Epoch 246/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3577 - auc: 0.9198 - val_loss: 0.6192 - val_auc: 0.8018\n",
      "Epoch 247/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3577 - auc: 0.9198 - val_loss: 0.6186 - val_auc: 0.8021\n",
      "Epoch 248/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3575 - auc: 0.9199 - val_loss: 0.6219 - val_auc: 0.8034\n",
      "Epoch 249/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3575 - auc: 0.9199 - val_loss: 0.6190 - val_auc: 0.8030\n",
      "Epoch 250/250\n",
      "21000/21000 [==============================] - 46s 2ms/step - loss: 0.3574 - auc: 0.9199 - val_loss: 0.6199 - val_auc: 0.8023\n",
      "Wall time: 12h 17min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bcc59bb348>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(x_train, y_train, epochs=250, validation_data=(x_test,y_test), batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
