{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn import datasets\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import shutil\n",
    "# # C:\\Users\\allro\\JupyterNotebook\\QTW\\Data\n",
    "# with gzip.open('C:\\\\Users\\\\allro\\\\JupyterNotebook\\\\QTW\\\\Data\\\\HIGGS.csv.gz', 'rb') as f_in:\n",
    "#    with open('C:\\\\Users\\\\allro\\\\JupyterNotebook\\\\QTW\\\\Data\\\\HIGGS.csv', 'wb') as f_out:\n",
    "#        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://archive.ics.uci.edu/ml/datasets/HIGGS#\n",
    "df = pd.read_csv(\"../../HIGGS.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns =['target', 'lepton_ph', 'lepton_eta', 'lepton_phi','missing_energy_magnitude','missing_energy_phi',\n",
    "             'jet_1_pt','jet_1_eta','jet_1_phi','jet_1_btag','jet_2_pt','jet_2_eta','jet_2_phi','jet_2_btag',\n",
    "             'jet_3_pt','jet_3_eta','jet_3_phi','jet_3_btag','jet_4_pt','jet_4_eta','jet_4_phi','jet_4_btag',\n",
    "             'm_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000000 entries, 0 to 10999999\n",
      "Data columns (total 29 columns):\n",
      "target                      float64\n",
      "lepton_ph                   float64\n",
      "lepton_eta                  float64\n",
      "lepton_phi                  float64\n",
      "missing_energy_magnitude    float64\n",
      "missing_energy_phi          float64\n",
      "jet_1_pt                    float64\n",
      "jet_1_eta                   float64\n",
      "jet_1_phi                   float64\n",
      "jet_1_btag                  float64\n",
      "jet_2_pt                    float64\n",
      "jet_2_eta                   float64\n",
      "jet_2_phi                   float64\n",
      "jet_2_btag                  float64\n",
      "jet_3_pt                    float64\n",
      "jet_3_eta                   float64\n",
      "jet_3_phi                   float64\n",
      "jet_3_btag                  float64\n",
      "jet_4_pt                    float64\n",
      "jet_4_eta                   float64\n",
      "jet_4_phi                   float64\n",
      "jet_4_btag                  float64\n",
      "m_jj                        float64\n",
      "m_jjj                       float64\n",
      "m_lv                        float64\n",
      "m_jlv                       float64\n",
      "m_bb                        float64\n",
      "m_wbb                       float64\n",
      "m_wwbb                      float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 2.4 GB\n"
     ]
    }
   ],
   "source": [
    "# Print out the data types\n",
    "df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  lepton_ph  lepton_eta  lepton_phi  missing_energy_magnitude  \\\n",
       "0     1.0   0.869293   -0.635082    0.225690                  0.327470   \n",
       "1     1.0   0.907542    0.329147    0.359412                  1.497970   \n",
       "2     1.0   0.798835    1.470639   -1.635975                  0.453773   \n",
       "3     0.0   1.344385   -0.876626    0.935913                  1.992050   \n",
       "4     1.0   1.105009    0.321356    1.522401                  0.882808   \n",
       "\n",
       "   missing_energy_phi  jet_1_pt  jet_1_eta  jet_1_phi  jet_1_btag  ...  \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064    0.000000  ...   \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230    2.173076  ...   \n",
       "2            0.425629  1.104875   1.282322   1.381664    0.000000  ...   \n",
       "3            0.882454  1.786066  -1.646778  -0.942383    0.000000  ...   \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871    0.000000  ...   \n",
       "\n",
       "   jet_4_eta  jet_4_phi  jet_4_btag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
       "0  -0.010455  -0.045767    3.101961  1.353760  0.979563  0.978076  0.920005   \n",
       "1  -1.138930  -0.000819    0.000000  0.302220  0.833048  0.985700  0.978098   \n",
       "2   1.128848   0.900461    0.000000  0.909753  1.108330  0.985692  0.951331   \n",
       "3  -0.678379  -1.360356    0.000000  0.946652  1.028704  0.998656  0.728281   \n",
       "4  -0.373566   0.113041    0.000000  0.755856  1.361057  0.986610  0.838085   \n",
       "\n",
       "       m_bb     m_wbb    m_wwbb  \n",
       "0  0.721657  0.988751  0.876678  \n",
       "1  0.779732  0.992356  0.798343  \n",
       "2  0.803252  0.865924  0.780118  \n",
       "3  0.869200  1.026736  0.957904  \n",
       "4  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsample the data\n",
    "train = df.sample(n=2600000, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>jet_2_pt</th>\n",
       "      <th>jet_2_eta</th>\n",
       "      <th>jet_2_phi</th>\n",
       "      <th>jet_2_btag</th>\n",
       "      <th>jet_3_pt</th>\n",
       "      <th>jet_3_eta</th>\n",
       "      <th>jet_3_phi</th>\n",
       "      <th>jet_3_btag</th>\n",
       "      <th>jet_4_pt</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.299203e-01</td>\n",
       "      <td>9.914658e-01</td>\n",
       "      <td>-8.297618e-06</td>\n",
       "      <td>-1.327225e-05</td>\n",
       "      <td>9.985364e-01</td>\n",
       "      <td>2.613459e-05</td>\n",
       "      <td>9.909152e-01</td>\n",
       "      <td>-2.027520e-05</td>\n",
       "      <td>7.716199e-06</td>\n",
       "      <td>9.999687e-01</td>\n",
       "      <td>9.927294e-01</td>\n",
       "      <td>-1.026444e-05</td>\n",
       "      <td>-2.076887e-05</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>9.922591e-01</td>\n",
       "      <td>1.459561e-05</td>\n",
       "      <td>3.678632e-06</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>9.861087e-01</td>\n",
       "      <td>-5.756954e-06</td>\n",
       "      <td>1.744903e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.034290e+00</td>\n",
       "      <td>1.024805e+00</td>\n",
       "      <td>1.050554e+00</td>\n",
       "      <td>1.009742e+00</td>\n",
       "      <td>9.729596e-01</td>\n",
       "      <td>1.033036e+00</td>\n",
       "      <td>9.598120e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.991040e-01</td>\n",
       "      <td>5.653777e-01</td>\n",
       "      <td>1.008827e+00</td>\n",
       "      <td>1.006346e+00</td>\n",
       "      <td>6.000185e-01</td>\n",
       "      <td>1.006326e+00</td>\n",
       "      <td>4.749747e-01</td>\n",
       "      <td>1.009303e+00</td>\n",
       "      <td>1.005901e+00</td>\n",
       "      <td>1.027808e+00</td>\n",
       "      <td>4.999939e-01</td>\n",
       "      <td>1.009331e+00</td>\n",
       "      <td>1.006154e+00</td>\n",
       "      <td>1.049398e+00</td>\n",
       "      <td>4.876623e-01</td>\n",
       "      <td>1.008747e+00</td>\n",
       "      <td>1.006305e+00</td>\n",
       "      <td>1.193676e+00</td>\n",
       "      <td>5.057777e-01</td>\n",
       "      <td>1.007694e+00</td>\n",
       "      <td>1.006366e+00</td>\n",
       "      <td>1.400209e+00</td>\n",
       "      <td>6.746354e-01</td>\n",
       "      <td>3.808074e-01</td>\n",
       "      <td>1.645763e-01</td>\n",
       "      <td>3.974453e-01</td>\n",
       "      <td>5.254063e-01</td>\n",
       "      <td>3.652556e-01</td>\n",
       "      <td>3.133378e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.746966e-01</td>\n",
       "      <td>-2.434976e+00</td>\n",
       "      <td>-1.742508e+00</td>\n",
       "      <td>2.370088e-04</td>\n",
       "      <td>-1.743944e+00</td>\n",
       "      <td>1.375024e-01</td>\n",
       "      <td>-2.969725e+00</td>\n",
       "      <td>-1.741237e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.889811e-01</td>\n",
       "      <td>-2.913090e+00</td>\n",
       "      <td>-1.742372e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.636076e-01</td>\n",
       "      <td>-2.729663e+00</td>\n",
       "      <td>-1.742069e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.653542e-01</td>\n",
       "      <td>-2.497265e+00</td>\n",
       "      <td>-1.742691e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.507046e-02</td>\n",
       "      <td>1.986757e-01</td>\n",
       "      <td>8.304866e-02</td>\n",
       "      <td>1.320062e-01</td>\n",
       "      <td>4.786215e-02</td>\n",
       "      <td>2.951122e-01</td>\n",
       "      <td>3.307214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.907533e-01</td>\n",
       "      <td>-7.383225e-01</td>\n",
       "      <td>-8.719308e-01</td>\n",
       "      <td>5.768156e-01</td>\n",
       "      <td>-8.712081e-01</td>\n",
       "      <td>6.789927e-01</td>\n",
       "      <td>-6.872450e-01</td>\n",
       "      <td>-8.680962e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.564608e-01</td>\n",
       "      <td>-6.944718e-01</td>\n",
       "      <td>-8.701791e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.508527e-01</td>\n",
       "      <td>-6.998083e-01</td>\n",
       "      <td>-8.711343e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.177673e-01</td>\n",
       "      <td>-7.141902e-01</td>\n",
       "      <td>-8.714789e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.906095e-01</td>\n",
       "      <td>8.462266e-01</td>\n",
       "      <td>9.857525e-01</td>\n",
       "      <td>7.675732e-01</td>\n",
       "      <td>6.738168e-01</td>\n",
       "      <td>8.193964e-01</td>\n",
       "      <td>7.703901e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.533714e-01</td>\n",
       "      <td>-5.415563e-05</td>\n",
       "      <td>-2.410638e-04</td>\n",
       "      <td>8.916277e-01</td>\n",
       "      <td>2.125454e-04</td>\n",
       "      <td>8.948193e-01</td>\n",
       "      <td>-2.543566e-05</td>\n",
       "      <td>5.813991e-05</td>\n",
       "      <td>1.086538e+00</td>\n",
       "      <td>8.901377e-01</td>\n",
       "      <td>6.027267e-05</td>\n",
       "      <td>3.514990e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.972494e-01</td>\n",
       "      <td>1.728937e-04</td>\n",
       "      <td>-7.519117e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.682333e-01</td>\n",
       "      <td>3.721330e-04</td>\n",
       "      <td>-2.642369e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.949304e-01</td>\n",
       "      <td>9.506853e-01</td>\n",
       "      <td>9.897798e-01</td>\n",
       "      <td>9.165110e-01</td>\n",
       "      <td>8.733798e-01</td>\n",
       "      <td>9.473447e-01</td>\n",
       "      <td>8.719701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.236226e+00</td>\n",
       "      <td>7.382142e-01</td>\n",
       "      <td>8.709940e-01</td>\n",
       "      <td>1.293056e+00</td>\n",
       "      <td>8.714708e-01</td>\n",
       "      <td>1.170740e+00</td>\n",
       "      <td>6.871941e-01</td>\n",
       "      <td>8.683126e-01</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>1.201875e+00</td>\n",
       "      <td>6.945924e-01</td>\n",
       "      <td>8.698727e-01</td>\n",
       "      <td>2.214872e+00</td>\n",
       "      <td>1.221798e+00</td>\n",
       "      <td>7.001541e-01</td>\n",
       "      <td>8.713947e-01</td>\n",
       "      <td>2.548224e+00</td>\n",
       "      <td>1.220930e+00</td>\n",
       "      <td>7.141017e-01</td>\n",
       "      <td>8.716055e-01</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>1.024730e+00</td>\n",
       "      <td>1.083493e+00</td>\n",
       "      <td>1.020528e+00</td>\n",
       "      <td>1.142226e+00</td>\n",
       "      <td>1.138439e+00</td>\n",
       "      <td>1.140458e+00</td>\n",
       "      <td>1.059248e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.209891e+01</td>\n",
       "      <td>2.434868e+00</td>\n",
       "      <td>1.743236e+00</td>\n",
       "      <td>1.539682e+01</td>\n",
       "      <td>1.743257e+00</td>\n",
       "      <td>9.940391e+00</td>\n",
       "      <td>2.969674e+00</td>\n",
       "      <td>1.741454e+00</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>1.164708e+01</td>\n",
       "      <td>2.913210e+00</td>\n",
       "      <td>1.743175e+00</td>\n",
       "      <td>2.214872e+00</td>\n",
       "      <td>1.470899e+01</td>\n",
       "      <td>2.730009e+00</td>\n",
       "      <td>1.742884e+00</td>\n",
       "      <td>2.548224e+00</td>\n",
       "      <td>1.288257e+01</td>\n",
       "      <td>2.498009e+00</td>\n",
       "      <td>1.743372e+00</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>4.019237e+01</td>\n",
       "      <td>2.037278e+01</td>\n",
       "      <td>7.992739e+00</td>\n",
       "      <td>1.426244e+01</td>\n",
       "      <td>1.776285e+01</td>\n",
       "      <td>1.149652e+01</td>\n",
       "      <td>8.374498e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target     lepton_ph    lepton_eta    lepton_phi  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   5.299203e-01  9.914658e-01 -8.297618e-06 -1.327225e-05   \n",
       "std    4.991040e-01  5.653777e-01  1.008827e+00  1.006346e+00   \n",
       "min    0.000000e+00  2.746966e-01 -2.434976e+00 -1.742508e+00   \n",
       "25%    0.000000e+00  5.907533e-01 -7.383225e-01 -8.719308e-01   \n",
       "50%    1.000000e+00  8.533714e-01 -5.415563e-05 -2.410638e-04   \n",
       "75%    1.000000e+00  1.236226e+00  7.382142e-01  8.709940e-01   \n",
       "max    1.000000e+00  1.209891e+01  2.434868e+00  1.743236e+00   \n",
       "\n",
       "       missing_energy_magnitude  missing_energy_phi      jet_1_pt  \\\n",
       "count              1.100000e+07        1.100000e+07  1.100000e+07   \n",
       "mean               9.985364e-01        2.613459e-05  9.909152e-01   \n",
       "std                6.000185e-01        1.006326e+00  4.749747e-01   \n",
       "min                2.370088e-04       -1.743944e+00  1.375024e-01   \n",
       "25%                5.768156e-01       -8.712081e-01  6.789927e-01   \n",
       "50%                8.916277e-01        2.125454e-04  8.948193e-01   \n",
       "75%                1.293056e+00        8.714708e-01  1.170740e+00   \n",
       "max                1.539682e+01        1.743257e+00  9.940391e+00   \n",
       "\n",
       "          jet_1_eta     jet_1_phi    jet_1_btag      jet_2_pt     jet_2_eta  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean  -2.027520e-05  7.716199e-06  9.999687e-01  9.927294e-01 -1.026444e-05   \n",
       "std    1.009303e+00  1.005901e+00  1.027808e+00  4.999939e-01  1.009331e+00   \n",
       "min   -2.969725e+00 -1.741237e+00  0.000000e+00  1.889811e-01 -2.913090e+00   \n",
       "25%   -6.872450e-01 -8.680962e-01  0.000000e+00  6.564608e-01 -6.944718e-01   \n",
       "50%   -2.543566e-05  5.813991e-05  1.086538e+00  8.901377e-01  6.027267e-05   \n",
       "75%    6.871941e-01  8.683126e-01  2.173076e+00  1.201875e+00  6.945924e-01   \n",
       "max    2.969674e+00  1.741454e+00  2.173076e+00  1.164708e+01  2.913210e+00   \n",
       "\n",
       "          jet_2_phi    jet_2_btag      jet_3_pt     jet_3_eta     jet_3_phi  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean  -2.076887e-05  1.000008e+00  9.922591e-01  1.459561e-05  3.678632e-06   \n",
       "std    1.006154e+00  1.049398e+00  4.876623e-01  1.008747e+00  1.006305e+00   \n",
       "min   -1.742372e+00  0.000000e+00  2.636076e-01 -2.729663e+00 -1.742069e+00   \n",
       "25%   -8.701791e-01  0.000000e+00  6.508527e-01 -6.998083e-01 -8.711343e-01   \n",
       "50%    3.514990e-04  0.000000e+00  8.972494e-01  1.728937e-04 -7.519117e-04   \n",
       "75%    8.698727e-01  2.214872e+00  1.221798e+00  7.001541e-01  8.713947e-01   \n",
       "max    1.743175e+00  2.214872e+00  1.470899e+01  2.730009e+00  1.742884e+00   \n",
       "\n",
       "         jet_3_btag      jet_4_pt     jet_4_eta     jet_4_phi    jet_4_btag  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   1.000011e+00  9.861087e-01 -5.756954e-06  1.744903e-05  1.000000e+00   \n",
       "std    1.193676e+00  5.057777e-01  1.007694e+00  1.006366e+00  1.400209e+00   \n",
       "min    0.000000e+00  3.653542e-01 -2.497265e+00 -1.742691e+00  0.000000e+00   \n",
       "25%    0.000000e+00  6.177673e-01 -7.141902e-01 -8.714789e-01  0.000000e+00   \n",
       "50%    0.000000e+00  8.682333e-01  3.721330e-04 -2.642369e-04  0.000000e+00   \n",
       "75%    2.548224e+00  1.220930e+00  7.141017e-01  8.716055e-01  3.101961e+00   \n",
       "max    2.548224e+00  1.288257e+01  2.498009e+00  1.743372e+00  3.101961e+00   \n",
       "\n",
       "               m_jj         m_jjj          m_lv         m_jlv          m_bb  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   1.034290e+00  1.024805e+00  1.050554e+00  1.009742e+00  9.729596e-01   \n",
       "std    6.746354e-01  3.808074e-01  1.645763e-01  3.974453e-01  5.254063e-01   \n",
       "min    7.507046e-02  1.986757e-01  8.304866e-02  1.320062e-01  4.786215e-02   \n",
       "25%    7.906095e-01  8.462266e-01  9.857525e-01  7.675732e-01  6.738168e-01   \n",
       "50%    8.949304e-01  9.506853e-01  9.897798e-01  9.165110e-01  8.733798e-01   \n",
       "75%    1.024730e+00  1.083493e+00  1.020528e+00  1.142226e+00  1.138439e+00   \n",
       "max    4.019237e+01  2.037278e+01  7.992739e+00  1.426244e+01  1.776285e+01   \n",
       "\n",
       "              m_wbb        m_wwbb  \n",
       "count  1.100000e+07  1.100000e+07  \n",
       "mean   1.033036e+00  9.598120e-01  \n",
       "std    3.652556e-01  3.133378e-01  \n",
       "min    2.951122e-01  3.307214e-01  \n",
       "25%    8.193964e-01  7.703901e-01  \n",
       "50%    9.473447e-01  8.719701e-01  \n",
       "75%    1.140458e+00  1.059248e+00  \n",
       "max    1.149652e+01  8.374498e+00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figure out which columns have values strictly greater than 0, for scaler purposes\n",
    "pd.set_option(\"display.max_rows\", 500, \"display.max_columns\", None)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600000, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "pre_X = train.loc[:, df.columns != 'target']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(pre_X)\n",
    "X = pd.DataFrame(data=scaled_train, columns=pre_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not complete, need columns where mean=1 and stdev=1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#these columns scale where mean=0 and stdev=1\n",
    "to_scale1 = pre_X[['lepton_eta','lepton_phi','missing_energy_phi','jet_1_eta','jet_1_phi','jet_2_eta','jet_2_phi','jet_3_eta','jet_3_phi','jet_4_eta','jet_4_phi']]\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(to_scale1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_2_eta</th>\n",
       "      <th>jet_2_phi</th>\n",
       "      <th>jet_3_eta</th>\n",
       "      <th>jet_3_phi</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.131178e-17</td>\n",
       "      <td>8.924613e-17</td>\n",
       "      <td>-3.083901e-17</td>\n",
       "      <td>4.807138e-18</td>\n",
       "      <td>-4.718029e-17</td>\n",
       "      <td>-8.113305e-17</td>\n",
       "      <td>-2.608358e-17</td>\n",
       "      <td>2.121924e-16</td>\n",
       "      <td>-2.010950e-16</td>\n",
       "      <td>-8.899181e-17</td>\n",
       "      <td>2.780400e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.414452e+00</td>\n",
       "      <td>-1.731104e+00</td>\n",
       "      <td>-1.731925e+00</td>\n",
       "      <td>-2.942199e+00</td>\n",
       "      <td>-1.730027e+00</td>\n",
       "      <td>-2.885415e+00</td>\n",
       "      <td>-1.732408e+00</td>\n",
       "      <td>-2.705312e+00</td>\n",
       "      <td>-1.730599e+00</td>\n",
       "      <td>-2.479189e+00</td>\n",
       "      <td>-1.731107e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.321584e-01</td>\n",
       "      <td>-8.659604e-01</td>\n",
       "      <td>-8.658190e-01</td>\n",
       "      <td>-6.819477e-01</td>\n",
       "      <td>-8.632094e-01</td>\n",
       "      <td>-6.889230e-01</td>\n",
       "      <td>-8.647062e-01</td>\n",
       "      <td>-6.935506e-01</td>\n",
       "      <td>-8.659706e-01</td>\n",
       "      <td>-7.085818e-01</td>\n",
       "      <td>-8.667571e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.386904e-04</td>\n",
       "      <td>-1.365973e-03</td>\n",
       "      <td>2.090639e-04</td>\n",
       "      <td>-1.125500e-03</td>\n",
       "      <td>-7.977719e-04</td>\n",
       "      <td>9.082319e-04</td>\n",
       "      <td>8.939700e-04</td>\n",
       "      <td>1.093501e-03</td>\n",
       "      <td>3.138265e-04</td>\n",
       "      <td>6.528141e-04</td>\n",
       "      <td>-1.998949e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.318811e-01</td>\n",
       "      <td>8.655338e-01</td>\n",
       "      <td>8.662048e-01</td>\n",
       "      <td>6.806777e-01</td>\n",
       "      <td>8.628153e-01</td>\n",
       "      <td>6.888153e-01</td>\n",
       "      <td>8.641829e-01</td>\n",
       "      <td>6.939334e-01</td>\n",
       "      <td>8.661466e-01</td>\n",
       "      <td>7.082342e-01</td>\n",
       "      <td>8.659056e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.414175e+00</td>\n",
       "      <td>1.732883e+00</td>\n",
       "      <td>1.732090e+00</td>\n",
       "      <td>2.941910e+00</td>\n",
       "      <td>1.731837e+00</td>\n",
       "      <td>2.885307e+00</td>\n",
       "      <td>1.732988e+00</td>\n",
       "      <td>2.705695e+00</td>\n",
       "      <td>1.731326e+00</td>\n",
       "      <td>2.478841e+00</td>\n",
       "      <td>1.731909e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lepton_eta    lepton_phi  missing_energy_phi     jet_1_eta  \\\n",
       "count  2.600000e+06  2.600000e+06        2.600000e+06  2.600000e+06   \n",
       "mean   4.131178e-17  8.924613e-17       -3.083901e-17  4.807138e-18   \n",
       "std    1.000000e+00  1.000000e+00        1.000000e+00  1.000000e+00   \n",
       "min   -2.414452e+00 -1.731104e+00       -1.731925e+00 -2.942199e+00   \n",
       "25%   -7.321584e-01 -8.659604e-01       -8.658190e-01 -6.819477e-01   \n",
       "50%   -1.386904e-04 -1.365973e-03        2.090639e-04 -1.125500e-03   \n",
       "75%    7.318811e-01  8.655338e-01        8.662048e-01  6.806777e-01   \n",
       "max    2.414175e+00  1.732883e+00        1.732090e+00  2.941910e+00   \n",
       "\n",
       "          jet_1_phi     jet_2_eta     jet_2_phi     jet_3_eta     jet_3_phi  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean  -4.718029e-17 -8.113305e-17 -2.608358e-17  2.121924e-16 -2.010950e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.730027e+00 -2.885415e+00 -1.732408e+00 -2.705312e+00 -1.730599e+00   \n",
       "25%   -8.632094e-01 -6.889230e-01 -8.647062e-01 -6.935506e-01 -8.659706e-01   \n",
       "50%   -7.977719e-04  9.082319e-04  8.939700e-04  1.093501e-03  3.138265e-04   \n",
       "75%    8.628153e-01  6.888153e-01  8.641829e-01  6.939334e-01  8.661466e-01   \n",
       "max    1.731837e+00  2.885307e+00  1.732988e+00  2.705695e+00  1.731326e+00   \n",
       "\n",
       "          jet_4_eta     jet_4_phi  \n",
       "count  2.600000e+06  2.600000e+06  \n",
       "mean  -8.899181e-17  2.780400e-17  \n",
       "std    1.000000e+00  1.000000e+00  \n",
       "min   -2.479189e+00 -1.731107e+00  \n",
       "25%   -7.085818e-01 -8.667571e-01  \n",
       "50%    6.528141e-04 -1.998949e-04  \n",
       "75%    7.082342e-01  8.659056e-01  \n",
       "max    2.478841e+00  1.731909e+00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_df = pd.DataFrame(scaled_train, columns=['lepton_eta','lepton_phi','missing_energy_phi','jet_1_eta','jet_1_phi','jet_2_eta','jet_2_phi','jet_3_eta','jet_3_phi','jet_4_eta','jet_4_phi'])\n",
    "scaled_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=500000, random_state=1776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y_train.to_numpy()\n",
    "# type(np.unique(y)[0])\n",
    "\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100000, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton_ph</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_btag</th>\n",
       "      <th>jet_2_pt</th>\n",
       "      <th>jet_2_eta</th>\n",
       "      <th>jet_2_phi</th>\n",
       "      <th>jet_2_btag</th>\n",
       "      <th>jet_3_pt</th>\n",
       "      <th>jet_3_eta</th>\n",
       "      <th>jet_3_phi</th>\n",
       "      <th>jet_3_btag</th>\n",
       "      <th>jet_4_pt</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>2.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.290482e-02</td>\n",
       "      <td>5.000287e-01</td>\n",
       "      <td>4.997432e-01</td>\n",
       "      <td>7.768960e-02</td>\n",
       "      <td>4.999762e-01</td>\n",
       "      <td>1.011576e-01</td>\n",
       "      <td>5.000246e-01</td>\n",
       "      <td>4.997386e-01</td>\n",
       "      <td>4.598750e-01</td>\n",
       "      <td>8.221750e-02</td>\n",
       "      <td>5.000093e-01</td>\n",
       "      <td>4.999163e-01</td>\n",
       "      <td>4.513519e-01</td>\n",
       "      <td>5.045377e-02</td>\n",
       "      <td>4.999646e-01</td>\n",
       "      <td>4.998950e-01</td>\n",
       "      <td>3.924435e-01</td>\n",
       "      <td>4.962456e-02</td>\n",
       "      <td>5.000351e-01</td>\n",
       "      <td>4.998842e-01</td>\n",
       "      <td>3.226283e-01</td>\n",
       "      <td>3.259405e-02</td>\n",
       "      <td>5.394110e-02</td>\n",
       "      <td>1.390821e-01</td>\n",
       "      <td>7.079912e-02</td>\n",
       "      <td>6.737304e-02</td>\n",
       "      <td>8.381950e-02</td>\n",
       "      <td>9.688168e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.955006e-02</td>\n",
       "      <td>2.070983e-01</td>\n",
       "      <td>2.886848e-01</td>\n",
       "      <td>4.672872e-02</td>\n",
       "      <td>2.886824e-01</td>\n",
       "      <td>5.629750e-02</td>\n",
       "      <td>1.699493e-01</td>\n",
       "      <td>2.888618e-01</td>\n",
       "      <td>4.729015e-01</td>\n",
       "      <td>5.114958e-02</td>\n",
       "      <td>1.732886e-01</td>\n",
       "      <td>2.885673e-01</td>\n",
       "      <td>4.737810e-01</td>\n",
       "      <td>3.374349e-02</td>\n",
       "      <td>1.848085e-01</td>\n",
       "      <td>2.888566e-01</td>\n",
       "      <td>4.684384e-01</td>\n",
       "      <td>4.046157e-02</td>\n",
       "      <td>2.016931e-01</td>\n",
       "      <td>2.887657e-01</td>\n",
       "      <td>4.514692e-01</td>\n",
       "      <td>2.291845e-02</td>\n",
       "      <td>2.587445e-02</td>\n",
       "      <td>2.452874e-02</td>\n",
       "      <td>3.545985e-02</td>\n",
       "      <td>3.837583e-02</td>\n",
       "      <td>4.317710e-02</td>\n",
       "      <td>5.010340e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.775815e-02</td>\n",
       "      <td>3.484000e-01</td>\n",
       "      <td>2.497537e-01</td>\n",
       "      <td>4.483757e-02</td>\n",
       "      <td>2.500295e-01</td>\n",
       "      <td>6.416143e-02</td>\n",
       "      <td>3.841281e-01</td>\n",
       "      <td>2.503904e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.780415e-02</td>\n",
       "      <td>3.806269e-01</td>\n",
       "      <td>2.503904e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.680753e-02</td>\n",
       "      <td>3.717906e-01</td>\n",
       "      <td>2.497537e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.016529e-02</td>\n",
       "      <td>3.571191e-01</td>\n",
       "      <td>2.495945e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.429879e-02</td>\n",
       "      <td>4.180044e-02</td>\n",
       "      <td>1.294109e-01</td>\n",
       "      <td>4.918208e-02</td>\n",
       "      <td>4.549617e-02</td>\n",
       "      <td>5.856219e-02</td>\n",
       "      <td>6.658847e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.079630e-02</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>4.993489e-01</td>\n",
       "      <td>6.937425e-02</td>\n",
       "      <td>5.000365e-01</td>\n",
       "      <td>8.977824e-02</td>\n",
       "      <td>4.998333e-01</td>\n",
       "      <td>4.995081e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>7.171910e-02</td>\n",
       "      <td>5.001667e-01</td>\n",
       "      <td>5.001743e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.387682e-02</td>\n",
       "      <td>5.001667e-01</td>\n",
       "      <td>4.999856e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.017501e-02</td>\n",
       "      <td>5.001667e-01</td>\n",
       "      <td>4.998265e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.784232e-02</td>\n",
       "      <td>4.888833e-02</td>\n",
       "      <td>1.300110e-01</td>\n",
       "      <td>6.249474e-02</td>\n",
       "      <td>6.011345e-02</td>\n",
       "      <td>7.367504e-02</td>\n",
       "      <td>8.282983e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.435011e-02</td>\n",
       "      <td>6.516000e-01</td>\n",
       "      <td>7.496096e-01</td>\n",
       "      <td>1.005773e-01</td>\n",
       "      <td>7.500342e-01</td>\n",
       "      <td>1.224505e-01</td>\n",
       "      <td>6.157052e-01</td>\n",
       "      <td>7.489729e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.036014e-01</td>\n",
       "      <td>6.193731e-01</td>\n",
       "      <td>7.492913e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.638056e-02</td>\n",
       "      <td>6.282094e-01</td>\n",
       "      <td>7.500871e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.841030e-02</td>\n",
       "      <td>6.428810e-01</td>\n",
       "      <td>7.499280e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.226186e-02</td>\n",
       "      <td>5.793053e-02</td>\n",
       "      <td>1.346274e-01</td>\n",
       "      <td>8.262032e-02</td>\n",
       "      <td>7.949804e-02</td>\n",
       "      <td>9.648749e-02</td>\n",
       "      <td>1.127462e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lepton_ph    lepton_eta    lepton_phi  missing_energy_magnitude  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06              2.600000e+06   \n",
       "mean   6.290482e-02  5.000287e-01  4.997432e-01              7.768960e-02   \n",
       "std    4.955006e-02  2.070983e-01  2.886848e-01              4.672872e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00              0.000000e+00   \n",
       "25%    2.775815e-02  3.484000e-01  2.497537e-01              4.483757e-02   \n",
       "50%    5.079630e-02  5.000000e-01  4.993489e-01              6.937425e-02   \n",
       "75%    8.435011e-02  6.516000e-01  7.496096e-01              1.005773e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00              1.000000e+00   \n",
       "\n",
       "       missing_energy_phi      jet_1_pt     jet_1_eta     jet_1_phi  \\\n",
       "count        2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean         4.999762e-01  1.011576e-01  5.000246e-01  4.997386e-01   \n",
       "std          2.886824e-01  5.629750e-02  1.699493e-01  2.888618e-01   \n",
       "min          0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%          2.500295e-01  6.416143e-02  3.841281e-01  2.503904e-01   \n",
       "50%          5.000365e-01  8.977824e-02  4.998333e-01  4.995081e-01   \n",
       "75%          7.500342e-01  1.224505e-01  6.157052e-01  7.489729e-01   \n",
       "max          1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "         jet_1_btag      jet_2_pt     jet_2_eta     jet_2_phi    jet_2_btag  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean   4.598750e-01  8.221750e-02  5.000093e-01  4.999163e-01  4.513519e-01   \n",
       "std    4.729015e-01  5.114958e-02  1.732886e-01  2.885673e-01  4.737810e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  4.780415e-02  3.806269e-01  2.503904e-01  0.000000e+00   \n",
       "50%    5.000000e-01  7.171910e-02  5.001667e-01  5.001743e-01  0.000000e+00   \n",
       "75%    1.000000e+00  1.036014e-01  6.193731e-01  7.492913e-01  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           jet_3_pt     jet_3_eta     jet_3_phi    jet_3_btag      jet_4_pt  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean   5.045377e-02  4.999646e-01  4.998950e-01  3.924435e-01  4.962456e-02   \n",
       "std    3.374349e-02  1.848085e-01  2.888566e-01  4.684384e-01  4.046157e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.680753e-02  3.717906e-01  2.497537e-01  0.000000e+00  2.016529e-02   \n",
       "50%    4.387682e-02  5.001667e-01  4.999856e-01  0.000000e+00  4.017501e-02   \n",
       "75%    6.638056e-02  6.282094e-01  7.500871e-01  1.000000e+00  6.841030e-02   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          jet_4_eta     jet_4_phi    jet_4_btag          m_jj         m_jjj  \\\n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06   \n",
       "mean   5.000351e-01  4.998842e-01  3.226283e-01  3.259405e-02  5.394110e-02   \n",
       "std    2.016931e-01  2.887657e-01  4.514692e-01  2.291845e-02  2.587445e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    3.571191e-01  2.495945e-01  0.000000e+00  2.429879e-02  4.180044e-02   \n",
       "50%    5.001667e-01  4.998265e-01  0.000000e+00  2.784232e-02  4.888833e-02   \n",
       "75%    6.428810e-01  7.499280e-01  1.000000e+00  3.226186e-02  5.793053e-02   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "               m_lv         m_jlv          m_bb         m_wbb        m_wwbb  \n",
       "count  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  2.600000e+06  \n",
       "mean   1.390821e-01  7.079912e-02  6.737304e-02  8.381950e-02  9.688168e-02  \n",
       "std    2.452874e-02  3.545985e-02  3.837583e-02  4.317710e-02  5.010340e-02  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    1.294109e-01  4.918208e-02  4.549617e-02  5.856219e-02  6.658847e-02  \n",
       "50%    1.300110e-01  6.249474e-02  6.011345e-02  7.367504e-02  8.282983e-02  \n",
       "75%    1.346274e-01  8.262032e-02  7.949804e-02  9.648749e-02  1.127462e-01  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# input\n",
    "model.add(tf.keras.Input(shape=(28,)))\n",
    "# hidden\n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.1)))  \n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.05)))\n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.05)))\n",
    "model.add(layers.Dense(300,\n",
    "                       activation='tanh', \n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.05)))\n",
    "model.add(layers.Dense(1,\n",
    "                       activation='sigmoid',\n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.001)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=1e-5)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2100000 samples, validate on 500000 samples\n",
      "Epoch 1/250\n",
      "2100000/2100000 [==============================] - 183s 87us/sample - loss: 0.6558 - AUC: 0.6438 - val_loss: 0.6422 - val_AUC: 0.6778\n",
      "Epoch 2/250\n",
      "2100000/2100000 [==============================] - 180s 86us/sample - loss: 0.6426 - AUC: 0.6699 - val_loss: 0.6362 - val_AUC: 0.6837\n",
      "Epoch 3/250\n",
      "2100000/2100000 [==============================] - 178s 85us/sample - loss: 0.6298 - AUC: 0.6933 - val_loss: 0.6182 - val_AUC: 0.7212\n",
      "Epoch 4/250\n",
      "2100000/2100000 [==============================] - 180s 86us/sample - loss: 0.6140 - AUC: 0.7177 - val_loss: 0.6130 - val_AUC: 0.7290\n",
      "Epoch 5/250\n",
      "2100000/2100000 [==============================] - 179s 85us/sample - loss: 0.6007 - AUC: 0.7359 - val_loss: 0.5878 - val_AUC: 0.7523\n",
      "Epoch 6/250\n",
      "2100000/2100000 [==============================] - 182s 87us/sample - loss: 0.5911 - AUC: 0.7474 - val_loss: 0.5875 - val_AUC: 0.7529\n",
      "Epoch 7/250\n",
      "2100000/2100000 [==============================] - 175s 83us/sample - loss: 0.5840 - AUC: 0.7552 - val_loss: 0.5768 - val_AUC: 0.7638\n",
      "Epoch 8/250\n",
      "2100000/2100000 [==============================] - 174s 83us/sample - loss: 0.5780 - AUC: 0.7615 - val_loss: 0.5851 - val_AUC: 0.7625\n",
      "Epoch 9/250\n",
      "2100000/2100000 [==============================] - 151s 72us/sample - loss: 0.5732 - AUC: 0.7668 - val_loss: 0.5697 - val_AUC: 0.7707\n",
      "Epoch 10/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.5687 - AUC: 0.7715 - val_loss: 0.5725 - val_AUC: 0.7698\n",
      "Epoch 11/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.5642 - AUC: 0.7762 - val_loss: 0.5545 - val_AUC: 0.7861\n",
      "Epoch 12/250\n",
      "2100000/2100000 [==============================] - 146s 70us/sample - loss: 0.5597 - AUC: 0.7807 - val_loss: 0.5839 - val_AUC: 0.7556\n",
      "Epoch 13/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.5553 - AUC: 0.7851 - val_loss: 0.5564 - val_AUC: 0.7839\n",
      "Epoch 14/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.5514 - AUC: 0.7889 - val_loss: 0.5572 - val_AUC: 0.7883\n",
      "Epoch 15/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.5481 - AUC: 0.7920 - val_loss: 0.5477 - val_AUC: 0.7945\n",
      "Epoch 16/250\n",
      "2100000/2100000 [==============================] - 149s 71us/sample - loss: 0.5450 - AUC: 0.7949 - val_loss: 0.5379 - val_AUC: 0.8018\n",
      "Epoch 17/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.5426 - AUC: 0.7972 - val_loss: 0.5501 - val_AUC: 0.7961\n",
      "Epoch 18/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.5400 - AUC: 0.7996 - val_loss: 0.5400 - val_AUC: 0.7997\n",
      "Epoch 19/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.5376 - AUC: 0.8017 - val_loss: 0.5338 - val_AUC: 0.8067\n",
      "Epoch 20/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.5352 - AUC: 0.8038 - val_loss: 0.5342 - val_AUC: 0.8050\n",
      "Epoch 21/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.5331 - AUC: 0.8057 - val_loss: 0.5359 - val_AUC: 0.8042\n",
      "Epoch 22/250\n",
      "2100000/2100000 [==============================] - 144s 68us/sample - loss: 0.5308 - AUC: 0.8077 - val_loss: 0.5382 - val_AUC: 0.8079\n",
      "Epoch 23/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.5285 - AUC: 0.8097 - val_loss: 0.5288 - val_AUC: 0.8113\n",
      "Epoch 24/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.5263 - AUC: 0.8116 - val_loss: 0.5224 - val_AUC: 0.8149\n",
      "Epoch 25/250\n",
      "2100000/2100000 [==============================] - 146s 70us/sample - loss: 0.5244 - AUC: 0.8132 - val_loss: 0.5320 - val_AUC: 0.8084\n",
      "Epoch 26/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.5228 - AUC: 0.8146 - val_loss: 0.5260 - val_AUC: 0.8147\n",
      "Epoch 27/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.5212 - AUC: 0.8159 - val_loss: 0.5264 - val_AUC: 0.8146\n",
      "Epoch 28/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.5197 - AUC: 0.8172 - val_loss: 0.5162 - val_AUC: 0.8201\n",
      "Epoch 29/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.5183 - AUC: 0.8184 - val_loss: 0.5151 - val_AUC: 0.8218\n",
      "Epoch 30/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.5169 - AUC: 0.8195 - val_loss: 0.5210 - val_AUC: 0.8187\n",
      "Epoch 31/250\n",
      "2100000/2100000 [==============================] - 147s 70us/sample - loss: 0.5158 - AUC: 0.8204 - val_loss: 0.5189 - val_AUC: 0.8178\n",
      "Epoch 32/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.5146 - AUC: 0.8214 - val_loss: 0.5208 - val_AUC: 0.8177\n",
      "Epoch 33/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.5135 - AUC: 0.8222 - val_loss: 0.5092 - val_AUC: 0.8260\n",
      "Epoch 34/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.5124 - AUC: 0.8231 - val_loss: 0.5119 - val_AUC: 0.8238\n",
      "Epoch 35/250\n",
      "2100000/2100000 [==============================] - 144s 68us/sample - loss: 0.5113 - AUC: 0.8240 - val_loss: 0.5165 - val_AUC: 0.8214\n",
      "Epoch 36/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.5102 - AUC: 0.8249 - val_loss: 0.5093 - val_AUC: 0.8257\n",
      "Epoch 37/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.5094 - AUC: 0.8255 - val_loss: 0.5088 - val_AUC: 0.8280\n",
      "Epoch 38/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.5084 - AUC: 0.8263 - val_loss: 0.5106 - val_AUC: 0.8247\n",
      "Epoch 39/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.5076 - AUC: 0.8269 - val_loss: 0.5103 - val_AUC: 0.8248\n",
      "Epoch 40/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.5068 - AUC: 0.8275 - val_loss: 0.5088 - val_AUC: 0.8276\n",
      "Epoch 41/250\n",
      "2100000/2100000 [==============================] - 144s 68us/sample - loss: 0.5060 - AUC: 0.8282 - val_loss: 0.5019 - val_AUC: 0.8320\n",
      "Epoch 42/250\n",
      "2100000/2100000 [==============================] - 138s 66us/sample - loss: 0.5051 - AUC: 0.8289 - val_loss: 0.5120 - val_AUC: 0.8242\n",
      "Epoch 43/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.5044 - AUC: 0.8295 - val_loss: 0.5175 - val_AUC: 0.8230\n",
      "Epoch 44/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.5036 - AUC: 0.8300 - val_loss: 0.5043 - val_AUC: 0.8298\n",
      "Epoch 45/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.5029 - AUC: 0.8306 - val_loss: 0.5048 - val_AUC: 0.8300\n",
      "Epoch 46/250\n",
      "2100000/2100000 [==============================] - 148s 71us/sample - loss: 0.5022 - AUC: 0.8311 - val_loss: 0.5122 - val_AUC: 0.8243\n",
      "Epoch 47/250\n",
      "2100000/2100000 [==============================] - 159s 76us/sample - loss: 0.5015 - AUC: 0.8317 - val_loss: 0.4991 - val_AUC: 0.8335\n",
      "Epoch 48/250\n",
      "2100000/2100000 [==============================] - 157s 75us/sample - loss: 0.5010 - AUC: 0.8321 - val_loss: 0.5006 - val_AUC: 0.8332\n",
      "Epoch 49/250\n",
      "2100000/2100000 [==============================] - 159s 76us/sample - loss: 0.5003 - AUC: 0.8326 - val_loss: 0.5104 - val_AUC: 0.8267\n",
      "Epoch 50/250\n",
      "2100000/2100000 [==============================] - 144s 69us/sample - loss: 0.4995 - AUC: 0.8332 - val_loss: 0.5084 - val_AUC: 0.8303\n",
      "Epoch 51/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4989 - AUC: 0.8337 - val_loss: 0.5008 - val_AUC: 0.8336\n",
      "Epoch 52/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4983 - AUC: 0.8341 - val_loss: 0.4982 - val_AUC: 0.8344\n",
      "Epoch 53/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4976 - AUC: 0.8347 - val_loss: 0.4964 - val_AUC: 0.8358\n",
      "Epoch 54/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4970 - AUC: 0.8351 - val_loss: 0.4981 - val_AUC: 0.8344\n",
      "Epoch 55/250\n",
      "2100000/2100000 [==============================] - 138s 66us/sample - loss: 0.4965 - AUC: 0.8355 - val_loss: 0.4974 - val_AUC: 0.8351\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100000/2100000 [==============================] - 146s 69us/sample - loss: 0.4960 - AUC: 0.8359 - val_loss: 0.5056 - val_AUC: 0.8286\n",
      "Epoch 57/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4953 - AUC: 0.8364 - val_loss: 0.5026 - val_AUC: 0.8310\n",
      "Epoch 58/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4947 - AUC: 0.8368 - val_loss: 0.4950 - val_AUC: 0.8372\n",
      "Epoch 59/250\n",
      "2100000/2100000 [==============================] - 152s 72us/sample - loss: 0.4944 - AUC: 0.8371 - val_loss: 0.5005 - val_AUC: 0.8329\n",
      "Epoch 60/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.4938 - AUC: 0.8375 - val_loss: 0.4942 - val_AUC: 0.8375\n",
      "Epoch 61/250\n",
      "2100000/2100000 [==============================] - 138s 66us/sample - loss: 0.4931 - AUC: 0.8380 - val_loss: 0.4953 - val_AUC: 0.8365\n",
      "Epoch 62/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4926 - AUC: 0.8384 - val_loss: 0.4960 - val_AUC: 0.8367\n",
      "Epoch 63/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4922 - AUC: 0.8388 - val_loss: 0.4931 - val_AUC: 0.8381\n",
      "Epoch 64/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4917 - AUC: 0.8391 - val_loss: 0.4969 - val_AUC: 0.8358\n",
      "Epoch 65/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4912 - AUC: 0.8395 - val_loss: 0.4989 - val_AUC: 0.8342\n",
      "Epoch 66/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4908 - AUC: 0.8398 - val_loss: 0.4948 - val_AUC: 0.8374\n",
      "Epoch 67/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4902 - AUC: 0.8402 - val_loss: 0.4957 - val_AUC: 0.8365\n",
      "Epoch 68/250\n",
      "2100000/2100000 [==============================] - 147s 70us/sample - loss: 0.4897 - AUC: 0.8406 - val_loss: 0.4925 - val_AUC: 0.8387\n",
      "Epoch 69/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4891 - AUC: 0.8410 - val_loss: 0.4935 - val_AUC: 0.8378\n",
      "Epoch 70/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4888 - AUC: 0.8412 - val_loss: 0.4917 - val_AUC: 0.8398\n",
      "Epoch 71/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4883 - AUC: 0.8416 - val_loss: 0.5052 - val_AUC: 0.8341\n",
      "Epoch 72/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4878 - AUC: 0.8420 - val_loss: 0.4917 - val_AUC: 0.8394\n",
      "Epoch 73/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4873 - AUC: 0.8424 - val_loss: 0.4938 - val_AUC: 0.8387\n",
      "Epoch 74/250\n",
      "2100000/2100000 [==============================] - 144s 69us/sample - loss: 0.4869 - AUC: 0.8426 - val_loss: 0.4934 - val_AUC: 0.8382\n",
      "Epoch 75/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4865 - AUC: 0.8429 - val_loss: 0.4912 - val_AUC: 0.8397\n",
      "Epoch 76/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4861 - AUC: 0.8432 - val_loss: 0.4969 - val_AUC: 0.8353\n",
      "Epoch 77/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4855 - AUC: 0.8436 - val_loss: 0.4958 - val_AUC: 0.8364\n",
      "Epoch 78/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4853 - AUC: 0.8439 - val_loss: 0.4909 - val_AUC: 0.8402\n",
      "Epoch 79/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4848 - AUC: 0.8442 - val_loss: 0.4925 - val_AUC: 0.8395\n",
      "Epoch 80/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4844 - AUC: 0.8445 - val_loss: 0.4998 - val_AUC: 0.8337\n",
      "Epoch 81/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4840 - AUC: 0.8448 - val_loss: 0.4936 - val_AUC: 0.8394\n",
      "Epoch 82/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4836 - AUC: 0.8451 - val_loss: 0.4907 - val_AUC: 0.8410\n",
      "Epoch 83/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4833 - AUC: 0.8453 - val_loss: 0.4904 - val_AUC: 0.8406\n",
      "Epoch 84/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4829 - AUC: 0.8456 - val_loss: 0.4891 - val_AUC: 0.8420\n",
      "Epoch 85/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4824 - AUC: 0.8459 - val_loss: 0.4901 - val_AUC: 0.8409\n",
      "Epoch 86/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4821 - AUC: 0.8462 - val_loss: 0.4949 - val_AUC: 0.8372\n",
      "Epoch 87/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4817 - AUC: 0.8464 - val_loss: 0.4971 - val_AUC: 0.8354\n",
      "Epoch 88/250\n",
      "2100000/2100000 [==============================] - 152s 72us/sample - loss: 0.4814 - AUC: 0.8466 - val_loss: 0.4889 - val_AUC: 0.8414\n",
      "Epoch 89/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4810 - AUC: 0.8470 - val_loss: 0.4903 - val_AUC: 0.8406\n",
      "Epoch 90/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4806 - AUC: 0.8473 - val_loss: 0.4915 - val_AUC: 0.8395\n",
      "Epoch 91/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4802 - AUC: 0.8475 - val_loss: 0.4909 - val_AUC: 0.8400\n",
      "Epoch 92/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4799 - AUC: 0.8477 - val_loss: 0.4939 - val_AUC: 0.8390\n",
      "Epoch 93/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4794 - AUC: 0.8481 - val_loss: 0.4881 - val_AUC: 0.8417\n",
      "Epoch 94/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4792 - AUC: 0.8483 - val_loss: 0.4903 - val_AUC: 0.8404\n",
      "Epoch 95/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4788 - AUC: 0.8485 - val_loss: 0.4880 - val_AUC: 0.8421\n",
      "Epoch 96/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4784 - AUC: 0.8488 - val_loss: 0.4870 - val_AUC: 0.8435\n",
      "Epoch 97/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4781 - AUC: 0.8491 - val_loss: 0.4893 - val_AUC: 0.8409\n",
      "Epoch 98/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4777 - AUC: 0.8493 - val_loss: 0.4887 - val_AUC: 0.8419\n",
      "Epoch 99/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4774 - AUC: 0.8495 - val_loss: 0.4929 - val_AUC: 0.8383\n",
      "Epoch 100/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4770 - AUC: 0.8498 - val_loss: 0.4877 - val_AUC: 0.8424\n",
      "Epoch 101/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.4767 - AUC: 0.8500 - val_loss: 0.4938 - val_AUC: 0.8413\n",
      "Epoch 102/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4764 - AUC: 0.8503 - val_loss: 0.4863 - val_AUC: 0.8439\n",
      "Epoch 103/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4760 - AUC: 0.8505 - val_loss: 0.4889 - val_AUC: 0.8419\n",
      "Epoch 104/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4757 - AUC: 0.8507 - val_loss: 0.4897 - val_AUC: 0.8409\n",
      "Epoch 105/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4753 - AUC: 0.8511 - val_loss: 0.4876 - val_AUC: 0.8425\n",
      "Epoch 106/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4749 - AUC: 0.8513 - val_loss: 0.4887 - val_AUC: 0.8419\n",
      "Epoch 107/250\n",
      "2100000/2100000 [==============================] - 146s 69us/sample - loss: 0.4747 - AUC: 0.8514 - val_loss: 0.4879 - val_AUC: 0.8425\n",
      "Epoch 108/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4743 - AUC: 0.8517 - val_loss: 0.4853 - val_AUC: 0.8442\n",
      "Epoch 109/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4739 - AUC: 0.8520 - val_loss: 0.4863 - val_AUC: 0.8436\n",
      "Epoch 110/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4736 - AUC: 0.8522 - val_loss: 0.4871 - val_AUC: 0.8430\n",
      "Epoch 111/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.4733 - AUC: 0.8524 - val_loss: 0.4912 - val_AUC: 0.8414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.4729 - AUC: 0.8527 - val_loss: 0.4882 - val_AUC: 0.8427\n",
      "Epoch 113/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4727 - AUC: 0.8529 - val_loss: 0.4894 - val_AUC: 0.8413\n",
      "Epoch 114/250\n",
      "2100000/2100000 [==============================] - 144s 68us/sample - loss: 0.4722 - AUC: 0.8532 - val_loss: 0.4926 - val_AUC: 0.8388\n",
      "Epoch 115/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4719 - AUC: 0.8534 - val_loss: 0.4869 - val_AUC: 0.8432\n",
      "Epoch 116/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4716 - AUC: 0.8536 - val_loss: 0.4899 - val_AUC: 0.8413\n",
      "Epoch 117/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4713 - AUC: 0.8538 - val_loss: 0.4913 - val_AUC: 0.8402\n",
      "Epoch 118/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4710 - AUC: 0.8541 - val_loss: 0.4898 - val_AUC: 0.8411\n",
      "Epoch 119/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4706 - AUC: 0.8543 - val_loss: 0.4883 - val_AUC: 0.8421\n",
      "Epoch 120/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4703 - AUC: 0.8545 - val_loss: 0.4921 - val_AUC: 0.8412\n",
      "Epoch 121/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4699 - AUC: 0.8548 - val_loss: 0.4895 - val_AUC: 0.8416\n",
      "Epoch 122/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4698 - AUC: 0.8549 - val_loss: 0.4917 - val_AUC: 0.8416\n",
      "Epoch 123/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4694 - AUC: 0.8551 - val_loss: 0.4876 - val_AUC: 0.8423\n",
      "Epoch 124/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4689 - AUC: 0.8555 - val_loss: 0.4882 - val_AUC: 0.8425\n",
      "Epoch 125/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4687 - AUC: 0.8556 - val_loss: 0.4909 - val_AUC: 0.8401\n",
      "Epoch 126/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4684 - AUC: 0.8559 - val_loss: 0.4918 - val_AUC: 0.8402\n",
      "Epoch 127/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4682 - AUC: 0.8560 - val_loss: 0.4938 - val_AUC: 0.8385\n",
      "Epoch 128/250\n",
      "2100000/2100000 [==============================] - 142s 67us/sample - loss: 0.4677 - AUC: 0.8563 - val_loss: 0.4864 - val_AUC: 0.8439\n",
      "Epoch 129/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4674 - AUC: 0.8566 - val_loss: 0.4874 - val_AUC: 0.8438\n",
      "Epoch 130/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4670 - AUC: 0.8568 - val_loss: 0.4923 - val_AUC: 0.8410\n",
      "Epoch 131/250\n",
      "2100000/2100000 [==============================] - 138s 66us/sample - loss: 0.4668 - AUC: 0.8569 - val_loss: 0.4902 - val_AUC: 0.8419\n",
      "Epoch 132/250\n",
      "2100000/2100000 [==============================] - 144s 69us/sample - loss: 0.4665 - AUC: 0.8572 - val_loss: 0.4932 - val_AUC: 0.8397\n",
      "Epoch 133/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.4662 - AUC: 0.8574 - val_loss: 0.4896 - val_AUC: 0.8414\n",
      "Epoch 134/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4659 - AUC: 0.8576 - val_loss: 0.4872 - val_AUC: 0.8431\n",
      "Epoch 135/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4655 - AUC: 0.8578 - val_loss: 0.4942 - val_AUC: 0.8411\n",
      "Epoch 136/250\n",
      "2100000/2100000 [==============================] - 148s 71us/sample - loss: 0.4651 - AUC: 0.8581 - val_loss: 0.4891 - val_AUC: 0.8419\n",
      "Epoch 137/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4648 - AUC: 0.8583 - val_loss: 0.4884 - val_AUC: 0.8422\n",
      "Epoch 138/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4646 - AUC: 0.8584 - val_loss: 0.4882 - val_AUC: 0.8424\n",
      "Epoch 139/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4643 - AUC: 0.8587 - val_loss: 0.4916 - val_AUC: 0.8400\n",
      "Epoch 140/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.4640 - AUC: 0.8588 - val_loss: 0.4883 - val_AUC: 0.8430\n",
      "Epoch 141/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4635 - AUC: 0.8592 - val_loss: 0.4882 - val_AUC: 0.8426\n",
      "Epoch 142/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4633 - AUC: 0.8594 - val_loss: 0.4895 - val_AUC: 0.8420\n",
      "Epoch 143/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4631 - AUC: 0.8595 - val_loss: 0.4952 - val_AUC: 0.8387\n",
      "Epoch 144/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4626 - AUC: 0.8598 - val_loss: 0.4903 - val_AUC: 0.8409\n",
      "Epoch 145/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4624 - AUC: 0.8599 - val_loss: 0.4898 - val_AUC: 0.8417\n",
      "Epoch 146/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4622 - AUC: 0.8601 - val_loss: 0.4911 - val_AUC: 0.8410\n",
      "Epoch 147/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4618 - AUC: 0.8604 - val_loss: 0.4897 - val_AUC: 0.8423\n",
      "Epoch 148/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4615 - AUC: 0.8606 - val_loss: 0.4888 - val_AUC: 0.8428\n",
      "Epoch 149/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4612 - AUC: 0.8608 - val_loss: 0.4948 - val_AUC: 0.8386\n",
      "Epoch 150/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4609 - AUC: 0.8610 - val_loss: 0.4950 - val_AUC: 0.8374\n",
      "Epoch 151/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4607 - AUC: 0.8611 - val_loss: 0.4911 - val_AUC: 0.8410\n",
      "Epoch 152/250\n",
      "2100000/2100000 [==============================] - 146s 69us/sample - loss: 0.4602 - AUC: 0.8614 - val_loss: 0.4938 - val_AUC: 0.8395\n",
      "Epoch 153/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4599 - AUC: 0.8616 - val_loss: 0.4922 - val_AUC: 0.8409\n",
      "Epoch 154/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4597 - AUC: 0.8618 - val_loss: 0.4898 - val_AUC: 0.8416\n",
      "Epoch 155/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4593 - AUC: 0.8620 - val_loss: 0.4922 - val_AUC: 0.8405\n",
      "Epoch 156/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4590 - AUC: 0.8622 - val_loss: 0.4980 - val_AUC: 0.8365\n",
      "Epoch 157/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4589 - AUC: 0.8624 - val_loss: 0.4936 - val_AUC: 0.8402\n",
      "Epoch 158/250\n",
      "2100000/2100000 [==============================] - 152s 72us/sample - loss: 0.4585 - AUC: 0.8626 - val_loss: 0.4970 - val_AUC: 0.8394\n",
      "Epoch 159/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4581 - AUC: 0.8628 - val_loss: 0.4905 - val_AUC: 0.8410\n",
      "Epoch 160/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4577 - AUC: 0.8631 - val_loss: 0.4942 - val_AUC: 0.8395\n",
      "Epoch 161/250\n",
      "2100000/2100000 [==============================] - 148s 70us/sample - loss: 0.4575 - AUC: 0.8633 - val_loss: 0.4985 - val_AUC: 0.8354\n",
      "Epoch 162/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4573 - AUC: 0.8634 - val_loss: 0.4955 - val_AUC: 0.8399\n",
      "Epoch 163/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4569 - AUC: 0.8636 - val_loss: 0.4929 - val_AUC: 0.8405\n",
      "Epoch 164/250\n",
      "2100000/2100000 [==============================] - 147s 70us/sample - loss: 0.4568 - AUC: 0.8637 - val_loss: 0.4923 - val_AUC: 0.8399\n",
      "Epoch 165/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4564 - AUC: 0.8640 - val_loss: 0.4935 - val_AUC: 0.8392\n",
      "Epoch 166/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.4560 - AUC: 0.8643 - val_loss: 0.4947 - val_AUC: 0.8387\n",
      "Epoch 167/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4557 - AUC: 0.8645 - val_loss: 0.4954 - val_AUC: 0.8390\n",
      "Epoch 168/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4555 - AUC: 0.8646 - val_loss: 0.4953 - val_AUC: 0.8401\n",
      "Epoch 169/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4553 - AUC: 0.8647 - val_loss: 0.4960 - val_AUC: 0.8383\n",
      "Epoch 170/250\n",
      "2100000/2100000 [==============================] - 142s 67us/sample - loss: 0.4549 - AUC: 0.8650 - val_loss: 0.4989 - val_AUC: 0.8384\n",
      "Epoch 171/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4546 - AUC: 0.8652 - val_loss: 0.4954 - val_AUC: 0.8386\n",
      "Epoch 172/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4542 - AUC: 0.8654 - val_loss: 0.4954 - val_AUC: 0.8389\n",
      "Epoch 173/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4539 - AUC: 0.8656 - val_loss: 0.4943 - val_AUC: 0.8394\n",
      "Epoch 174/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4537 - AUC: 0.8658 - val_loss: 0.5016 - val_AUC: 0.8350\n",
      "Epoch 175/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4535 - AUC: 0.8659 - val_loss: 0.4975 - val_AUC: 0.8389\n",
      "Epoch 176/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4531 - AUC: 0.8662 - val_loss: 0.4957 - val_AUC: 0.8403\n",
      "Epoch 177/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4529 - AUC: 0.8663 - val_loss: 0.4969 - val_AUC: 0.8390\n",
      "Epoch 178/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4524 - AUC: 0.8666 - val_loss: 0.4996 - val_AUC: 0.8364\n",
      "Epoch 179/250\n",
      "2100000/2100000 [==============================] - 144s 68us/sample - loss: 0.4522 - AUC: 0.8667 - val_loss: 0.4987 - val_AUC: 0.8378\n",
      "Epoch 180/250\n",
      "2100000/2100000 [==============================] - 144s 68us/sample - loss: 0.4520 - AUC: 0.8669 - val_loss: 0.4989 - val_AUC: 0.8375\n",
      "Epoch 181/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4517 - AUC: 0.8671 - val_loss: 0.4969 - val_AUC: 0.8380\n",
      "Epoch 182/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4515 - AUC: 0.8672 - val_loss: 0.4971 - val_AUC: 0.8384\n",
      "Epoch 183/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.4512 - AUC: 0.8674 - val_loss: 0.4983 - val_AUC: 0.8383\n",
      "Epoch 184/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4508 - AUC: 0.8677 - val_loss: 0.5004 - val_AUC: 0.8359\n",
      "Epoch 185/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4505 - AUC: 0.8679 - val_loss: 0.5065 - val_AUC: 0.8356\n",
      "Epoch 186/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4502 - AUC: 0.8681 - val_loss: 0.5076 - val_AUC: 0.8364\n",
      "Epoch 187/250\n",
      "2100000/2100000 [==============================] - 149s 71us/sample - loss: 0.4500 - AUC: 0.8682 - val_loss: 0.5010 - val_AUC: 0.8369\n",
      "Epoch 188/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4497 - AUC: 0.8684 - val_loss: 0.5008 - val_AUC: 0.8365\n",
      "Epoch 189/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4494 - AUC: 0.8686 - val_loss: 0.5001 - val_AUC: 0.8363\n",
      "Epoch 190/250\n",
      "2100000/2100000 [==============================] - 151s 72us/sample - loss: 0.4491 - AUC: 0.8687 - val_loss: 0.4979 - val_AUC: 0.8381\n",
      "Epoch 191/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.4488 - AUC: 0.8689 - val_loss: 0.5022 - val_AUC: 0.8362\n",
      "Epoch 192/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4486 - AUC: 0.8691 - val_loss: 0.4979 - val_AUC: 0.8374\n",
      "Epoch 193/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4483 - AUC: 0.8693 - val_loss: 0.5032 - val_AUC: 0.8349\n",
      "Epoch 194/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4480 - AUC: 0.8695 - val_loss: 0.5010 - val_AUC: 0.8364\n",
      "Epoch 195/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4478 - AUC: 0.8696 - val_loss: 0.5007 - val_AUC: 0.8362\n",
      "Epoch 196/250\n",
      "2100000/2100000 [==============================] - 150s 72us/sample - loss: 0.4476 - AUC: 0.8697 - val_loss: 0.5066 - val_AUC: 0.8312\n",
      "Epoch 197/250\n",
      "2100000/2100000 [==============================] - 152s 72us/sample - loss: 0.4473 - AUC: 0.8699 - val_loss: 0.5042 - val_AUC: 0.8345\n",
      "Epoch 198/250\n",
      "2100000/2100000 [==============================] - 155s 74us/sample - loss: 0.4470 - AUC: 0.8701 - val_loss: 0.5074 - val_AUC: 0.8306\n",
      "Epoch 199/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4467 - AUC: 0.8703 - val_loss: 0.5016 - val_AUC: 0.8352\n",
      "Epoch 200/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4464 - AUC: 0.8705 - val_loss: 0.5024 - val_AUC: 0.8356\n",
      "Epoch 201/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4461 - AUC: 0.8707 - val_loss: 0.5040 - val_AUC: 0.8351\n",
      "Epoch 202/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4459 - AUC: 0.8708 - val_loss: 0.5020 - val_AUC: 0.8358\n",
      "Epoch 203/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4457 - AUC: 0.8710 - val_loss: 0.5034 - val_AUC: 0.8358\n",
      "Epoch 204/250\n",
      "2100000/2100000 [==============================] - 138s 66us/sample - loss: 0.4453 - AUC: 0.8712 - val_loss: 0.5040 - val_AUC: 0.8346\n",
      "Epoch 205/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4451 - AUC: 0.8713 - val_loss: 0.5041 - val_AUC: 0.8338\n",
      "Epoch 206/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.4449 - AUC: 0.8715 - val_loss: 0.5027 - val_AUC: 0.8347\n",
      "Epoch 207/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4447 - AUC: 0.8716 - val_loss: 0.5088 - val_AUC: 0.8332\n",
      "Epoch 208/250\n",
      "2100000/2100000 [==============================] - 146s 70us/sample - loss: 0.4444 - AUC: 0.8718 - val_loss: 0.5056 - val_AUC: 0.8338\n",
      "Epoch 209/250\n",
      "2100000/2100000 [==============================] - 160s 76us/sample - loss: 0.4442 - AUC: 0.8719 - val_loss: 0.5059 - val_AUC: 0.8325\n",
      "Epoch 210/250\n",
      "2100000/2100000 [==============================] - 167s 80us/sample - loss: 0.4441 - AUC: 0.8720 - val_loss: 0.5038 - val_AUC: 0.8345\n",
      "Epoch 211/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4436 - AUC: 0.8723 - val_loss: 0.5035 - val_AUC: 0.8352\n",
      "Epoch 212/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4434 - AUC: 0.8724 - val_loss: 0.5051 - val_AUC: 0.8335\n",
      "Epoch 213/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4432 - AUC: 0.8726 - val_loss: 0.5059 - val_AUC: 0.8352\n",
      "Epoch 214/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4428 - AUC: 0.8728 - val_loss: 0.5087 - val_AUC: 0.8334\n",
      "Epoch 215/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4427 - AUC: 0.8729 - val_loss: 0.5060 - val_AUC: 0.8342\n",
      "Epoch 216/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4424 - AUC: 0.8731 - val_loss: 0.5087 - val_AUC: 0.8353\n",
      "Epoch 217/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4421 - AUC: 0.8732 - val_loss: 0.5082 - val_AUC: 0.8326\n",
      "Epoch 218/250\n",
      "2100000/2100000 [==============================] - 142s 67us/sample - loss: 0.4422 - AUC: 0.8732 - val_loss: 0.5096 - val_AUC: 0.8318\n",
      "Epoch 219/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4416 - AUC: 0.8736 - val_loss: 0.5082 - val_AUC: 0.8333\n",
      "Epoch 220/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.4416 - AUC: 0.8735 - val_loss: 0.5083 - val_AUC: 0.8328\n",
      "Epoch 221/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4412 - AUC: 0.8738 - val_loss: 0.5103 - val_AUC: 0.8315\n",
      "Epoch 222/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4411 - AUC: 0.8739 - val_loss: 0.5084 - val_AUC: 0.8326\n",
      "Epoch 223/250\n",
      "2100000/2100000 [==============================] - 138s 66us/sample - loss: 0.4407 - AUC: 0.8741 - val_loss: 0.5110 - val_AUC: 0.8326\n",
      "Epoch 224/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4405 - AUC: 0.8743 - val_loss: 0.5100 - val_AUC: 0.8308\n",
      "Epoch 225/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.4402 - AUC: 0.8745 - val_loss: 0.5164 - val_AUC: 0.8265\n",
      "Epoch 226/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4402 - AUC: 0.8745 - val_loss: 0.5065 - val_AUC: 0.8336\n",
      "Epoch 227/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4400 - AUC: 0.8746 - val_loss: 0.5111 - val_AUC: 0.8319\n",
      "Epoch 228/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4397 - AUC: 0.8747 - val_loss: 0.5104 - val_AUC: 0.8326\n",
      "Epoch 229/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4396 - AUC: 0.8748 - val_loss: 0.5078 - val_AUC: 0.8333\n",
      "Epoch 230/250\n",
      "2100000/2100000 [==============================] - 144s 68us/sample - loss: 0.4391 - AUC: 0.8751 - val_loss: 0.5111 - val_AUC: 0.8328\n",
      "Epoch 231/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4391 - AUC: 0.8751 - val_loss: 0.5098 - val_AUC: 0.8318\n",
      "Epoch 232/250\n",
      "2100000/2100000 [==============================] - 139s 66us/sample - loss: 0.4388 - AUC: 0.8753 - val_loss: 0.5156 - val_AUC: 0.8296\n",
      "Epoch 233/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4387 - AUC: 0.8754 - val_loss: 0.5112 - val_AUC: 0.8312\n",
      "Epoch 234/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4384 - AUC: 0.8756 - val_loss: 0.5125 - val_AUC: 0.8311\n",
      "Epoch 235/250\n",
      "2100000/2100000 [==============================] - 145s 69us/sample - loss: 0.4382 - AUC: 0.8757 - val_loss: 0.5127 - val_AUC: 0.8314\n",
      "Epoch 236/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4379 - AUC: 0.8758 - val_loss: 0.5135 - val_AUC: 0.8304\n",
      "Epoch 237/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4378 - AUC: 0.8759 - val_loss: 0.5105 - val_AUC: 0.8335\n",
      "Epoch 238/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4375 - AUC: 0.8762 - val_loss: 0.5183 - val_AUC: 0.8288\n",
      "Epoch 239/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4373 - AUC: 0.8763 - val_loss: 0.5131 - val_AUC: 0.8301\n",
      "Epoch 240/250\n",
      "2100000/2100000 [==============================] - 148s 70us/sample - loss: 0.4370 - AUC: 0.8764 - val_loss: 0.5123 - val_AUC: 0.8323\n",
      "Epoch 241/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4369 - AUC: 0.8765 - val_loss: 0.5192 - val_AUC: 0.8258\n",
      "Epoch 242/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4367 - AUC: 0.8766 - val_loss: 0.5163 - val_AUC: 0.8279\n",
      "Epoch 243/250\n",
      "2100000/2100000 [==============================] - 138s 66us/sample - loss: 0.4364 - AUC: 0.8768 - val_loss: 0.5156 - val_AUC: 0.8300\n",
      "Epoch 244/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4362 - AUC: 0.8769 - val_loss: 0.5132 - val_AUC: 0.8310\n",
      "Epoch 245/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4361 - AUC: 0.8770 - val_loss: 0.5127 - val_AUC: 0.8299\n",
      "Epoch 246/250\n",
      "2100000/2100000 [==============================] - 142s 68us/sample - loss: 0.4358 - AUC: 0.8772 - val_loss: 0.5154 - val_AUC: 0.8304\n",
      "Epoch 247/250\n",
      "2100000/2100000 [==============================] - 141s 67us/sample - loss: 0.4356 - AUC: 0.8773 - val_loss: 0.5149 - val_AUC: 0.8305\n",
      "Epoch 248/250\n",
      "2100000/2100000 [==============================] - 140s 66us/sample - loss: 0.4355 - AUC: 0.8774 - val_loss: 0.5192 - val_AUC: 0.8286\n",
      "Epoch 249/250\n",
      "2100000/2100000 [==============================] - 143s 68us/sample - loss: 0.4352 - AUC: 0.8775 - val_loss: 0.5134 - val_AUC: 0.8301\n",
      "Epoch 250/250\n",
      "2100000/2100000 [==============================] - 140s 67us/sample - loss: 0.4351 - AUC: 0.8776 - val_loss: 0.5164 - val_AUC: 0.8279\n",
      "Wall time: 9h 57min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a91f546748>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(x_train, y_train, epochs=250, validation_data=(x_test,y_test), batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
