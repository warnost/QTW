{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Bank Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data\n",
    "\n",
    "In this section we read in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>C</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>...</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.630686</td>\n",
       "      <td>7.464411</td>\n",
       "      <td>C</td>\n",
       "      <td>4.145098</td>\n",
       "      <td>8.742359</td>\n",
       "      <td>2.436402</td>\n",
       "      <td>2.483921</td>\n",
       "      <td>1.496569</td>\n",
       "      <td>...</td>\n",
       "      <td>6.822439</td>\n",
       "      <td>3.549938</td>\n",
       "      <td>0.919812</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.672658</td>\n",
       "      <td>3.239542</td>\n",
       "      <td>2.030373</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925763</td>\n",
       "      <td>1.739389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2 v3        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1  1.630686  7.464411  C  4.145098   9.191265  2.436402  2.483921   \n",
       "2   5       1  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1  1.630686  7.464411  C  4.145098   8.742359  2.436402  2.483921   \n",
       "\n",
       "         v8  ...      v122      v123      v124  v125      v126      v127  \\\n",
       "0  0.012941  ...  8.000000  1.989780  0.035754    AU  1.804126  3.113719   \n",
       "1  2.301630  ...  6.822439  3.549938  0.598896    AF  1.672658  3.239542   \n",
       "2  0.019645  ...  9.333333  2.477596  0.013452    AE  1.773709  3.922193   \n",
       "3  0.171947  ...  7.018256  1.812795  0.002267    CJ  1.415230  2.954381   \n",
       "4  1.496569  ...  6.822439  3.549938  0.919812     Z  1.672658  3.239542   \n",
       "\n",
       "       v128  v129      v130      v131  \n",
       "0  2.024285     0  0.636365  2.857144  \n",
       "1  1.957825     0  1.925763  1.739389  \n",
       "2  1.120468     2  0.883118  1.176472  \n",
       "3  1.990847     1  1.677108  1.034483  \n",
       "4  2.030373     0  1.925763  1.739389  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/case_8.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obvious issues like parsing errors or missings. Lets see what we have for data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 133 columns):\n",
      "ID        int64\n",
      "target    int64\n",
      "v1        float64\n",
      "v2        float64\n",
      "v3        object\n",
      "v4        float64\n",
      "v5        float64\n",
      "v6        float64\n",
      "v7        float64\n",
      "v8        float64\n",
      "v9        float64\n",
      "v10       float64\n",
      "v11       float64\n",
      "v12       float64\n",
      "v13       float64\n",
      "v14       float64\n",
      "v15       float64\n",
      "v16       float64\n",
      "v17       float64\n",
      "v18       float64\n",
      "v19       float64\n",
      "v20       float64\n",
      "v21       float64\n",
      "v22       object\n",
      "v23       float64\n",
      "v24       object\n",
      "v25       float64\n",
      "v26       float64\n",
      "v27       float64\n",
      "v28       float64\n",
      "v29       float64\n",
      "v30       object\n",
      "v31       object\n",
      "v32       float64\n",
      "v33       float64\n",
      "v34       float64\n",
      "v35       float64\n",
      "v36       float64\n",
      "v37       float64\n",
      "v38       int64\n",
      "v39       float64\n",
      "v40       float64\n",
      "v41       float64\n",
      "v42       float64\n",
      "v43       float64\n",
      "v44       float64\n",
      "v45       float64\n",
      "v46       float64\n",
      "v47       object\n",
      "v48       float64\n",
      "v49       float64\n",
      "v50       float64\n",
      "v51       float64\n",
      "v52       object\n",
      "v53       float64\n",
      "v54       float64\n",
      "v55       float64\n",
      "v56       object\n",
      "v57       float64\n",
      "v58       float64\n",
      "v59       float64\n",
      "v60       float64\n",
      "v61       float64\n",
      "v62       int64\n",
      "v63       float64\n",
      "v64       float64\n",
      "v65       float64\n",
      "v66       object\n",
      "v67       float64\n",
      "v68       float64\n",
      "v69       float64\n",
      "v70       float64\n",
      "v71       object\n",
      "v72       int64\n",
      "v73       float64\n",
      "v74       object\n",
      "v75       object\n",
      "v76       float64\n",
      "v77       float64\n",
      "v78       float64\n",
      "v79       object\n",
      "v80       float64\n",
      "v81       float64\n",
      "v82       float64\n",
      "v83       float64\n",
      "v84       float64\n",
      "v85       float64\n",
      "v86       float64\n",
      "v87       float64\n",
      "v88       float64\n",
      "v89       float64\n",
      "v90       float64\n",
      "v91       object\n",
      "v92       float64\n",
      "v93       float64\n",
      "v94       float64\n",
      "v95       float64\n",
      "v96       float64\n",
      "v97       float64\n",
      "v98       float64\n",
      "v99       float64\n",
      "v100      float64\n",
      "v101      float64\n",
      "v102      float64\n",
      "v103      float64\n",
      "v104      float64\n",
      "v105      float64\n",
      "v106      float64\n",
      "v107      object\n",
      "v108      float64\n",
      "v109      float64\n",
      "v110      object\n",
      "v111      float64\n",
      "v112      object\n",
      "v113      object\n",
      "v114      float64\n",
      "v115      float64\n",
      "v116      float64\n",
      "v117      float64\n",
      "v118      float64\n",
      "v119      float64\n",
      "v120      float64\n",
      "v121      float64\n",
      "v122      float64\n",
      "v123      float64\n",
      "v124      float64\n",
      "v125      object\n",
      "v126      float64\n",
      "v127      float64\n",
      "v128      float64\n",
      "v129      int64\n",
      "v130      float64\n",
      "v131      float64\n",
      "dtypes: float64(108), int64(6), object(19)\n",
      "memory usage: 116.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see mostly floats. There are some object data types we should probably recast. We have 114K observations, plenty to work with.  No variable names, as expected. He said there are no missings but lets check anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine. He told the truth. How about that target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    87021\n",
      "0    27300\n",
      "Name: target, dtype: int64\n",
      "0.2388\n"
     ]
    }
   ],
   "source": [
    "counts = df.target.value_counts()\n",
    "print(counts)\n",
    "print(round(counts[0]/sum(counts),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is binary and a little unbalanced, but not terrible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v3'] = df['v3'].astype('category')\n",
    "df['v22'] = df['v22'].astype('category')\n",
    "df['v24'] = df['v24'].astype('category')\n",
    "df['v30'] = df['v30'].astype('category')\n",
    "df['v31'] = df['v31'].astype('category')\n",
    "df['v47'] = df['v47'].astype('category')\n",
    "df['v52'] = df['v52'].astype('category')\n",
    "df['v56'] = df['v56'].astype('category')\n",
    "df['v66'] = df['v66'].astype('category')\n",
    "df['v71'] = df['v71'].astype('category')\n",
    "df['v74'] = df['v74'].astype('category')\n",
    "df['v75'] = df['v75'].astype('category')\n",
    "df['v79'] = df['v79'].astype('category')\n",
    "df['v91'] = df['v91'].astype('category')\n",
    "df['v107'] = df['v107'].astype('category')\n",
    "df['v110'] = df['v110'].astype('category')\n",
    "df['v112'] = df['v112'].astype('category')\n",
    "df['v113'] = df['v113'].astype('category')\n",
    "df['v125'] = df['v125'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 133 columns):\n",
      "ID        int64\n",
      "target    int64\n",
      "v1        float64\n",
      "v2        float64\n",
      "v3        category\n",
      "v4        float64\n",
      "v5        float64\n",
      "v6        float64\n",
      "v7        float64\n",
      "v8        float64\n",
      "v9        float64\n",
      "v10       float64\n",
      "v11       float64\n",
      "v12       float64\n",
      "v13       float64\n",
      "v14       float64\n",
      "v15       float64\n",
      "v16       float64\n",
      "v17       float64\n",
      "v18       float64\n",
      "v19       float64\n",
      "v20       float64\n",
      "v21       float64\n",
      "v22       category\n",
      "v23       float64\n",
      "v24       category\n",
      "v25       float64\n",
      "v26       float64\n",
      "v27       float64\n",
      "v28       float64\n",
      "v29       float64\n",
      "v30       category\n",
      "v31       category\n",
      "v32       float64\n",
      "v33       float64\n",
      "v34       float64\n",
      "v35       float64\n",
      "v36       float64\n",
      "v37       float64\n",
      "v38       int64\n",
      "v39       float64\n",
      "v40       float64\n",
      "v41       float64\n",
      "v42       float64\n",
      "v43       float64\n",
      "v44       float64\n",
      "v45       float64\n",
      "v46       float64\n",
      "v47       category\n",
      "v48       float64\n",
      "v49       float64\n",
      "v50       float64\n",
      "v51       float64\n",
      "v52       category\n",
      "v53       float64\n",
      "v54       float64\n",
      "v55       float64\n",
      "v56       category\n",
      "v57       float64\n",
      "v58       float64\n",
      "v59       float64\n",
      "v60       float64\n",
      "v61       float64\n",
      "v62       int64\n",
      "v63       float64\n",
      "v64       float64\n",
      "v65       float64\n",
      "v66       category\n",
      "v67       float64\n",
      "v68       float64\n",
      "v69       float64\n",
      "v70       float64\n",
      "v71       category\n",
      "v72       int64\n",
      "v73       float64\n",
      "v74       category\n",
      "v75       category\n",
      "v76       float64\n",
      "v77       float64\n",
      "v78       float64\n",
      "v79       category\n",
      "v80       float64\n",
      "v81       float64\n",
      "v82       float64\n",
      "v83       float64\n",
      "v84       float64\n",
      "v85       float64\n",
      "v86       float64\n",
      "v87       float64\n",
      "v88       float64\n",
      "v89       float64\n",
      "v90       float64\n",
      "v91       category\n",
      "v92       float64\n",
      "v93       float64\n",
      "v94       float64\n",
      "v95       float64\n",
      "v96       float64\n",
      "v97       float64\n",
      "v98       float64\n",
      "v99       float64\n",
      "v100      float64\n",
      "v101      float64\n",
      "v102      float64\n",
      "v103      float64\n",
      "v104      float64\n",
      "v105      float64\n",
      "v106      float64\n",
      "v107      category\n",
      "v108      float64\n",
      "v109      float64\n",
      "v110      category\n",
      "v111      float64\n",
      "v112      category\n",
      "v113      category\n",
      "v114      float64\n",
      "v115      float64\n",
      "v116      float64\n",
      "v117      float64\n",
      "v118      float64\n",
      "v119      float64\n",
      "v120      float64\n",
      "v121      float64\n",
      "v122      float64\n",
      "v123      float64\n",
      "v124      float64\n",
      "v125      category\n",
      "v126      float64\n",
      "v127      float64\n",
      "v128      float64\n",
      "v129      int64\n",
      "v130      float64\n",
      "v131      float64\n",
      "dtypes: category(19), float64(108), int64(6)\n",
      "memory usage: 102.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_data(data):\n",
    "    #OH encode\n",
    "    label_encode = ['v3','v24','v30','v31','v47','v52','v56','v66','v71','v74','v75','v79','v91','v107','v110','v112','v113','v125']\n",
    "    for var in label_encode:\n",
    "        #impute to Mode\n",
    "        data[var].fillna(data[var].mode()[0], inplace=True)\n",
    "        cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "        data_new = data.join(cat_list)\n",
    "        data = data_new\n",
    "\n",
    "    normalize = [x for x, y in dict(data.dtypes).items() if y == np.float64]\n",
    "    for col in normalize:\n",
    "        #change impution scheme?\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "        normalizer = StandardScaler()\n",
    "        ar_train = data[col].to_numpy().reshape(-1, 1)\n",
    "        normalizer.fit(ar_train)\n",
    "        data.loc[:, col] = normalizer.transform(ar_train)\n",
    "    \n",
    "    data.drop(columns=label_encode, inplace=True)\n",
    "    #data.drop(columns=target_col, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform = df\n",
    "transform_data(df_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/Sundar0989/WOE-and-IV/blob/master/WOE_IV.ipynb\n",
    "\n",
    "# import packages\n",
    "import pandas.core.algorithms as algos\n",
    "from pandas import Series\n",
    "import scipy.stats.stats as stats\n",
    "import re\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "max_bin = 20\n",
    "force_bin = 3\n",
    "\n",
    "# define a binning function\n",
    "def mono_bin(Y, X, n = max_bin):\n",
    "    \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]\n",
    "    r = 0\n",
    "    while np.abs(r) < 1:\n",
    "        try:\n",
    "            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
    "            d2 = d1.groupby('Bucket', as_index=True)\n",
    "            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "            n = n - 1 \n",
    "        except Exception as e:\n",
    "            n = n - 1\n",
    "\n",
    "    if len(d2) == 1:\n",
    "        n = force_bin         \n",
    "        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
    "        if len(np.unique(bins)) == 2:\n",
    "            bins = np.insert(bins, 0, 1)\n",
    "            bins[1] = bins[1]-(bins[1]/2)\n",
    "        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
    "        d2 = d1.groupby('Bucket', as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"MIN_VALUE\"] = d2.min().X\n",
    "    d3[\"MAX_VALUE\"] = d2.max().X\n",
    "    d3[\"COUNT\"] = d2.count().Y\n",
    "    d3[\"EVENT\"] = d2.sum().Y\n",
    "    d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n",
    "    d3=d3.reset_index(drop=True)\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def char_bin(Y, X):\n",
    "        \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
    "    df2 = notmiss.groupby('X',as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"COUNT\"] = df2.count().Y\n",
    "    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
    "    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
    "    d3[\"EVENT\"] = df2.sum().Y\n",
    "    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    d3 = d3.reset_index(drop=True)\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def data_vars(df1, target):\n",
    "    \n",
    "    stack = traceback.extract_stack()\n",
    "    filename, lineno, function_name, code = stack[-2]\n",
    "    vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
    "    final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
    "    \n",
    "    x = df1.dtypes.index\n",
    "    count = -1\n",
    "    \n",
    "    for i in x:\n",
    "        if i.upper() not in (final.upper()):\n",
    "            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
    "                conv = mono_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i\n",
    "                count = count + 1\n",
    "            else:\n",
    "                conv = char_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i            \n",
    "                count = count + 1\n",
    "                \n",
    "            if count == 0:\n",
    "                iv_df = conv\n",
    "            else:\n",
    "                iv_df = iv_df.append(conv,ignore_index=True)\n",
    "    \n",
    "    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n",
    "    iv = iv.reset_index()\n",
    "    return(iv_df,iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-dea5e503498a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIV\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_transform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-dfa4f94288f6>\u001b[0m in \u001b[0;36mdata_vars\u001b[1;34m(df1, target)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmono_bin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mconv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"VAR_NAME\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML7331\\lib\\site-packages\\numpy\\core\\numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[1;34m(arg1, arg2)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \"\"\"\n\u001b[0;32m    392\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0marg2_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "df_final, IV=data_vars(df_transform,df_transform.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_vars_list = ['v3']\n",
    "\n",
    "for var in transform_vars_list:\n",
    "    small_df = final_iv[final_iv['VAR_NAME'] == var]\n",
    "    transform_dict = dict(zip(small_df.MAX_VALUE,small_df.WOE))\n",
    "    replace_cmd = ''\n",
    "    replace_cmd1 = ''\n",
    "    for i in sorted(transform_dict.items()):\n",
    "        replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n",
    "        replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n",
    "    replace_cmd = replace_cmd + '0'\n",
    "    replace_cmd1 = replace_cmd1 + '0'\n",
    "    if replace_cmd != '0':\n",
    "        try:\n",
    "            df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd))\n",
    "        except:\n",
    "            df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score #https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator_grid_search:[80, 90, 100]\n",
      "max_features_grid_search:[5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
      "min_samples_split_grid_search:[500, 600, 700]\n",
      "min_samples_leaf_grid_search:[10, 20]\n"
     ]
    }
   ],
   "source": [
    "n_estimators= list(range(80, 110, 10))\n",
    "max_features = list(range(5, 50, 5))\n",
    "min_samples_split = list(range(500, 701, 100))\n",
    "min_samples_leaf = [10, 20]\n",
    "print(f'n_estimator_grid_search:{n_estimators}')\n",
    "print(f'max_features_grid_search:{max_features}')\n",
    "print(f'min_samples_split_grid_search:{min_samples_split}')\n",
    "print(f'min_samples_leaf_grid_search:{min_samples_leaf}')\n",
    "\n",
    "\n",
    "param_dist = {'n_estimators': n_estimators,\n",
    "              'max_features': max_features,\n",
    "              'min_samples_split': min_samples_split,\n",
    "              'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "scoring = {\n",
    "            'Accuracy':'accuracy'\n",
    "            , 'F-1 Score':'f1'\n",
    "            , 'Log Loss':'neg_log_loss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is:  (114321, 112)\n",
      "The shape of y is:  (114321,)\n"
     ]
    }
   ],
   "source": [
    "X = df.copy().drop(columns=[\"ID\",\"target\"]).select_dtypes(include=['number'])\n",
    "print(\"The shape of X is: \", X.shape)\n",
    "\n",
    "y = df.loc[:,\"target\"].copy()\n",
    "print(\"The shape of y is: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pickle\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, n_jobs=-1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%%script false --no-raise-error\n",
    "\n",
    "n_iter_search = 2\n",
    "rf_random_search = RandomizedSearchCV(clf, param_distributions=param_dist, scoring=scoring, cv = cv, random_state=42,\n",
    "                                   n_iter=n_iter_search, refit='Accuracy')\n",
    "rf_random_search.fit(X, y)\n",
    "\n",
    "filename = 'rf_random_search.p'\n",
    "pickle.dump(rf_random_search, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_F-1 Score</th>\n",
       "      <th>rank_test_F-1 Score</th>\n",
       "      <th>split0_test_Log Loss</th>\n",
       "      <th>split1_test_Log Loss</th>\n",
       "      <th>split2_test_Log Loss</th>\n",
       "      <th>split3_test_Log Loss</th>\n",
       "      <th>split4_test_Log Loss</th>\n",
       "      <th>mean_test_Log Loss</th>\n",
       "      <th>std_test_Log Loss</th>\n",
       "      <th>rank_test_Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.157500</td>\n",
       "      <td>0.522185</td>\n",
       "      <td>0.299219</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>100</td>\n",
       "      <td>600</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 600...</td>\n",
       "      <td>0.761207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.511693</td>\n",
       "      <td>-0.512290</td>\n",
       "      <td>-0.510889</td>\n",
       "      <td>-0.512233</td>\n",
       "      <td>-0.511126</td>\n",
       "      <td>-0.511646</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.877493</td>\n",
       "      <td>0.558074</td>\n",
       "      <td>0.392696</td>\n",
       "      <td>0.078932</td>\n",
       "      <td>90</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>{'n_estimators': 90, 'min_samples_split': 500,...</td>\n",
       "      <td>0.761207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.514703</td>\n",
       "      <td>-0.515797</td>\n",
       "      <td>-0.514101</td>\n",
       "      <td>-0.515398</td>\n",
       "      <td>-0.514052</td>\n",
       "      <td>-0.514810</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      14.157500      0.522185         0.299219        0.022185   \n",
       "1      10.877493      0.558074         0.392696        0.078932   \n",
       "\n",
       "  param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                100                     600                     20   \n",
       "1                 90                     500                     10   \n",
       "\n",
       "  param_max_features                                             params  \\\n",
       "0                 45  {'n_estimators': 100, 'min_samples_split': 600...   \n",
       "1                 35  {'n_estimators': 90, 'min_samples_split': 500,...   \n",
       "\n",
       "   split0_test_Accuracy  ...  std_test_F-1 Score  rank_test_F-1 Score  \\\n",
       "0              0.761207  ...        1.110223e-16                    1   \n",
       "1              0.761207  ...        1.110223e-16                    1   \n",
       "\n",
       "   split0_test_Log Loss  split1_test_Log Loss  split2_test_Log Loss  \\\n",
       "0             -0.511693             -0.512290             -0.510889   \n",
       "1             -0.514703             -0.515797             -0.514101   \n",
       "\n",
       "   split3_test_Log Loss  split4_test_Log Loss  mean_test_Log Loss  \\\n",
       "0             -0.512233             -0.511126           -0.511646   \n",
       "1             -0.515398             -0.514052           -0.514810   \n",
       "\n",
       "   std_test_Log Loss  rank_test_Log Loss  \n",
       "0           0.000566                   1  \n",
       "1           0.000694                   2  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_search = pd.read_pickle('rf_random_search.p')\n",
    "pd.DataFrame(rf_random_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#https://xgboost.readthedocs.io/en/latest/build.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'learning_rate': [0.005, 0.01, 0.02, 0.05, 0.1],\n",
    "        'n_estimators': [100,200,400,600,800,1000],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic',\n",
    "                    silent=True, nthread=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%%script false --no-raise-error\n",
    "n_iter_search = 2\n",
    "xgb_random_search = RandomizedSearchCV(xgb, param_distributions=params, scoring=scoring, cv = cv, random_state=42,\n",
    "                                   n_iter=n_iter_search, refit='Accuracy')\n",
    "xgb_random_search.fit(X, y)\n",
    "\n",
    "filename = 'xgb_random_search.p'\n",
    "pickle.dump(xgb_random_search, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_F-1 Score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_F-1 Score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_F-1 Score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_F-1 Score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_F-1 Score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_F-1 Score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_F-1 Score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_Log Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_Log Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_Log Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_Log Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_Log Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_Log Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_Log Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_Log Loss</th>\n",
       "      <th>std_test_Log Loss</th>\n",
       "      <th>rank_test_Log Loss</th>\n",
       "      <th>split0_train_Log Loss</th>\n",
       "      <th>split1_train_Log Loss</th>\n",
       "      <th>split2_train_Log Loss</th>\n",
       "      <th>split3_train_Log Loss</th>\n",
       "      <th>split4_train_Log Loss</th>\n",
       "      <th>mean_train_Log Loss</th>\n",
       "      <th>std_train_Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.695948</td>\n",
       "      <td>0.513996</td>\n",
       "      <td>0.563534</td>\n",
       "      <td>0.012532</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499054</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.371650</td>\n",
       "      <td>-0.371244</td>\n",
       "      <td>-0.370991</td>\n",
       "      <td>-0.371692</td>\n",
       "      <td>-0.370583</td>\n",
       "      <td>-0.371232</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.084821</td>\n",
       "      <td>0.255249</td>\n",
       "      <td>0.416493</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496882</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.493681</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.493701</td>\n",
       "      <td>-0.493410</td>\n",
       "      <td>-0.494110</td>\n",
       "      <td>-0.493723</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      78.695948      0.513996         0.563534        0.012532   \n",
       "1      37.084821      0.255249         0.416493        0.004925   \n",
       "\n",
       "  param_subsample param_n_estimators param_min_child_weight param_max_depth  \\\n",
       "0             0.8               1000                      5               5   \n",
       "1               1                800                     10               3   \n",
       "\n",
       "  param_learning_rate param_gamma  ... mean_test_Log Loss std_test_Log Loss  \\\n",
       "0                 0.1           2  ...          -0.499054          0.001442   \n",
       "1               0.005           1  ...          -0.496882          0.000619   \n",
       "\n",
       "   rank_test_Log Loss  split0_train_Log Loss  split1_train_Log Loss  \\\n",
       "0                   2              -0.371650              -0.371244   \n",
       "1                   1              -0.493681              -0.493714   \n",
       "\n",
       "   split2_train_Log Loss  split3_train_Log Loss  split4_train_Log Loss  \\\n",
       "0              -0.370991              -0.371692              -0.370583   \n",
       "1              -0.493701              -0.493410              -0.494110   \n",
       "\n",
       "   mean_train_Log Loss  std_train_Log Loss  \n",
       "0            -0.371232            0.000416  \n",
       "1            -0.493723            0.000224  \n",
       "\n",
       "[2 rows x 57 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_random_search = pd.read_pickle('xgb_random_search.p')\n",
    "pd.DataFrame(xgb_random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC\n",
    "This never finishes. Need to reduce features for it to do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%%script false --no-raise-error\n",
    "#n_iter_search = 2\n",
    "#svc_random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid, scoring=scoring, cv = 2, random_state=42,\n",
    "                                   n_iter=n_iter_search, refit='Accuracy')\n",
    "#svc_random_search.fit(X, y)\n",
    "\n",
    "#filename = 'svc_random_search.p'\n",
    "#pickle.dump(svc_random_search, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[1,10,100,1000], 'loss':['hinge','square_hinge']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported set of arguments: loss='square_hinge' is not supported, Parameters: penalty='l2', loss='square_hinge', dual=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-257e34f9aef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m lsvc_random_search = RandomizedSearchCV(LinearSVC(), param_distributions=param_grid, scoring=scoring, cv = 2, random_state=42,\n\u001b[0;32m      3\u001b[0m                                    n_iter=n_iter_search, refit='Accuracy')\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlsvc_random_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lsvc_random_search.p'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1515\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"crammer_singer\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m     \u001b[0msolver_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0;32m    912\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_get_liblinear_solver_type\u001b[1;34m(multi_class, penalty, loss, dual)\u001b[0m\n\u001b[0;32m    764\u001b[0m     raise ValueError('Unsupported set of arguments: %s, '\n\u001b[0;32m    765\u001b[0m                      \u001b[1;34m'Parameters: penalty=%r, loss=%r, dual=%r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m                      % (error_string, penalty, loss, dual))\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported set of arguments: loss='square_hinge' is not supported, Parameters: penalty='l2', loss='square_hinge', dual=True"
     ]
    }
   ],
   "source": [
    "n_iter_search = 2\n",
    "lsvc_random_search = RandomizedSearchCV(LinearSVC(), param_distributions=param_grid, scoring=scoring, cv = 2, random_state=42,\n",
    "                                   n_iter=n_iter_search, refit='Accuracy')\n",
    "lsvc_random_search.fit(X, y)\n",
    "\n",
    "filename = 'lsvc_random_search.p'\n",
    "pickle.dump(lsvc_random_search, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
